---
title: The Ocean Health Index Assessment Manual
---

# What is OHI+?

> Your assessment will be an example of independent Ocean Health Index+ assessment (OHI+). At this stage, you should have **Learned** and **Planned** for your assessment, and are now ready to **Conduct** it.

The Ocean Health Index framework presents a highly tailorable approach ready to meet the needs and priorities of those who wish to use the ocean sustainably. Here you will learn how to conduct an Ocean Health Index+ (OHI+) assessment.  The OHI+ approach adds relevant inputs and information to the overarching OHI framework and consists of data and indicators that are specific to the local context. Because the methods of the framework are repeatable, transparent, quantitative, and goal-driven, repeated assessments are valuable because they can be used to tack and monitor the progress of ocean health through time. Even if yours is a first effort, your OHI+ is valuable because it establishes a monitoring baseline and calls attention to the state of the data quality and availability in your area. Such a flexible approach allows OHI+ assessments to adapt to local conditions while still being useful for management.

> Remember that when conducting an assessment, the process is just as valuable as the results.

The Index is an assessment tool that provides a common platform for scientifically combining and comparing key elements from all dimensions of the oceans health — biological, physical, economic, and social – to measure how sustainably people are using the ocean. By allowing for a comprehensive and integrated view of marine systems as a way to understand the trade-offs and synergies among these goals, the Index represents a significant advance over conventional single-sector approaches to assessing sustainability as communicated through other kinds of index efforts. Because of this, preparing the conducting phase will require careful thought, consideration, and documentation, throughout this process.

### The Process of OHI+

The OHI+ process consists of four distinct phases. In the first phase, you **learned** about the OHI and understood the philosophy behind it and the motivation for conducting your study. In the second phase, you actively **planned** to conduct an OHI+ Assessment. Now, in the third phase, you will **conduct** the assessment by engaging with the science of finding the data, preparing the goal models, and taking the necessary steps to learn the software and produce the results. In the final phase, you will communicate the results of your OHI+ Assessment in order to inform stakeholders who will use its findings.

- >**Phase 1:** **Learn** about the OHI
- >**Phase 2:** **Plan** an OHI+ Assessment
- **Phase 3:** **Conduct** the OH+ Assessment
- >**Phase 4:** **Communicate** and Inform

#### What to expect when conducting an assessment
<!---From Conducting_assessment--->
There are key considerations and processes that will be a part of every assessment, however, the process for conducting each assessment will be unique depending on the local context. For example: what data and indicators are available will determine how goal models can be tailored to the region, and what skillsets and resources are involved will affect the time it takes to complete the assessment.

> In OHI+,it is important for your team doing the study to make the decisions and modifications that are most important for the region, and then defend it clearly what was done and why. At the same, your team should  as creative and insightful as you can be.

#### Where to start when conducting an assessment

You should start by understanding the structure of the global assessment and the data involved will help you think about what should be done differently in your local context.  

The best way to do this is to begin with the WebApps. As described in the section, "**Overview of the OHI WebApp**," most coastal countries have a WebApp that was created to facilitate planning and communication during your assessment. The WebApp presents data, goal models and calculated scores for each region (global administrative area identified by http://gadm.org) visually through maps, histograms, and tables. All data presented were extracted from the global analysis, and scores were calculated using global goal models. For a finer-scale assessment of ocean health in your region, these data files provided will need to be updated with available data and indicators for each region in your assessment. However, if better data are not available, you can use the data provided. Then, to dive deeper into data layers and goal models, you can explore your assessment's GitHub repository, which stores all the information presented through the WebApp.  

You should also be familiar with the approaches taken by other assessments adapted from the global context, including Brazil, the US West Coast, and Fiji. You can find these studies at http://ohi-science.org.  

While our team of scientists and managers is prepared to provide guidance for assessments, you should follow the steps in this training program to complete your assessment as autonomously as possible.

### Expected outcomes

**The process of conducting an OHI assessment is as valuable as the final results.** This is because while conducting an OHI assessment you will identify gaps in knowledge and data, produce decision-relevant information, and create an ocean alliance that combines knowledge and cultural values across disciplines. Conducting an OHI assessment requires engagement from as many different groups as possible, including research institutions, government agencies, policy groups, non-governmental organizations, and the civil and private sectors.  

**Finding the best data and indicators available is crucial for obtaining meaningful findings that can help inform decision-making.**  Assessments can incorporate higher-resolution data and indicators, local priorities and preferences, and develop tailored goal models and reference points, which produce scores that better reflect local realities. If a goal is not relevant in the local context, it can be excluded entirely. When you change goal models, though, it is important to capture the process in order to justify decisions that will inform the results. Similarly, pressures and resilience measures can be refined using local data and indicators. Index scores are only as good as the data on which they are based.

# Overview of the OHI WebApp

>**Section Summary:**

>In this section, you will get an introduction to the OHI WebApps. When using the WebApp, you can conduct a preliminary assessment and use the built-in functions to compare input layers,  output scores, and change data display options. You will return to the WebApp at the end of this phase.

> OHI WebApps serve several purposes because they:

> * allow for exploration of how the Index works: what data look like and which data layers are used in each goal
* are a communication platform for an assessment team, since information is presented in a manner that is accessible to group members of different disciplines and technical capacities
* can be used to set data gathering or goal model development priorities for the assessment
* display your assessment’s data and calculated scores once you have finalized and formatted your data and modified goal models.  

## Background

**OHI WebApps** are websites created to facilitate independent assessments, and one is available for nearly every coastal nation or territory. The WebApps are meant to be a ‘Starter Kit’ and are available through http://ohi-science.org using a three-letter identifier in the URL. For example, Ecuador’s WebApp ("ECU") is found at http://ohi-science.org/ecu.
Each WebApp displays data layers\*, which are raw data in this case, as well as the calculated OHI scores based on information extracted from global assessments. As such, they do not provide fine-scale resolution of data for each coastal nation or territory: the scores and data on which they are based are a starting point for an assessment to be conducted by an independent group. These data can be used as a default if better data for the region do not exist, but we encourage you to replace them wherever possible. (\*Note: each data component that is included in the OHI is called a **data layer** because it will be combined with others to calculate the goal scores. Many data layers are rescaled from 0-1 to be combined with  other data layers on the same unitless scale.)  
Boundaries for exclusive economic zones (EEZs) were identified by http://www.marineregions.org and the largest subcountry regions (i.e., provinces, states, districts) were identified by http://gadm.org. Subcountry region boundaries were extended offshore to divide the EEZ of each study area into offshore regions. These subcountry regions have been provided as a starting point, and are typically coastal states or provinces, which, in our experience, is consistent with the scale at which most policy decisions are made. However, it is possible to change the boundaries for the regions and the study area depending on your preferences.

> Note that the OHI+ team doesn't take a stance on disputed territories. For independent assessments, we defer to the map-providers and the best judgment of the technical team.  

The information displayed on the website is stored online, in a **GitHub repository.** GitHub is an open-source development platform allows for multiple users to collaborate, track changes, and document work such as data files and code. Therefore, any changes made to the files contained within the GitHub repository will be displayed on the WebApp for all team members to view. (See the section on **GitHub** for how to modify files using that platform).

## Using the WebApp

> When your team has finalized data layers and updated goal models, these data and scores will be visualized through the WebApp.

When first exploring a WebApp (for example, http://ohi-science.org/ecu), first note that it is possible to **translate** the site into any language that Google provides using the pull-down menu at the top. This will help with communication among your team. 

![The WebApp start page. Note that it's possible to translate the page into your language of choice.](https://docs.google.com/drawings/d/11Gojqw0Xz4kUo_uM1Y699EKO3qN_dae0w93ICzXJ2Pg/pub?w=960&h=720)

The WebApp homepage provides several tabs for you to explore. The interactive **App** sub-page allows you to explore input data layers and output calculated scores for each region (See **Overview of Variable Options**). More detailed information is about the default **regions** and **data layers**, **goal models**, and **calculated scores** based on global data can be viewed in separate tabs, as well as through the App page.
A quick reference about navigating the WebApp is available through the **Docs** link at the bottom of the page.

## The App Page

The App page allows you to explore and visualize input data layers and calculated output scores for each region in the study area. By default, global data are presented for each subcountry region in the study area, and scores are calculated for each region using those data.  

The App  page displays this information through two tabs: Data and Compare. The **Data** tab provides several subtabs for viewing data (*Map*, *Histogram*, *Table*), and is the default tab when the Toolbox is launched. The **Compare** tab is most useful for comparing output scores when modifications are made to the underlying data or models (this provides a way to error check) once you have begun the process of calculating your own assessment.  

The App provides two Branch/Scenario options to view, identified in the upper-left corner of the Data tab. The **Branch** options refer to the versions of the GitHub repository where data are stored. Branches start off as copies of the same repository, but can be modified independently of each other, enabling progress to be made on one (‘draft’ branch) while not altering the vetted original (‘published’ branch). These branches can be merged back together at any time. The App page will display the ‘published branch’ by default; we recommend working on the ‘draft’ branch until your assessment is finalized, at which point you would merge the draft branch with the published branch.  

**Scenario** folders contain all the files needed to calculate scores. Scenario folders can differ from each other based on the years included (i.e., 2014 would be a different scenario from 2015), or they can be used to explore outcomes of policy alternatives, such as implementation of a proposed Marine Protected Area network or fisheries regulations. Running these different scenarios can be very useful for an OHI+ assessment in which multiple outcomes are to be evaluated.


## The App's Data tab

### Overview of display options

The Data tab displays input data layer or calculated scores for each goal parameter, and presents the information as a map, histogram, or table. These options (*Map*, *Histogram*, *Table*) are presented as subtabs located the map. The Map subtab is the default display option for the Data tab, and all data presented are drawn from data from the Global Assessments. This means they are either directly duplicated, or down-scaled using regional areas or population weightings.


**Data displayed in the Map subtab:**

![The Map subtab. Click on  'Map'  to see a geographic view of your assessment region. Colors indicate scores or values for your input layers or output scores.](https://docs.google.com/drawings/d/1SzyHRaHqNWyr_6fji5RcY-nYtN5x5HSTjSgl4tFty44/pub?w=959&h=405)

The map displays data for every region as reported in the scenario. A color legend is displayed in the lower right corner of the map. The range of values will change as different variables are selected, and the colors will automatically change to create a visual scale of reference.


**Data displayed in the Histogram subtab:**

![Click on 'Histogram' to see the distribution of your data or scores, after selecting a variable layer on the left. This example shows the Species sub-goal scores for the study regions of Ecuador.](https://docs.google.com/drawings/d/10TGLNEWQpGcUHeLwT06kJUSUcMEa2tb1IwFaauf6Fmk/pub?w=959&h=415)

The histogram shows the distribution of the selected variable as the number of observations per value bin (white bars) and a smoothed density function (pink shading).


**Data displayed in the Table subtab:**

![Click on 'Table' to see a table of your data or scores, after selecting a variable layer on the left. This example shows the Species sub-goal scores for the study regions of Ecuador.](https://docs.google.com/drawings/d/12CC5Q7YXweoKw39lHkRjBGcoEVsw3bWuuJPVdzxFRAc/pub?w=960&h=419)

The table displays the target value for each region and the overall study area. It provides an identifying code (*rgn_id*), name (*rgn_name*), and value (*value*) for each.


### Overview of variable options

The Data tab has drop-down menus from which  you choose the data to be displayed. Data selected from the pull-down menus can be viewed in Map, Histogram, or Table form as described in the section above. Descriptions, statistics and metadata for the chosen fields are also displayed below the drop-down menus on the left side of the tab.

![Overview of the Data tab. Choose the variable you would like to explore through the drop-down menus on the left-hand side of the page. Once you select either raw data or a score, you can view a description and statistical summary below.](https://docs.google.com/drawings/d/17YGGl8ZGa7vB7MJTLGwCOL6yh2Ap-OZOK9iVsI-ez4M/pub?w=960&h=374)

> TIP: Remember that your descriptions and values in `layers.csv` will appear here.

The first selection to be made from the drop-down menus is variable type, in which you can choose the **Output Score** that will show a calculated score (for a particular target chosen subsequently), or **Input Layer** that will show the data layer used to calculate the score of a particular target. To reiterate, Output Scores are the scores calculated using the Input Layers (data layers).  

For example, if you select ‘Output Score’ as the variable type (which is the default), you will then be able to choose a target (goal or sub-goal), and the OHI dimension to be reported.  

As another example, if you select 'Input Layer' as the variable type, you will be able to choose a target and a specific data layer associated with that target. If that layer has multiple categories or years available, you will be able to select a preference. Without selection, the default setting is the first category alphabetically and the most recent year.


![](./fig/overview_variable_options2.png)

## The App’s Compare tab

The **Compare** tab allows you to compare differences in calculated scores based on changes you have made to the underlying data layers. Visualizing these differences is extremely helpful for confirming results and error checking. More context on the use of this function can be found in the section, "**The Ocean Health Index Toolbox**."<!--- develop. Removed line on 'instructions' for this functionality, so might want to include discussion of that elsewhere --->

## Discovering and Gathering Appropriate Data and Indicators

The OHI spans disciplines and integrates diverse data to give a comprehensive assessment of ocean health. A hallmark of the OHI is that it uses freely-available, existing data and indicators to create models that capture the philosophy of individual goals, and finding appropriate data requires good problem-solving abilities. There are many decisions to make when gathering from disparate sources, identifying good proxies and indicators, deciding reference points, and developing goal models.

** The accuracy of Index scores is a reflection of input data quality and the degree of understanding of the study area, and thus including the best quality and appropriate data and indicators available is of highest importance.**

Because the data and indicators you use will come from different sources and available from online databases, reports, spreadsheets and text files, they will also have different formatting. To include these data and indicators in your assessment, you will need to process these files into the format required by the Toolbox, which is explained in the section, **Formatting Data for the Toolbox**. When data have been prepared and formatted for the Toolbox, we call it a **data layer.** Because creating data layers can be quite time-intensive, data should only be prepared for the Toolbox after final decisions have been made to include the data or indicator in your assessment, and after the appropriate goal model and reference points have been finalized.  

There are many data layers included in the OHI framework. There are about eighty individual data layers from the global assessment that should be replaced with higher-resolution data in your study area where possible. You will need to search for data used to calculate status models as well as pressures and resilience layers.  

### Data sources

Existing data and indicators can be gathered from many sources across environmental, social, and economic disciplines, including:

* government reports and project websites
* peer-reviewed literature
* masters and PhD theses
* university websites
* non-profit organizations  

All data must be rescaled to specific reference points (targets) before being combined with the Toolbox; therefore setting these reference points at the appropriate scale is a fundamental component of any OHI assessment. This requires your assessment team to interpret the philosophy of each Index goal and sub-goal using the best available data and indicators. Some indicators already are scaled (e.g., from 0-1 or 0-10), and can easily be incorporated into your assessment since the reference points have already been identified.

### Gathering responsibilities

Gathering appropriate data requires searching for and accessing existing data. You do not have to go collect the data itself, but you do need to discover and acquire existing data. It is important that team members responsible for data discovery make thoughtful decisions about whether data are appropriate for the assessment, and that they get feedback from the full team to discuss the merits of different data sources. Data discovery and acquisition are typically an iterative process, as there are both practical and philosophical reasons for including or excluding data.  

When you begin exploring data possibilities, you can seek local data sources that could directly replace data from the global assessment provided in your repository. Such data would be better quality, i.e., higher accuracy and spatio-temporal resolution, than the data from the global assessment, and models may not need to change. However, we recommend first exploring other data possibilities that could capture specific characteristics to your study area. Assessments conducted at smaller scales are an opportunity to include characteristics specific to your study area that were not captured in the global assessment.

### The process of discovery

The most important thing to remember when gathering data and indicators is that they must contribute to measuring ocean health. Not all information that enhances our knowledge of marine processes directly convey information about ocean health and may not be appropriate within the OHI framework. Because of this, compiled indicators can sometimes be more suitable than raw data measuring single marine attributes.  

Begin by understanding and comparing the best approaches used in assessments that have been completed, including global assessments, Brazil, Fiji, and the US West Coast. For OHI+ assessments, if finer-resolution local data were available in the study area, these data were either incorporated into modified goal models that used locally appropriate and informed approaches or into the existing global goal model. When local data were not available, the global-scale data and global goal models were used, which is least desirable because it does not provide more information than the global study. When looking for data, the following decision tree may be useful.

 This should be a goal-by-goal process:


![](https://docs.google.com/drawings/d/1bJ3lk0stX78YM_VVR8VDAmdVUcMv4riSZk-0L2x8ybw/pub?w=624&h=336)

### Requirements for data and indicators

There are six requirements to remember when investigating (or ‘scoping’) potential data and indicators. It is important that data satisfy as many of these requirements as possible, at times requiring gap-filling solutions. If requirements are not met and gap-filling solutions are not possible, you will likely need to exclude a dataset from the analyses. If data cannot be included, you may elect to use the global data layers or identify other data and a different modeling approach.

1. relevance to ocean health
2. accessibility
3. quality
4. how to set the reference point
5. spatial scale
6. temporal scale


#### Relevance to ocean health  

There must be a clear connection between the data and ocean health, and determining this will be closely linked to each goal model.

#### Accessibility

The two main points regarding accessibility are whether the source is open access and whether the data or indicators will be updated regularly.  

The Index was created in the spirit of transparency and open-access, using open-source software and online platforms such as GitHub, is to ensure as much accessibility and open collaboration as possible. Data and indicators included should also follow these guidelines, so that anyone wishing to understand more about the Index may be able to see what data were used and how. For this reason we emphasize the importance of using data that may be made freely downloadable, as well as the importance of clearly documenting all data sources and reasons for the choices made in selecting data, indicators, and models.  

Index scores can be recalculated annually as new data become available. This can establish a baseline of ocean health and serve as a monitoring mechanism to evaluate the effectiveness of actions and policies in improving the status of overall ocean health. This is good to keep in mind while looking for data: will it be available again in the future? It is also important to document the sources of all data so that it is both transparent where it came from and you will be able to find it in the future.

#### Quality

Understanding how the data or indicators were collected or created is important. Are they collected by a respected organization with quality control? Are there any protocol changes to be aware of, e.g., were there changes in the collection protocol to be aware of when interpreting temporal trends?



#### Reference point  

Most data will need to be scaled to a reference point, as you consider different data sources it is important to think about or identify what a reasonable reference point may be. Ask the following types of questions as you explore data possibilities:  

* Has past research identified potential targets for these data?
  + example: maximum sustainable yield in fisheries
* Have policy targets been set regarding these data?
  + example: maximum levels of pollutants before beach closures
* Would a historic reference point be an appropriate target?
  + example: percent of habitat coverage before coastal development
* Could a region within the study area be set as a spatial reference point?
  + example: a certain region a leader in creating protected areas


#### Appropriate spatial scale

Data must be available for every region within the study area.*

#### Appropriate temporal scale
  Data must be available for at least three to five years to calculate the trend. For some goals, where temporal reference points are desirable, longer time series are preferable.*  

\* It is not always possible to fully meet the spatial and temporal requirements with each source. In these cases, provided that the gaps are not extensive, it can still be possible to use these data if appropriate gap-filling techniques are used (See: 'Formatting Data for Toolbox' section).  

### Example: US West Coast data discovery

Below are examples of some decisions made when exploring available data for the US West Coast assessment. Determining whether certain data could be included began with a solid understanding of the data layers and models included in the global assessment. Since the US West Coast is a data-rich region, finer-resolution local data could be used in place of many of the global data layers. The US West Coast assessment had five regions: Washington, Oregon, Northern California, Central California, and Southern California.


#### Reasons data were excluded  

There are a lot of existing data that contribute to our scientific understanding of ocean processes and interactions but are not ideal for the OHI. Reasons to exclude data are both due to practical requirements (e.g., resolution, coverage, or other requirements that have been listed) and philosophical requirements (i.e., they do not help capture the attributes of interest for assessing ocean health). Some common reasons for excluding data are:  

* **The data do not cover the entire area of the reporting region**. The state of California had excellent, long-term data on public attendance at state parks that would have been quite useful in the calculation of the tourism and recreation goal. However, data were only available for three of the five regions (the three California regions but not Oregon and Washington), so they could not be used.  

* **There is not a clear and scientifically observed relationship between the data and ocean health**. Along the US West Coast, kelp beds are a very important habitat because of their contribution to biodiversity and coastal protection. However, kelp coverage variation and is driven primarily by abiotic natural forcing (wave/storm disturbance and temperature) and thus it is not a good indicator of kelp forest health, particularly in the case of anthropogenic impacts. For these reasons kelp coverage was not included in the assessment.  

* **The feature being measured may provide benefits to people, but this feature is not derived from marine or coastal ecosystems**. Sea walls and riprap provide coastal protection to many people along the US West Coast. However, these structures are not a benefit that is derived from the marine ecosystems, so only coastal habitats were included in the calculation of this goal. These data can be included as a pressure due to habitat loss. They were not used as a resilience measure because they can often have negative side effects (e.g., by altering sedimentation dynamics), and because they have limited long-term sustainability (i.e., they need maintenance).  

* **Data collection is biased and might misrepresent ocean health**. The US Endangered Species Act identifies a species list focused on species of concern within the US. As such, these data are biased in the context of ocean health since they only assess species whose populations may be in danger. For the calculation of the biodiversity goal, using these data would be inappropriate because this goal represents the status of all species in the region, not just those that are currently of conservation concern. Using these data may have shown the status of biodiversity to be lower than it really is because the selection of species to assess was already biased towards species of concern.

* **Time series data are not long enough to calculate a trend or a reference point** (when a historical reference point is most appropriate). For the US West Coast, the current extent of seagrass habitats was available, however, these do not exist for previous points in time in most areas, so could not be used to calculate the trend or set a historical reference point. Therefore, we estimated the trend in health of seagrass habitats using as a proxy the trend in the main stressor (i.e., turbidity). In other words, we assumed that the rate of seagrass loss was directly proportional to the rate of increase in turbidity. Similar solutions may be used to estimate trends in your own assessment, if there is scientific support for assuming that the trend of what we want to assess (or the relationship between the current state and the state in the reference year) has a strong relationship with the trend of the proxy data available.

<!---Option: JSL develop the discussion of searching not only for strict data within your country to use, but studies that have been done anywhere in the world, demonstrating relationships between different things (eg camaroneras effects on mangrove condition)--->

## Best Approaches for Starting an Assessment

The Ocean Health Index team has a gained much knowledge from years of developing the Index. However, with each new independent assessment, the team is learning even more, and we hope to share that information with you and encourage outside dialogue on the best approaches to conducting an Independent Assessment.Your OHI+ assessment will also be invaluable in learning how to develop better and more appropriate techniques to changing goal models.

For goals that have been conducted commonly across OHI+ assessments and the Global Assessment, we provide recommendations for how to approach them broadly here in the Manual. Some broad themes to keep in mind are listed below, followed by practical considerations for each goal model area.

If you haven't already read about the goal philosophies in the OHI **Conceptual Guide**, you should read it before continuing. You should also read about **Assembling a Team** and **Strategy**. These are important first steps in starting an OHI+ assessment. You should also have checked out the WebApp and be familiar with its capabilities to keep your end-goal in mind.

****

**Here are some cross-cutting themes to keep in mind as you conduct your OHI+ assessment:**

#### Think Creatively

Humans interact with and depend upon the oceans in complex ways, some of which are familiar and easy to measure, such as providing seafood, transporting goods, or disposing of waste. Other benefits are more difficult to measure, such as the way marine-related jobs indirectly affect coastal communities, how different habitats mediate storm damage or the benefits people receive or perceive simply from living near the ocean. Thinking creatively and exploring the data available can make the Index more representative of reality.

 It is important to think creatively and beyond the interests of a specific institution or primary field of study. Google or other internet search engines are great starting places: investigate what kinds of information are available from government and public records, scientific literature, academic studies, surveys and reports or other sources.

 Data used in the Ocean Health Index spans a wide array of disciplines, both within and outside of oceanography and marine ecology. Therefore, it is necessary to look beyond the most known or obvious data sources to find data relevant for the goals in the region. Discussions with colleagues, literature searches, emails to experts, and search engines are good ways to understand what kinds of data are collected and to hunt for appropriate data.

#### Search for the Appropriate Data

Any assessment will depend on the available data, which requires creative thinking, particularly when ideal data are unavailable. Determining the appropriate scale and defining the study area and any regions within the study area will also depend on available data. The scale and resolution of available data can help inform the scale of the study area to be analyzed and how to divide it into regions.

Data included to calculate scores are partly based on the philosophical framework of the Ocean Health Index (see Part I), and partly based on data available. Several goals that combine across categories have many potential data sources that could be included (or excluded): in particular the natural products, livelihoods and economies, and habitat based goals. The existence of the data itself will drive a lot of these decisions, but here are some guidelines to help determine if data are appropriate philosophically:

* Do the data represent something truly ocean-based, and natural (i.e. not man-made)?
* How would the reference point be calculated?
* Do data cover the appropriate spatial scales?
* Do data cover the appropriate temporal scales?

#### Think about Spatial Considerations

Here it is important to think about why is there interest in completing an OHI assessment. If managers or policy makers are interested, at what scale do they work? Where are the political boundaries? These questions are important to keep the OHI assessment relevant, but ultimately data availability will be most important in how to define regional boundaries for the OHI.

There are several spatial considerations you should have prepared before moving forward with the Toolbox. One is your map definitions for use in the assessment and in the WebApps. You must define your map regions and boundary. This can be politically drawn or, if appropriate, biogeographically drawn. Biographic considerations may be important when there are disputed territories or boundary lines in your area. *Note that OHI+ does not take a position on disputed territories, so it is up to you to vet the quality of the maps.*

Once you have the maps, you may also need to define buffer zones. Buffers are distances from shore, both inland and offland, that can be used later in the Toolbox to assess many impacts more accurately.

Finally, you will need to prepare your layers folder with spatial data. Only goals certain goals will require data layers that are spatial (see Section, **Habitat-Based Goals**). When considering spatial data, you should be conscientious of how it is presented: is it by square kilometers, or by a kind of region such as an EEZ or other identifier? Do you have better local data than global satellite or modeled data? Once you find the data, consider how far back in time it goes. Can you set a reference point with this data, or do you have to find another dataset or other source of information to find a historical reference point?

> TIP: The only thing to do is remember that you are trying to capture ocean health--too far inland may no longer relate to ocean health.

<!---FIX: Does 1km land buffer make sense in this context? Should they extend this beyond maybe ~5km or more? It just depends on how Ecuadorians define ‘coastal’. Maybe 1km is too much? Maybe not enough? How do people interact with the ocean from onland? Maybe it’s only if you can see the water. Or maybe more. Maybe they could look at cultural sites on land that have been considered coastal and see how many km inland they are. Maybe they should clip as far inland as mangroves go, if these are special places. The only thing to do is remember that you are trying to capture ocean health: too far inland may no longer relate to ocean health. So maybe the idea of a constant buffer is a bad one, and follow the mangrove or saltmarsh lines, combined with other specific special places. But they can also just leave it and not worry about it. Might not be worth bringing up the debate now.
some history: the 1km buffer was used at the global scale because there was spatial data of parks on land, and we needed to exclude ones that didn’t make sense. but since they have a better knowledge of their coastlines and what’s important, they could ditch the buffers and just pick the ones that they know are important coastally.--->

<!---BUFFERS note: a common theme was ‘these are special areas inland, but they’re not considered by the index since they are >1km inland’. us: ‘but you can change that buffer. Define it as is important to you, to your interpretation of ocean health--->

#### Keep Reference Points in Mind
<!---Develop--->
The decisions on choosing a reference point will be a theme in each of the goal models you develop. The choice of a reference point will affect how the final scores are calculated, and will have to be balanced between limitations of the data and expert judgment to assess the conditions of the various dimensions of ocean health.

In addition to set values, such as maximum or minimum observed value, it's possible to use spatial reference points and temporal reference points. In spatial reference points, you find the highest-scoring region and say that it is perfect. It's also possible to set a different reference point for each region of your study area, as was done in the U.S. West Coast study (2014). Using temporal reference points, a historical benchmark is used as a the "ideal" point in the past. A third type of reference point is a policy-set target, such as a sustainable catch yield by a certain year, or the number of people employed in a marine sector by a certain year. In any case, you must balance being realistic with being ambitious. We suggest following the S.M.A.R.T. criteria when choosing a reference point--they should be "Specific," "Measurable," "Ambitious," "Realistic," and "Time-bound."

You will learn more, and think more critically about reference points, as you develop the data layers for your assessment.

## Practical Guidance

### Synergies: Data to Approach Together

Whether you are working goal-by-goal, or data layer by data layer, it is important to consider where you can find synergies in data discovery. For example, while you are looking for data layers for fisheries goals, you may also find data layers for fishing pressures, such as metrics on bycatch or trawling intensity. This will save you time and allow you to start thinking about how to rank pressures and resilience weights on your goals as well. Conceptually, it will help your team build a picture of how your goals are interlocking in a way that is reflective of the actual linkages that exist in the coupled human and natural systems you are studying. Some key examples are listed below, and are further explained in the following sections.

#### Do Habitat-Based Goals Together

You should do the habitat-based goals together. These include **Carbon Storage**, **Coastal Protection**, **Biodiversity: Habitats** in the Global Assessment. This will be more efficient because the spatial analyst can do the data manipulation to create the spatial layers that get used for these goals, based off the same source material. This will greatly expedite your data search, and layer preparation. If you wish to further coordinate these activities on a higher level, you could have the same team member coordinate activities for the development of these three goals.

> If you look at `functions.R`, you will see that the reason this is the case is because the data layer, `Hab_extent`, is used in multiple places in the software:

 * NP
* FIS
* CS
* CP

![Note that Habitat Extent appears in several goal model functions. ](https://docs.google.com/drawings/d/1HtrwjFi1Lod6B687nNTUPqK-MTAr9uwShooHUIu3Le4/pub?w=790&h=258)

#### Linkages: connections between pressures and goals

You should note the connections between your goals and the pressures and resilience that affect them.

For instance, you should do the fisheries goals and pressures together. The **Wild-Caught Fisheries** model uses functional relationships that rely on catch data, which may lead to information on commercial high- and low-bycatch. Bycatch data are used in the pressures layers and affect other goals such as, **Livelhoods and Economies** and **Biodiversity**, but perhaps not **Food Provision**, and so it will be good to think about those connections as you go through the data discovery process. <!--- @Julie is this the right place for 'the idea of greedy goals'?--->

Another example is how climate change impacts will appear in your assessment. Climate change pressures layers can include UV radiation, Sea Surface Temperature (SST), sea-level rise (SLR), ocean acidification. These impacts might affect such goals as **Natural Products**, **Carbon Storage**, **Coastal Protection**, **Sense of Place**, **Livelihoods and Economies**, and **Biodiversity**.

In the case of Global 2012, the **Clean Waters** goal is very much linked to the pressures because the same data layers for pressures are used as the input layers for the status. Note that because trash is also a pressure, it affects other goals as well, including **Tourism and Reacreation**, **Lasting Special Places**, **Livelihoods and Economies,** and **Species**.

These connections will become more clear as you go through the OHI+ assessment process.

### Practical Considerations for Habitat-based Goals

> Habitat-based goals can be approached together in the data gathering process. Habitats appear in such goals as **Carbon Storage**, **Coastal Protection**, and **Biodiversity**. Your approach will largely depend on the type of data you have.

*Ideal Approach*

Ideally, information on the extent and condition of every single habitat type would be available. The reference point for habitat-based goals will likely be temporal. This means that historic data are needed such that current habitat and value data can be compared to historic data. This could also be achieved by using or a proportion of historic data.

*Practical Guidance*

The first thing to consider with habitats is **what habitats are in your area**. You should consider what habitats are in your coastal regions as well as your offshore regions throughout your EEZ. Are there mangroves, coral reefs, seagrass beds, salt marshes, sea ice, or subtidal soft-bottom habitats? Are there kelp forests in your waters?

Once you determine what habitats are in your area, you should also consider **their range extent within your reporting regions**. You should consider whether and how far they go offshore and inland. You will likely use a combination of clipped spatial data and spatial data for whole regions, depending on the goal being assessed. For instance, the **Habitat** sub-goal of **Biodiversity** uses the entire region for habitats such as coral reefs in the calculation, but the **Coastal Protection** only uses the extent to 1 kilometer offshore and inland to 1 kilometer <!---Check---> This will affect the preparation of the spatial data layers later in you assessment.

> For instance, do mangroves occur in river deltas in your area, and if so, how far upriver do they go? In the 2013 Global Assessment, for example, mangrove was assessed from 1 kilometer offshore to 1 kilometer inland, but this distance is variable and could change for you OHI+ assessments. It depends on your geography.

Several factors for habitats will have to be considered. In score calculations, habitats are weighted in different ways based on the amount of protection they provide and the amount carbon they sequester, and they are also derived from estimations of habitat health and condition (See **Carbon Storage**, **Coastal Protection**, and **Biodiversity**). The weights of the habitats relative to each other comes from the literature. If you have access to regional-specific studies, you should use try to use that information. Otherwise, the Global data layers can be used as a secondary option.

When thinking about condition, for instance, coral health is based on the percentage of "living cover" on a reef relative to the potential range of the reef.

> In the Global Assessment, coral reference points used the mean predicted values for a country from 1985-1987. When this data was not available for a country, we used the value of neighboring countries. There was also some analyses to control for the fact that the % live coral cover naturally varies over time, hence the use of "predicted values".

> In the 2012 Global Assessment, soft-bottom habitat had an estimated status based on the "intensity of trawl fishing" as a proxy.

It is also important to think about the temporal aspect of your habitats. This will affect the **trend** and the choice of the **reference point**. Trend is the change in health or condition over time. However, this might be constrained by data availability due to the heterogeneity of habitat types and data sources. Ideally, there will be enough years of data to directly calculate the recent change in health of the habitat by using a linear model to calculate trend. This isn't always the case, and proxies or estimates might need to be used. For example, due to spotty salt marsh data we created trend categories of increasing (0.5), stable (0), and decreasing (-0.5) based on available data.

> For example, for sea ice in the Global Assessment, a linear model was set to a metric of sea ice cover for data from 2006-2011, after some smoothing to account for natural variation.

Overall, the historical **reference point** is particularly important for the habitat goals. What's the ideal reference point, however? You could consider setting the reference point further back in history if you have the data for it. This would assume there was a more pristine condition in the past, and would be based on the assumption that habitat destruction has been and still is occurring. Here it is useful to use the S.M.A.R.T. principles (See **Conceptual Guide**). It is highly encouraged to set an ambitious reference point, and deviate from those which were set in the Global.

****

#### Ready to start the **Carbon Storage** goal?

*Ideal Approach*

Ideally,  information would be available to allow you to to assess the amount of carbon stored in every coastal habitat in your area. The best information would show area covered and some measure of the quality of the habitat for this goal. For example, a dense mangrove forest would be better quality than a sparse mangrove forest. Additionally, different weights would be assigned to the habitats based on their relative ability to store carbon, and this factor could be used to penalize areas where there is greater loss of carbon and reward areas where this is a greater storage of carbon. The carbon storage model could then incorporate such weights in a similar way to the **Coastal Protection** goal. The reference point for habitat-based goals will likely be temporal in most cases. This means that historic data are needed so that current habitat values can be compared to a past state.

>TIP: Understanding habitat carbon storage rates is an area of ongoing research. The capacity for habitats to store carbon varies, and depends on the morphology of plants in the system.

*Practical Guidance*

The model and approach for **Carbon Storage** developed for the Global assessment will likely be appropriate for independent assessments. Knowing the area and the condition of of carbon-storing habitats are the two components that are most important. It is important to spend time looking for a way to quantify condition, but it may not be possible to find.

One of the first decisions for your team to make is **whether to use the given data** in the Global Assessments or **to find and use a better dataset**. Even though your goal model shouldn't change entirely from the Global, you should find more localized data than the global data, because the global data layers have already been processed and include clipped regions that reduce the specificity of the information for your area. This is because in the default WebApp methods, the habitat area was calculated by using the global areal coverage of the habitat weighted by the size of the offshore area of the region. This is not consistent currently in the WebApps; for example, if you look at [the given layers a WebApp](https://github.com/OHI-Science/col/blob/draft/subcountry2014/layers/hab_extent_gl2014.csv), you will see that the same values are applied to all regions. You should think here, however, of how your regions' size compare to any spatial dataset's scale, and return to the question of spatial coverage once you are thinking about the **reference points** farther on.

> Questions to consider: Do you have maps, for example, that show current habitat distributions and maps that show historical habitat distributions?  If so, you could extract that data for each of your regions to get a current and reference area. You could also use summarized habitat data that exists in tables or are already compiled in another source.

The types of habitat data you search for also matter. It is recommended to search for mangroves, saltmarshes, and sea grasses because these are viewed as carbon-sequestering habitats that are both ecologically threatened and sensitive to policy responses.  You should remember that we recommend using habitats that can store carbon on the order of 100 years, thereby limiting the types of habitat types you will need. This would also affect other kinds of indicator considerations not discussed in the Global Assessments, such as chlorophyll abundance.

> TIP:, if you look at your default data on the WebApp, you will see **Carbon Storage** information presented for **mangroves**, **salt marshes**, and **sea grass** even if there are no mangroves in your area. You will not be scored on these if they are not in your area.

The second group of items to consider are the **condition** and **carbon contribution**. **Condition** is more essential than **contribution** in this case because it is a more direct measure of ecosystem health and would give a more accurate score for this goal. **Condition** means . It can be measured by a number of ways, often indirectly through studies on density of the habitats, disease affecting the particular habitats, or other impacts such as change in species composition or growth rates from impacts such as overgrazing. Has there been a study assessing habitat integrity or health specifically in your area? **Contribution** is how much each habitat stores relatively to the others--such as the rates of carbon uptake as measured by empirical data. For this you would have to go to the literature and find ratios of organic nutrient uptake between habitats, and you would have to make sure these studies are done correctly to represent your area. For example, were the studies done with a young mangrove forest, or an older one, which might have different growth rates?

> In the 2012 Global Assessment, the condition of mangroves was assessed as, "Current square kilometers of mangrove coverage divided by the reference hectares, calculated from 1980 to 2005. Seagrass condition was calculated as, "Current percent cover, or hectares, of habitat divided by the reference percentage cover, or hectares from 1975 to 2010."  <!---See Table S7, Supplementary Information, Halpern et al. 2012, p. 24. Note that interestingly it does say salt marsh "condition" was calculated by an increasing or stable trend (value = 1), or by a decreasing trend (value = 0.5). Excluded it because it seems like an estimation.--->

A vital consideration for this goal is **the reference point**. It is an important decision to be made based on good science given the limitations of available data. The reference point is the extent of the habitat at some time in the past, in other words the ideal condition. You will need historical data for this--either from satellites, published papers, or even hand-drawn maps. For questions of sustainability, you must consider, what is a good year to set as your historical past extent? The reference year should be identified based on SMART principles, particularly that it is an ambitious goal, but also realistic. If you do not have trend data, you will have to use a proxy for the trend.

> In the U.S. West Coast assessment (2014), researchers went to the local public library to find hand-drawn maps of historical salt marsh extents in California.

In this case, perhaps your choice of historical reference point may be guided by a policy target as well. For example, are there any climate change policies in your area, with defined targets and objectives? Are there any restoration or carbon storage projects in your area? Do any organizations offer guidance on the amount of carbon storage your management policies should be aiming for?

#### Ready to start on **Coastal Protection**?

> **Coastal Protection** aims to assess the amount of protection provided by marine and coastal habitats against flooding and erosion to coastal areas that people value.

*Ideal Approach*

Ideally, data for all habitats within a region would be available, as well as information on the value of the land and the vulnerability of inhabitants being protected by these habitats. This requires data for habitat type at high spatial resolution  as well as a measure of the value of what is protected by the habitats. The reference point for habitat-based goals will likely be a temporal baseline; this means that historic data are needed such that current habitat and value data can be compared to them.

*Practical Guidance*

The areas relevant to this goal include both inhabited places, such as homes and other structures, and uninhabited places such as parks and special places. However, no credit is given for sea-walls, because they are not regarded as sustainable. At local and regional scales data may exist on all these variables at a high enough resolution to map and calculate exactly which habitats are providing how much protection to which coastal areas. You must first decide which data sources to use for your maps. Do you have spatially-explicit satellite data? If so, how far back in time does it go? The data consideration will be a consideration when you set the reference points.

> In the U.S. West Coast assessment (2014), researchers went to the local public library to find hand-drawn maps of historical sand-dunes in California, for example, in order to find information for sand dune extent in the 1850s.

In addition, one might want to know the level of vulnerability of the different coastal communities. Vulnerability can be quantified as the ability to evacuate, fragility of constructions, economic ability to reconstruct in case of damage. The the reason this is done is to prioritize the protection of certain locations. Physical properties may be available in regional studies, allowing for more a detailed understanding of the protective ability, and likelihood of exposure for each habitat type in different portions of the coastline.

As with the other habitat-based goals, you will need to make careful decisions about your reference point. It's an important decision to be made based on good science given the limitations of available data. The reference point is the extent of the habitat at some time in the past, in other words the ideal condition. You will need historical data for this--either from satellites, published papers, or even hand-drawn maps. For questions of sustainability, you must consider, what is a good year to set as your historical past extent? Do you want to be ambitious and set it far in the past, so it gets closer to a more "pristine" condition? Or do you want to make it represent human use? Will it make your scores look better or worse if you choose a more recent or more distant example?

#### Linking Habitats and Biodiversity

It is important to think about how habitat relate to the **Biodiversity** goal. The current approach tracks **Species** and **Habitats** separately because of imperfect data for **Species**. In other words, habitats are an estimation of the health of the species in an area. Therefore if you have comprehensive species assessments in your area you wouldn’t need the **Habitat** sub-goal. However, the inventory of marine biodiversity may not often be sufficiently complete in your area.

You should also think about the linkages between the habitat-based goals, such as **Carbon Storage** and **Coastal Protection**, and the pressures and resilience. Does the encroachment or reduction of these habitats have an effect on carbon sequestration, or does it change ecosystem composition sufficiently to impact species? Could habitats have an effect on **Clean Waters**, or are they impacted more by local pollution than other impacts? If habitats change for natural reasons, you might not need to worry about their pressures on other goals, but if they consist of introduced species, you should think about the effects on other goals.

> For example, the invasive marsh plants such as *Spartina* may afford some Carbon Storage, but it’s a non-native habitat to an area such as the San Francisco Bay. It could still count towards the **Carbon Storage** goal, but would also be a pressure on **Biodiversity**.


#### History of the Approaches

*Carbon Storage Goal*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | The status of Carbon Storage is measured as a function of its current ‘condition’ relative to a reference condition and a variable that weights the relative contribution of each habitat type to total carbon storage (measured as the amount of area each habitat covers relative to the total area covered by all three habitats given the available data). In Global 2012, the coastal ecosystems assessed were seagrasses, tidal marshes and mangroves.<br  /><br  />Reference conditions were set as the current condition or area of coastal plant habitat coverage relative to that in ~1980. This is not a very ambitious reference point, but the best that the data would allow. | We focused on three coastal habitats known to provide meaningful amounts of carbon storage: mangroves, seagrasses, and salt marshes. For mangroves, we included the whole extent of the coastal forests, including the parts on land or in river deltas, since these too provide significant additional amounts of carbon storage. | A score of 100 would indicate that the percent cover (and health, when measured) of each habitat had not changed since the date set as reference point (the 1980s or pre-industrial coverage, depending on the assessment used).
**Global 2013** | The goal model and reference point were the same as in Global 2012. There were improvements in data processing were.<br  /><br  />The reference point was the same as Global 2012. | Mangrove data used in the goal model were processed differently than described in Global 2012: data now include 1km inland in addition to 1km offshore. |
**Brazil (2014)** | The goal model was the same as in Global 2012.<br  /><br  />The reference condition was determined specifically for each habitat type. For salt marshes the reference year is 1975. For mangroves, we knew the current (2010) extent per state, but only had a total country extent for the reference year (1980). We apportioned the total reported mangrove extent for Brazil in 1980 by state using a linear regression model that estimates the percent of mangrove loss per state. Data to assess current and reference condition for seagrasses did not meet minimum data requirements: they were available only for three sites in Brazil within the time period 2002-2010 (no data for a reference condition). For this reason, we used available data from adjacent EEZs (countries in the South Atlantic) and used georegional averages as current condition and reference condition values for Brazil. A linear model was fitted to the data for all countries, and the mean of predicted values for 1979-1981 was used as the reference condition, and the mean of predicted values of the three most recent years (2008, 2009, 2010) was used as the current condition. | The same approach was used as in Global 2012, with local data used as available. |
**U.S. West Coast (2014)** | We used reconstructions of historic extents compared to current habitat coverage to set more ambitious targets. However, the historical reconstructions did not include information on habitat health so only extent was used in this assessment.<br  /><br  />Reliable, comprehensive habitat extent data prior to the 1990s are unavailable for most coastal regions within the U.S. Estimates of habitat loss since European settlement have been extrapolated in some regions for some habitats. However, while the habitat extent from the 1990s would represent a very un-ambitious target, a pre-industrialized reference point for habitat extent is considered an unrealistic goal under current conditions. To establish our temporal reference points we instead set our reference uniquely for each habitat, as a percentage of pre-industrialized habitat coverage for salt marshes, as habitat extent between the 1950s and 1960s for sand dunes, or utilized pressures on habitats as a proxy of habitat condition for seagrasses and soft bottom habitats. | Only two out of the three habitats considered in the global analysis were included here: salt marshes and seagrass beds. Mangroves are not found in the US West Coast and are not included in this assessment. |

*Coastal Protection Goal*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | The status of this goal was calculated to be a function of the amount and/or condition (depending on data availability) of marine habitat(s) relative to their reference states and the ranked protective ability of each habitat type. Rank weights for the protective ability of each habitat come from previous work that ranks mangroves, corals and sea ice as 4, salt marshes as 3, and seagrasses as 1, where higher values are better.<br  /><br  />The reference point compares the current extent and condition of five key habitats that protect coastlines (mangrove forests, seagrass meadows, salt marshes, tropical coral reefs, and sea ice) from flooding and erosion relative to their condition in the early 1980's. | At global scales, fine-scale habitat data do not exist and so we focused on EEZ-scale assessments, even though this scale does not allow one to account for the spatial configuration of habitats relative to coastal areas and the vulnerability of human coastal communities. Consequently, we assumed that all coastal areas have equal value and equal vulnerability and assessed the total area and condition of key habitats within each EEZ (without regard to their precise location). The habitats that provide protection to coastal areas from inundation and erosion and for which we have global data include mangroves, coral reefs, seagrasses, salt marshes, and sea ice. | A score of 100 would indicate that these habitats are all still intact or have been restored to the reference condition (i.e. their extent during the early 1980’s if using Global 2012, or 50% of their extent for some of the habitats in US West Coast, etc.). Any score below 100 indicates that these habitats have declined in coverage or in health since then, with lower scores indicating more significant declines, and stronger penalties for declines in habitats with high protection ability (e.g. mangroves in Global 2012).
**Global 2013** | The goal model and reference point were the same as in Global 2012. | Same as Global 2012. |
**Brazil (2014)** | Same goal model as Global 2012, using local data.<br  /><br  />To calculate the reference state for coral reef status within Brazil we lacked a minimum of two data points within the time period 1980-1995 (which was considered the acceptable range to use as “reference” years). We therefore estimated the status as the averages of scores from 24 countries within the Caribbean ecoregion that had sufficient coral data. For each of those countries, we fitted a linear model to the data available, pooled across all sampled sites, and we defined the ‘current’ condition (health) as the mean of the predicted values for 2008-2010, and the reference condition as the mean of the predicted values for 1985-1987. | Area was measured for each coastal state as the 12 nmi jurisdiction boundary for each habitat type. For mangroves we focused only on the most coastal portion of mangrove forests as they are the main source of coastal protection. For seagrasses we used the total reported extent of seagrasses in Brazil divided by the coastal area of each state. For coral reefs we calculated the extent per coastal waters of each state using maps of coral reef distribution. The salt marsh extents for Santa Catarina and Rio Grande do Sul states are from national statistics. |
**U.S. West Coast (2014)** | Same as Global 2012, with more ambitious reference points for target habitat coverage.<br  /><br  />Reliable, comprehensive habitat extent data prior to the 1990s are unavailable for most coastal regions within the U.S. Estimates of habitat loss since European settlement have been extrapolated in some regions for some habitats. However, while the habitat extent from the 1990s would represent a very un-ambitious target, a pre-industrialized reference point for habitat extent is considered an unrealistic goal under current conditions. To establish our temporal reference points we instead set our reference uniquely for each habitat, as a percentage of pre-industrialized habitat coverage for salt marshes, as habitat extent between the 1950s and 1960s for sand dunes, or utilized pressures on habitats as a proxy of habitat condition for seagrasses and soft bottom habitats. | In the U.S. west coast we measured the role of salt marshes, seagrasses, and sand dunes as these habitats provide the most significant and measurable amount of coastal protection and had data available to include. |

*Habitat sub-goal of Biodiversity*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | The status of the Habitat sub-goal was assessed for all habitats for which at least some global data were available, specifically: mangroves, coral reefs, seagrass beds, salt marshes, sea ice edge, and subtidal soft-bottom habitats. Status was assessed as the average of the condition estimates for each habitat present in a region.<br  /><br  />In the global study, the current condition of salt marshes, seagrasses, mangroves and corals was compared to a reference year that is intended to represent optimal conditions (1980 for salt marshes and sand dunes, varied by site for seagrasses). We generally considered the reference years to be between 1980-1995 and the current years to be between 2001-2010, although these varied by habitat due to data availability. | A significant amount of pre-processing of the habitat data was needed to fill data gaps and resolve data quality issues (see the data layers section for details on data sources). Because consistent habitat monitoring data were unavailable for many regions, anomalous values can occur. | A score of 100 would indicate that habitat coverage had not reduced when compared to the temporal reference point.
**Global 2013** | The goal model and reference point were the same as Global 2012. | The approach was the same as Global 2013. |
**Brazil (2014)** | The goal model was the same as as Global 2012 for mangroves, coral reefs, seagrass beds, salt marshes, and subtidal soft-bottom habitats.<br  /><br  />The timeframes between current and reference condition vary across habitats, but we generally used a 20-year gap. However, it is important to bear in mind that we were able to obtain only a few time-series in which habitat health was resampled through time, so that information from a few point estimates had to be used to infer the health of a large and highly heterogeneous region. | The approach was the same as Global 2012. |
**U.S. West Coast (2014)** | Same as Global 2012 for salt marshes, seagrasses, sand dunes, and soft-bottom habitats. Additionally, when assessing habitat condition, we used reconstructions of historic extents to set more ambitious targets.<br  /><br  />To establish our temporal reference points we instead set our reference uniquely for each habitat, as a percentage of pre-industrialized habitat coverage for salt marshes, as habitat extent between the 1950s and 1960s for sand dunes, or we utilized pressures on habitats as a proxy of habitat condition for seagrasses and soft bottom habitats. | Reliable, comprehensive habitat extent data prior to the 1990s are unavailable for most coastal regions within the U.S. Estimates of habitat loss since European settlement have been extrapolated in some regions for some habitats. However, while the habitat extent from the 1990s would represent a very un-ambitious target, a pre-industrialized reference point for habitat extent is considered an unrealistic goal under current conditions. To establish our temporal reference points we instead set our reference uniquely for each habitat, as a percentage of pre-industrialized habitat coverage for salt marshes; and as habitat extent between the 1950s and 1960s for sand dunes. We utilized pressures on habitats as a proxy of habitat condition for seagrasses and soft bottom habitats. |

****

#### Practical Considerations for Species Goals

#### Comparing **Biodiversity, Species** and **Iconic Species**

> In the Global Assessments, the **Species** sub-goal for **Biodiversity** and the **Iconic Species** sub-goal for **Lasting Places** make use of related data sources.

#### *Ideal Approach*

Ideally, you would find data for all species present in your region including information on their habitat ranges along with scientific studies that speak to the health of their populations. You would also ideally have a list of species that are valued as 'iconic' by coastal communities as a subset of the list of species that are present in your area. Since different species are be iconic to different groups, defining which species are iconic can be challenging when it's a cultural question--you might have to find information from experts or local customs and tradition.

#### Ready to start on species goals?

You should start by trying to **find spatial information for species that occur in your area and determine whether or not they have been scientifically assessed and given a conservation status**. For the **Biodiversity** goal, it is important to note that you can only use species for which there are both spatial data and an assessment. The International Union for the Conservation of Nature (IUCN) provides global species assessments that indicate the conservation status of species. These range from species of "Least Concern" to "Critically Endangered" to "Extinct." You can turn values like as these into numbers and use them as weighting factors in your calculations. You should use unbiased scientific data sources where possible. [AquaMaps](http://aquamaps.org/) offers data for species ranges that have also been used in the Global Assessments. However, good marine species data are lacking at global scale and so wherever there are [spatial data from IUCN](http://www.iucnredlist.org/technical-documents/spatial-data), the Global Assessments prefer it over AquaMaps. For regional assessments, local studies of marine species status and local datasets are best here. The spatial information can be a range map with simple presence or absence information, or it can have more detailed data. You can complement the species list search with a scientific literature search to see if anyone has scored the species status in a way that you can use.

>For example, the OHI Antarctic Seas Assessment (2014) assessed thirty-five iconic species. These included bowhead, minke, fin, gray, and humpback whales, and polar bears. Walruses were not included in the High Seas Assessment because they were determined to be data-deficient by the IUCN.

Once you have the full list of assessed species, you need to determine a subset for the **Iconic Species** sub-goal of **Sense of Place**. Choosing iconic species is not a fixed process, so you may have to consider multiple approaches. For instance, are there known "indicator species" in your area? Are there species that are culturally held as valuable? Do any species appear on the currency or postage stamps? In practice, **Iconic Species** are usually a subset of the broader list of species in an area, and so you should be able to find **Iconic Species** after having found assessed species data for the **Species** sub-goal of the **Biodiversity** goal first.

Alternatively, you can figure out which iconic species are present, and then use another kind of assessment approach to see if the populations are healthy, which could be indicated, for instance, by the stability of their populations. The approach you take will depend on the data you find.

> Often, local experts are consulted to determine what **Iconic Species** are in an area. In the Fiji Assessment (2014), regional experts identified thirty-three species. In the U.S. West Coast study (2014), local experts identified seventeen species. You could also pursue more creative approaches way to think about these species. You could think think about what kinds of animals or plants would appear on local stamps, currency, or even flags. In any case, the choice of species has already been made by a community.

The choice of inclusion of iconic species in your list can be a subjective judgment. You could also come up with specific inclusion criteria, for instance, that would filter a list of species or filter a subset of the gathered data for **Biodiversity**, and then you could use this new list in the **Sense of Place** goal. This would be a more rigorous approach because then it could be documented and you could replicate the study in future assessments.

#### Map Considerations

Once you have gathered the data, the treatment of it will matter for the model and goal score calculation. The treatment will be both scientific and philosophical. Do you know how the data were collected? Do you have information on sampling effort? If you don't know, you may not be sure whether changes in condition are due to monitoring efforts or biodiversity change, and you therefore may want to consider the uncertainty of your model.

In any case, the original logic of the **Species** sub-goal of the **Biodiversity** goal is to represent the species present relative to the proportion of their range within a given region. The goal is to summarize extinction risk for an area across assessed species, and assign it appropriately so that the loss of species scores poorly. You should consider whether the impacts to local species status are linear or non-linear. Will drawing borders affect how your scores are assigned? You may also want to avoid making the scores low for a region in the case where a very small portion of the range comes from a highly threatened species, or, you may wish to err on the side of higher caution.

When considering how to change the model, you should think about the outcome of the score on your decisions. For instance, will weighting a "Critically Endangered" species higher on the scale result in the inclusion or exclusion of more rare species? Will the way you aggregate spatial data to summarize extinction risk for your area take into account the influence of species with smaller ranges size, or will that information be lost in the averaging process? An inherent disadvantage for conservation may occur when rare species get rarer in the future, and will therefore have a relatively small influence on the score while common species drive the results.

> Range size has an impact on score results. For example, if you use the current model, none of the cone snail species listed below will have a big impact on the **Species** sub-goal score because to their small range size that covers one cell of map area. However,  the 0.8 score for *Conus roeckeli* shows that it is a rare species as assessed by the IUCN. On the other hand, the coral *Acropora palmata* is also rare and yet covers a large range.

Scientific name | IUCN Category | Trend | Map Cells
---------------|-----------------------------|-------------------|----|
*Conus salreiensis* | Critically Endangered |  Decreasing | 1
*Conus trochulus* |  NearThreatened |  Unknown | 1
*Conus roeckeli* | Least Concern | Unknown | 1
*Acropora palmata* | Critically Endangered | Stable | 1158

When considering how to change the model, you should think about the outcome of the score on your decisions. For instance, will weighting a "Critically Endangered" species higher on the scale result in the inclusion or exclusion of more rare species? Will the way you aggregate spatial data to summarize extinction risk for your area take into account the influence of species with smaller ranges size, or will that information be lost in the averaging process? An inherent disadvantage for conservation may occur when rare species get rarer in the future, and will therefore have a relatively small influence on the score while common species drive the results.

You should also think about the reference point for scores that signal poor **Biodiversity** status. You can use the same threshold as the Global Assessments which say that places with extinction risk scores greater than seventy-five percent will get scores of zero. This is an estimation based on the literature of mass extinctions (e.g., Barnosky *et al*., 2011) and could be applied across scales. You don’t need all species extinct for there to be a zero, so you will have to choose how to rescale it, and whether the risk effects are linear or nonlinear.

#### History of the Approaches

*Species sub-goal of Biodiversity goal*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | For the Species sub-goal, we used recent assessments by the International Union for Conservation of Nature (IUCN)- Global Marine Species Assessment of the extinction risk status of 2377 species for which distribution maps also exist across a wide range of taxa to provide a geographic snapshot of how total marine biodiversity is faring, even though it is a very small sub-sample of overall species diversity. The status of assessed species was calculated as the area- and threat status-weighted average of the number of threatened species within each 0.5 degree grid cell. Species distribution and threat category data came from the IUCN Global Marine Species Assessment results.<br  /><br  />The target for the species sub-goal is to have all species at a risk status of Least Concern. We scaled the lower end of the biodiversity goal to be 0 when 75% species are extinct, a level comparable to the five documented mass extinctions and that would constitute a catastrophic loss of biodiversity. | We did not include ecological integrity measures as they are based on the same data used to calculate Status and Trend. | A score of 100 would indicate that over 75% of species have a ‘least concern’ risk of extinction.
**Global 2013** | The goal model and reference point were the same as Global 2012. | Updates were available for data used for this goal.  It is important to note that extinction risk estimates for significantly more species were released in the past year, such that the scores needed to be updated for this sub-goal (and therefore the biodiversity goal overall) for 2012 to reflect improved reporting of species assessments (e.g., data quality). Actual changes in risk status from last year to this year occurred for only 15 of 6080 species, primarily because species are rarely re-assessed; in other words, only when species are reassessed can the status score of this sub-goal change. |
**Brazil (2014)** | The status of assessed species was calculated as the threat status-weighted average of all species occurring in the Brazilian EEZ (we did not weight by area of occurrence as in Global 2012 because distribution maps were not available for all species at the time of this assessment). The sub-goal was therefore calculated at the national level, giving equal weight to all species occurring in Brazilian waters. Threat weights were assigned based on the IUCN threat categories status of each species.<br  /><br  />The reference point was the same was Global 2012. | A list of marine species that occur in Brazil and were evaluated globally under the IUCN Red List assessment process was combined with a list of species assessed regionally in Brazil using the same criteria (Brazilian Red List assessments from Chico Mendes Institute for Biodiversity Conservation; see Data Layers). We substitute global assessments for regional (Brazil-specific) assessments whenever these were available. We had assessments for a total of 504 species. |
**U.S. West Coast (2014)** | The model description and reference point were the same as Global 2012, with regional data available for threat categories. | Data were available at a regional scale, but the approach was the same as Global 2012. |

*Iconic Species sub-goal of **Special Places***


Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | Status of this sub-goal is the average extinction risk of iconic species, calculated as the weighted sum of the number of species in each threat category, where an increasing weight is assigned by level of extinction risk of the threat category. This formula penalizes the gravity and number of species endangered among those recognized as iconic.<br  /><br  />The reference point is to have the risk status of all assessed species as Least Concern, meaning that the species is at lowest risk of extinction.  Species that either have not been assessed or are labeled as data deficient are not included in the calculation. | To define the list of iconic species for each region, we compiled lists of region-specific iconic species combined with lists of globally-recognized iconic species to create the total list of iconic species per region. Species were drawn from the World Wildlife Fund’s global and regional lists for Priority Species (especially important to people for their health, livelihoods, and/or culture) and Flagship Species (‘charismatic’ and/or well-known). Ultimately, almost any species can be iconic to someone, and so the intent with this goal was to focus on those species widely seen as iconic from a cultural or existence value (rather than for a livelihoods or extractive reason). Many lists exist for globally important, threatened, endemic, etc. species, but in all cases it is not clear if or to what extent these species represent culturally iconic species. The lists we used from World Wildlife Fund are the only source that included cultural reasons for listing iconic species but they only cover a few regions and by no means capture the rich diversity of species that are iconic for local regions, communities, religions, tribes or other groups elsewhere. Collecting data at those scales would be a very important advance forward.<br  /><br  />Habitat-forming species are not included in this definition of iconic species, nor are species that are harvested solely for economic or utilitarian purposes (even though they may be iconic to a sector or individual). | A score of 100 would indicate that all species are in the threat category equivalent to ‘least concern’.
**Global 2013** | The methods and reference point were the same as Global 2012. | The approach was the same as Global 2012. |
**Brazil (2014)** | The methods and reference point were the same as Global 2012. | The approach was the same as Global 2012. |
**U.S. West Coast (2014)** | To assess the status of these iconic species within the region we used the same methods outlined in Global 2012, but replaced the global IUCN risk assessments with regionally specific species assessments provided by NatureServe.<br  /><br  />The reference point was the same as Global 2012. | Same as Global 2012, with regional data for the threat categories. |

***

### Practical Considerations for Sense of Place

#### Ready to start on the **Lasting Special Places** sub-goal of the **Sense of Place** Goal?

> Remember, **Sense of Place** has another sub-goal, **Iconic Species**, which is described in the *Species goals* section.

*Ideal Approach*

Ideally, you would be able to produce a list of all the places that people within your region consider special, and then assess how well they are protected. How well they are protected could be the percentage of area protected, and you could also find how well they are protected using other data. This sub-goal could also be based on the extent to which people partaking in spiritual or religious activities are able to access special places.

*Practical Guidance*

It is important to think about how this goal can be tailored to your region. This sub-goal is intended to be meaningful and specific to your location. Keep in mind, however, that it is a difficult goal to express accurately, since it attempts to capture how people interact culturally with their coastal places.

> In the U.S. West Coast assessment (2014), **Special Places** was one of the most important goals. At the end of the day, how people interact with ‘their ocean’ is fundamentally important to whether they think oceans are healthy or not.

The main consideration for this sub-goal is the spatial data and the list of protected areas. Typically in assessments, the area of designated protected places relative to a target of thirty percent coastal area protected is used as a measure. Coastal area could be based off a 1 km^2 buffer, as in the Global Assessment, or it could be based on what is reasonable to your area; in any case, you would want to consider how far out from shore you should include as well; would it be 3 nautical miles, or as far as your territorial waters up to 12 nautical miles?

> In the Brazil Assessment (2014), the **Lasting Special Places** sub-goal was assessed using a national database of protected areas that included fully-protected and sustainable use designations at federal, state and municipal levels, and included indigenous lands. The highest-scoring area contained the largest continuous extent of protected areas within the country in what is called the Biodiversity Corridor of Amapa´.

Data sources should be specific to your region. International databases, like the World Database of Protected Areas, offer rich information, but they may not be as up-to-date as the list of national parks in your area, and may not have as much information on the quality of protection. If you have more information on quality, you could think about another approach than the thirty percent reference point target.

*Thinking Ahead*

You should be thinking about **Resilience** at the same time as you think about **Lasting Special Places** sub-goal of **Special Places**. This is because the **LSP** sub-goal makes use of protected areas, and some of the same information gathered on projected areas can be used to create resilience data layers like Marine Protected Areas (See section, **Pressures and Resilience**).

Once you area ready, you should return to the **Iconic Species** sub-goal of **Lasting Special Places** and think about how to combine the two together. Do you want to use equal or unequal weighting? How do the two components relate to each other?

> In the Global Assessment framework, the **Special Places** sub-goals were weighted equally and combined in an average to create a single goal score. The two sub-goals are averaged currently in the framework. But these could be combined with a weighted average, or even a different sub-goal instead of **Sense of Place**.

#### History of the Approach

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | The status of this sub-goal is calculated by combining the percent of coastal waters that are coastal marine protected areas and the percent of coastline that is protected. Both sea and land components are compared to a target (reference point) of 30% protection.<br  /><br  />Using lists of protected areas as the catalogue of special places then creates the problem of determining a reference condition. We do not know how many special places have yet to be protected, and so we end up having all identified special places also being protected. To solve this problem we make two important assumptions. First, we assume that all regions have roughly the same percentage of their coastal waters and coastline that could qualify as lasting special places. In other words, they all have the same reference target (as a percentage of the total area). Second, we assume that protecting 30% of the coastal area is a target that allows protecting enough lasting special places to achieve the goal. | This sub-goal is particularly hard to quantify, because there are no lists of marine places protected especially for their cultural, spiritual, aesthetic or related intangible values.  Ideally one would survey every community around the world to determine the top list of such special places, and then assess how those locations are faring relative to a desired state (e.g., protected or well managed), but in the absence of such lists we assume areas that are protected for other reasons (e.g. MPAs, reserves, historical areas, World Heritage sites, etc.) represent these special places (i.e. the effort to protect them suggests they are important places) and that in each region there are enough special places to cover at least 30% of the coastal strip. Clearly this is an imperfect assumption, but in many cases it was true so that it did not prove unrealistic. | A score of 100 would indicate that 30% of the waters and land immediately adjacent to the coast is protected.
**Global 2013** | The model and reference point were the same as Global 2012. | The approach was same as Global 2012 |
**Brazil (2014)** | The model and reference point were the same as Global 2012. | The approach was same as Global 2012 |
**U.S. West Coast (2014)** | The model and reference point were the same as Global 2012. | This approach also focuses on the protection status of all marine and coastal areas as was done in the global assessment, under the assumption that efforts to protect places suggest that they are significant to people. We recognize that for some individuals, placing regulations on an area to protect it may prevent them from the very activities that made those places special to them in the first place, such that higher protection may not represent a healthier state in their view. However, we use this approach here because data exist to calculate it and because, although imperfect, it does convey some information about lasting special places. If a place is special and appropriate regulations/protection are placed on that location (for example, limited access, restrictions or limits on uses such as fishing, etc.), we feel that this ensures long-term sustainability of a place people care about. |

***

#### Practical Considerations for Natural Products

> The **Natural Products** goal describes how sustainably people harvest non-food products from the sea.

#### *Ideal Approach*

Ideally, quantity, value, and a sustainability rating of the harvest method would be available for every marine and coastally-derived natural product within the regions of a study area. This could include a wide range of products depending on what is harvested in the study area, including corals, shells, seaweeds, aquarium fish, mangrove wood, or any non-food marine product that is harvested within a region. The ideal reference point would be derived from a functional relationship of the sustainability of the harvest for each product relative to the amount of product available in the ecosystem, informed by scientific studies. Without such information, assumptions and expert judgment will need to be made to set the reference point.

#### Ready to start on **Natural Products**?

Whether you use the approach from the global assessment or are developing your own new model entirely, there are a few tasks that will remain the same because are key to the philosophy of this goal.

The first is to identify **identify which products are in your study area.** For example, does your study area have corals, ornamental fishes, sponges? Does your area yield medicines from the sea, or other products that are not used for nutrition under **Food Provision**? Does your area harvest drinking water from the ocean through desalination plants? Is there a kelp or seaweed industry in your area? If there are multiple uses of the product, you must also consider what proportion of the product is used for food, and what proportion is used for other purposes. As another example, oil from marine mammals was considered but excluded from the global models, but if a region has a considerable amount of mammal oil harvest, they should include it in the calculation, keeping in mind that the sustainability of this type of harvest is likely to be low and should be reflected in the score.

The second task is to think about **where these products are harvested and how much of them are harvested** in these areas through a period of time. You should find spatial representation of these products, which can be done by knowing where they are derived from. Do they come from certain habitats (in the case of coral) or animals (in the case of fish oil)? This information will help calculate the sustainability of the harvest of eah natural product.  harvest amounts and the spatial data are used to calculate **exposure** further on, and can also be used to set the **relative weighting** between the products. These spatial data may have already been used in other goals, or they may lead you to find useful data that can be used in other parts of the assessment (See **Best Approaches**).

The second task is to think about **where these products are harvested and how much of them are harvested** in these areas through a period of time. You will have to assign geographic representation of these products, which can be done by knowing where they are derived from, ideally, or by assigning relative weightings. Do they come from certain habitats (in the case of coral) or animals (in the case of fish oil)? This information will help calculate the sustainability of the harvest of eah natural product.  harvest amounts and the spatial data are used to calculate **exposure** further on, and can also be used to set the **relative weighting** between the products. These spatial data may have already been used in other goals, or they may lead you to find useful data that can be used in other parts of the assessment (See **Best Approaches**).

The third component is to try to find the **sustainability** coefficients of the identified products. It is possible to measure sustainability in a number of different ways. Quantitative information can be used, or expert judgment, perhaps based on information or rough estimates of how sustainable the harvest method is, which is what was done in Global 2012. We based the sustainability component on the historical maximum harvest recorded, the maximum harvesting density recorded, and risk status assessments by the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES).  In the absence of these, we borrowed general principles from fisheries models to provide rough estimates. If these are given values you could simplify the model, or they could be derived from two factors, **exposure and risk**. The **exposure** will come from the spatio-temporal harvest amount data already prepared, and the **risk** will come from the scientific literature or a developed indicator. For both of those cases, the values can be calculated in separate equations as part of your data preparation process.

![Natural Products goal model from OHI Global Assessment 2013](https://docs.google.com/drawings/d/1JFU166u9J8-bYDxeEJPKoZjHOnUtOsz4GlsxlMgKsQo/pub?w=594&h=100)

> Global assessments borrow principles from fisheries science to make estimates of product sustainability. In the Global 2013 assessment the sustainability component was derived from the historical maximum harvest recorded, the maximum harvesting density recorded, and risk status assessments by the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES).

One very important thing to consider at this point is your **reference point for the relative harvest amount**. The relative harvest of your data is multiplied by the sustainability coefficient in the last step. Setting the reference point is a decision your team must make based on the available data and an inferred functional relationship between the harvest of the product and the amount in the system. Understanding the patterns in harvest can help inform how to set the reference point. For example, knowing whether harvesting effort was constant or whether product yields changed due to the market demand and not the availability. This information could help inform whether it is more appropriate to set the reference point as the peak yield of the time-series, or some percentage above or below, or some other approach that is both ambitious and realistic (**SMART** principles). The decision you make for the reference point should be based on the trend of the data; for instance, if your harvests have only increased over time, which may be indicative of an emerging economy, you will have to account for that.

One very important thing to consider at this point is your **reference point for the relative harvest amount**. The relative harvest of your data is multiplied by the sustainability coefficient in the last step. Setting the reference point is a decision your team must make based on the available data and an inferred functional relationship between the harvest of the product and the amount in the system. Understanding the patterns in harvest can help inform how to set the reference point. For example, knowing whether harvesting effort was constant or whether product yields changed due to the market demand and not the availability. This information could help inform whether it is more appropriate to set the reference point as the peak yield of the time-series, or some percentage above or below, or some other approach that is both ambitious and realistic (**SMART** principles). The decision you make for the reference point should be based on the trend of the data; for instance, if your harvests have only increased over time, which may be indicative of an emerging economy, you will have to account for that. <!--Added explicit case where only increase in trend. I think having a graph of harvest yields as a time series, by product, would be a helpful visual.-->

Example: The Global assessment used the following information in the Natural Products equations:

product | relative tonnes (1) | weighting (2) | Exposure (3) | Risk (4)
----------|---------------------|-------------|--------------|------
coral | FAO |  FAO | coral habitat | all 1
sponges | FAO | FAO | coral + rocky reef habitat | all 0
ornamentals | FAO | FAO | coral + rocky reef habitat | 1 if blast/cyanide fishing, otherwise 0
fish oil | FAO | FAO | fish score/100 | --
shells | FAO | FAO | coral + rocky reef habitat | all 0
seaweeds | FAO | FAO | rocky reef habitat | --

#### History of the Approach

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | For the status of each product, we assessed the most recent harvest (in metric tons) per region relative to a fraction of the maximum value (in 2008 USD) ever achieved in that region. This was under the assumption that the maximum achieved at any point in time was likely the maximum possible, and that the sustainable maximum harvest was lower than that value, similarly to what is known about maximum fisheries harvests (Srinivasan et al., 2008). The status for each natural product category is calculated separately and then combined by weighting each category by the proportional value of that product relative to the total value of all products. Part of the status calculation for each product category is a measure of sustainability; the goal captures exposure, risk, and viability of harvesting the product.<br  /><br  />The reference point for Natural Products was based on the fisheries concept of maximum sustainable yield (MSY), applied to the extraction of natural products. MSY was assessed for each type of product quantified globally, and a temporal (historic benchmark) reference point for each product was defined as 35% below the maximum harvest that had been produced to date in the region being evaluated. The 35% buffer protects against the possibility that the maximum historical harvest was not sustainable. A high score indicates that a region’s current sustainable rate of harvest is near to and not more than 65% of the historic maximum possible sustainable harvest achieved in that region. | Natural products data were available for coral, ornamental fish, fish oil, seaweeds and marine plants, shells, and sponges from the UN FAO. Using these data, we weighted each category by the sustainability of harvest. We did not have data for other key natural products such as wood from mangroves, and we excluded oils from mammals as they are widely seen as (currently) unsustainably harvested due to low mammal populations. Mammal oils represented a small (~<2%) and decreasing amount of total oil harvest each year (since 1993 it has been well below 1%), although for some regions it remains a significant percent of total oil harvested. | A score of 100 would indicate that a region’s natural product yield equals 65% of its historic maximum. A low score indicates that a region has the potential to improve sustainable harvests of natural products, either by eliminating overharvesting, increasing harvests that are too low, or reducing the pressures that decrease potential harvests. The more natural products extracted sustainably, the higher the score, provided that the harvest does not exceed the 65% precautionary level.
**Global 2013** | The goal model and reference point had the same approach as Global 2012, although the data processing did change | We used the same data and basic approach as for Global 2012, but developed several methods to fill gaps in data that resulted from inconsistencies in the data reported to FAO. In particular, many regions only report either data on harvest or on the monetary value of each product for a given year, but not both. Since the score is computed as a weighted sum of individual product scores, if either the weight or the product score was 0, these mismatches in reporting would cause products to ‘drop out’ of the calculation of overall status, thus losing real data.  The gap filling methods we developed estimated the US dollar value of harvested products from the tonnage reported; or the tonnage harvested based on a product’s reported economic value. |
**Brazil (2014)** | The goal models and reference points used the same approach as Global 2012 | This used the same data and approach as for Global 2012. |
**U.S. West Coast (2014)** | Not included in this assessment. Scores were not calculated because there are few data available on local-scale harvest and this is currently no longer pursued in any measurable quantities, and in the past had occurred mostly in the southern California region. Given this situation, the two options for how to include this goal in the assessment were to give the southern California region a zero (lowering the overall Index score), or to have the goal drop out completely of the assessment. The former option would assume there was demand for seaweed that was no longer met because the resource had been depleted, the latter assumes there is not enough demand for seaweed to make it commercially viable and so it is no longer harvested. We felt the latter was a more likely scenario. | Because this goal was not included, this assessment  had 9 goals that all had equal weighting. |

***

### Practical Considerations for Economic Goals

> The **Coastal Livelihoods and Economies** goal rewards productive coastal economies that avoid the loss of ocean-dependent livelihoods while maximizing livelihood quality. The **Tourism and Recreation** goal captures the value people have for experiencing and taking pleasure in coastal areas.

Some goals in your assessment will draw from economic information. Such sub-goals that you can approach together include the **Livelihoods** and **Economies**. If you have sub-goals for this theme, you will have to decide how to weight them in the goal score. If you find jobs, wages, and revenue data broadly, you will have to decide how to apportion it appopriately between **Livelihoods and Economies** and sometimes even with **Tourism and Recreation** given its different philosophy.

In your regional assessment, there is the opportunity to study the behavior of economic trends in your area. You can examine time-series with greater detail and, for example, establish a different time-periods that reflect economic cycles in your area, or even process the data to eliminate the “noise” from fluctuations and capture more persistent trends. You also have the chance to factor in the sustainability of the jobs--something that has not yet been done in the Global Approach.

> TIP: **You will most likely simplify the given Global models.** This is because you will be looking at local economic scales, you likely will not need to adjust for currency differences, for example, as was done in the Global Assessment through such metrics as the Consumer Price Index and Purchasing Power Parity.

In your regional assessment, there is the opportunity to study the behavior of economic trends in your area. You can examine time-series with greater detail and, for example, establish a different time-periods that reflect economic cycles in your area, or even process the data to eliminate the “noise” from fluctuations and capture more persistent trends.

#### Ready to start on **Livelihoods?**

> The **Livelihoods** sub-goal describes livelihood quantity and quality.

Ideally, this sub-goal would speak to the quality and quantity of marine jobs in an area. It would encompass all the marine sectors that supply jobs and wages to coastal communities, incorporating information on the sustainability of different sectors while also telling about the working conditions and job satisfaction. The jobs and revenue produced from marine-related industries directly benefit those who are employed, and also those who gain indirect value from related economic and social impacts of a stable coastal economy, such as community identity and tax revenue. You should capture the indirect as well as direct benefits from jobs, wages and revenue from coastal communities.

*Practical Guidance*

The first step of this goal is to **identify the marine-related sectors in your area**. There are jobs that are directly connected to the marine environment, such as shipping, fishing, longshore workers, but also some that are connected indirectly, such as supplies and supporting industries.

> For example, the sectors for which data were found in the Global Assessment included tourism, commercial fishing, marine mammal watching, aquarium fishing, water and tidal energy jobs, mariculture, transportation and shipping, ports and harbors, ship and boatbuilding. Much of the data on wages came from the International Labour Organization.

After you have identified which jobs are in your area, you will want to find some **measure of their direct and indirect benefits**.There are two broad kinds of data you should be looking for. The first are direct data that feed into the model equations. These are jobs and wages data for the direct benefits of jobs. This includes the number of jobs in each area, and the wages or income for such jobs. You could find such information from you local national statistical office, or economics bureau, for example. The second are data that show the indirect benefits of these jobs to the local communities. This can be found directly or  indirectly through the use of economic multipliers. With multipliers you can attempt to estimate the revenue generated by jobs more broadly associated with marine sectors. It's encouraged to use economic multipliers from the literature.

> You can multiply the number of fishermen by an economic multiplier to estimate larger economic effects. This is because the fishing industry provides indirect jobs beyond just the jobs of the fishermen, ranging from gear manufacturing companies to restaurants and movie theaters where the fishermen spend their income.

Next you must think about how to use the data to **infer quality and quantity of jobs**. Do you have the old format of data going back in time? If so, can you check to see how wages per sector have changed over time? If all of the sectors change in the same way, for instance, they might show broader economic trends that you could use to project forward per sector per country to find a likely future state and infer relationships between them.

#### Ready to Start on **Economies**?

*Ideal Approach*

> The **Economies** sub-goal captures the economic value associated with marine industries using revenue from marine sectors.

Ideally, economic data would be collected coastally, and traced from sectors both directly and indirectly related to marine industries. When these data are not available it is possible to use revenue data at a larger scale and adapt them to a coastal area based on population distribution. The reference point in this sub-goal will likely be set as a moving window temporal approach.

*Practical Guidance*

You should be searching for these data at the same time as the **Livelihoods** sub-goal, because of the similarities of the data sources. You need to mainly find revenue data for the marine sectors in your area, after you have already identified the sectors.

*Reference Points for the Economic Goals*

| L&E component | Type of Reference | Point Example
|-----|-----|-----|
| Number of jobs | Temporal | Current number of jobs minus number of jobs five years before |
| Wages | Spatial | Highest observed value across reporting units |
| Revenue | Temporal| Current revenue compared to past revenue |

Because there are no absolute reference points for these goals, you will have to make the reference points relative to the given information. If you are following the Global approach, the reference points in **Livelihoods** sub-goal should be set as temporal approach comparing current to past conditions; they could also be done a spatial comparison to compare regions to the highest observed incomes in your area. In the **Economies** sub-goal, revenue has a moving target temporal comparison; we highly recommend that this remains a temporal comparison so that a specific place is compared to its performance in the past and not to anywhere else.

It is highly recommended that you keep the reference point for jobs as a temporal comparison, and only using a spatial comparison for wages.  Comparing the number of jobs across different places, for instance, would require at the very least adjusting values by the size of the workforce in each location.

One way to do the temporal comparison is to have a moving-window approach by comparing the value in the current year to values in previous years. If using a temporal approach, you must consider how far back in time to go. The Global Assessments used a five-year moving-window because it is intended to capture short-term changes in the trajectory. But then you must consider, would five or ten years accurately represent economic trends, or would it be skewed by the effects of an economic downtown? If there is a not economic downturn, do you want to reward an increasing number of jobs, or reward maintaining the same number of jobs--in other words, not losing any jobs?

> Your choice may differ depending on the given economic growth rate of your country. Are there policy targets in place for growth? Or has growth leveled out, and you wish to maintain livelihood quantity overall?

Lastly you will have to *combine the sub-goals*. You can weight the two sub-goals unequally if, for example, the number of jobs was considered more important than the wages rendered.

#### History of the Approaches

***Livelihoods***

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | This sub-goal is measured as the number of direct and indirect jobs across sectors within a region plus the average purchasing power parity (PPP)-adjusted wages within each sector. Jobs are summed across sectors and measured at current and reference time points. Wages are averaged across sectors within each region and the reference value is taken from the region with the highest average wages across all sectors.<br  /><br  />In the livelihoods sub-goal, jobs had a moving target temporal comparison and wages had a spatial comparison. The reference point for jobs (and for the economies sub-goal) is a moving baseline because there is no established target for number of jobs (and setting a specific target number of jobs would be completely arbitrary). In these cases it is important to compare the same place to itself in the past, and not to compare it to a different place. Therefore, the objective of the jobs component is actually no loss of jobs. In addition, we want to ensure that we are detecting changes that are specific to marine-related sectors. Jobs must keep pace with growth in employment rates or sustain losses no greater than national increases in unemployment rates. For wages we assumed the target value for average annual wages is the highest value observed across all reporting units. | We assumed that sector-specific job and revenue multipliers are static and globally consistent, but distinct for developed versus developing regions (when such information was available), because we do not have data to resolve temporal or regional differences. For all other sectors where the data sources only provided direct jobs or direct revenue, we used sector- and development status-specific multipliers derived from the literature to estimate total job or revenue impacts. We did not apply multiplier values to wages since the cascading effects of earned income are more contentious. To account for broader economic forces that may affect jobs independent of changes in ocean health (e.g., a global recession), we adjusted (as noted above) relative values for the number of jobs by changes in national employment rates.<br  /><br  />While job identity has social and cultural value, there are not adequate data to track individual workers and assess their job satisfaction on a global scale. Also because of data constraints, this goal does not provide more credit for sectors or economic activities that are more ecologically sustainable. | A score of 100 would indicate that the number of marine jobs had not reduced relative to that number five years previous, and that the wages in the area were the highest anywhere.
**Global 2013** | Based on Global 2012, with some simplifications: Since many of the values were not available in 2010, older wages data were divided by the inflation conversion factor for 2010 so that wage data across years would be comparable in 2010 US dollars. These data were also multiplied by the purchasing power parity-adjusted per capita GDP (PPPpcGDP). Jobs data were adjusted by dividing by total number of people employed for the corresponding year: (1 – percent unemployment) * total labor force. This factor ensures that any changes detected are strictly due to marine-related dynamics and not driven by national macroeconomic events across all sectors, marine and not. One of the adjustment terms previously used was considered redundant and removed: an additional factor had previously been used to modify the wages data, obtained from the International Labour Organization (ILO).<br  /><br  />The reference point was the same as Global 2012. | The approach was the same as Global 2012 except for a few simplified multipliers. |
**Brazil (2014)** | The model and reference point were the same as Global 2012. | The approach was the same as Global 2012. |
**U.S. West Coast (2014)** | This goal follows the same model as in Global 2012, but using local data with a slightly different list of sectors. Data came from the National Ocean Economics Program (NOEP); sectors include: living resources, tourism and recreation, shipping and transport, marine related construction, and ship and boat building/repair. For each of these sub-components we use sector-specific multipliers derived from the NOEP data so that we assess both direct and indirect effects. We recognize that sectors and economic activity within a region can be influenced by activities outside the region (e.g., fish caught in Alaska could be brought to Washington for processing, or vice-versa), thus leading to an over or under estimate economic benefits derived from marine ecosystems within the study region. As with any ecosystem study, defining boundaries for the ecosystem is an artificial operation, and linkages with external elements necessarily exist but are challenging to account for.<br  /><br  />The reference point was the same as in Global 2012. | The approach was the same as Global 2012. |

***Economies***

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | This sub-goal is captured as the total adjusted revenue generated directly and indirectly from each sector (measured in 2010 USD), at current and reference time points.<br  /><br  />In the economies sub-goal, revenue had a moving target temporal comparison. Because there is no absolute reference point for revenue, this sub-goal employs a moving baseline. We made a correction to revenue based on a region's GDP (“no loss and must keep pace with growth in GDP or can sustain losses comparable to national declines in GDP”). The current and reference years used for unemployment and GDP data were based on the average current year and average reference year across the sector data sources used for number of jobs and revenue, respectively. | We assumed that sector-specific job and revenue multipliers are static and globally consistent, but distinct for developed versus developing regions (when such information was available), because we do not have data to resolve temporal or regional differences. For all other sectors where the data sources only provided direct jobs or direct revenue, we used sector- and development status-specific multipliers derived from the literature to estimate total job or revenue impacts. We did not apply multiplier values to wages since the cascading effects of earned income are more contentious. | A score of 100 would indicate that revenue has not decreased compared to its value five years previous.
**Global 2013** | The model was same as Global 2012, with a few simplifications:  revenue data were adjusted by dividing by GDP per region (reported in 2013 USD; data from the World Bank).<br  /><br  />The reference point was the same as Global 2012. | The approach was the same as Global 2012, although simplified where appropriate. |
**Brazil (2014)** | The model and reference point were the same as Global 2012. | The approach was the same as Global 2012. |
**U.S. West Coast (2014)** | The model and reference point were the same as Global 2012. | The approach was the same as Global 2012. |

****

### Practical Considerations for Tourism

#### Ready to start on **Tourism and Recreation**?

> This goal will necessarily draw from different data sources than the Global Assessment, and so it is encourage to look at what other OHI+ and regional assessments have done. This goal demonstrates the flexibility of the OHI+ approach, so you are encouraged to think creatively.

*Ideal Approach*

> The **Tourism and Recreation** goal captures the value people have for experiencing and taking pleasure in coastal areas.

Ideally, you would find information for how the ocean in your area is used and enjoyed by local residents and tourists alike, thereby capturing the full range of values and touristic and recreational activities. Models will vary because there are many ways to potentially measure the delivery of this goal. The type of reference point used will depend on the data available.

*Practical Guidance*

Your approach will be different than the Global Assessments. In fact, the **Tourism and Recreation** goal shows how flexible the OHI+ approach is to adapting models with improved data or approaches.  It could be approached economically, and combined in the data searching for the **Livelihoods and Economies** goal, or done in another manner. You can get creative with your approach, and you are encouraged to read the previous OHI regional studies, such as the U.S. West Coast Assessment (2014) and Brazil Assessment (2014), since examples are best studied for guidance here.

> For example, in the Brazil Assessment (2014), the density of hotel employees per state was used as a metric to determine how well touristed coastal areas were. This was better than using international travel information, as was used in the Global Assessment, because for a large country like Brazil, internal travel would not have been accounted for.

There are potentially dozens of variables that affect the number of people that engage in tourism and recreation within a region and where they go, including local and global economies, infrastructure to support the activities, promotion of particular locations, safety and security, political stability, and so on. If you can't find information on visitors, can you find information on access as a proxy for visitors? Do people have access to boating areas, or to surfing spots?

> TIP: If you already have access information for **Artisanal Opportunities**, that would not be double-counting here.

Because we currently do not know which variables matter and to what degree, or have data for many of these variables, we instead assume that tourists distribute themselves within a region proportional to where local populations are. This means that populated areas get a greater proportion of the tourists, so you can use population data to distribute other kinds of data you may find.

*Reference Points*

The reference point used will depend upon the types of data incorporated into the model. Does your country have growth rate targets? Do you want to increase tourism, or instead ensure it does not decline?

#### History of the Approach

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | Data on international arrivals were used as a proxy for the value of tourism and recreation in each region, as this was the most comprehensive data available on a global scale. Additionally, the length of each tourist’s stay in a region was incorporated: we used tourist-days as the measure for this goal because some locations, especially remote ones, may receive fewer arrivals but tourists may stay for longer periods of time. We therefore multiplied the number of arrivals by the average length of stay in order to incorporate this information. Sustainability was incorporated by using the tourism competitiveness index (TTCI) from the World Economic Forum to capture the sustainability of the tourism industry. To account for different surface areas and number of inhabitants across regions, the tourist-day values were adjusted by local population size. <br  /><br  />Global 2012 used a spatial comparison reference point that compares each region to the best performing regions. | It is very difficult to have a quantitative measure of whether people are fully taking advantage of recreation opportunities offered by marine and coastal environments. We assumed that the amount of international arrivals (although this ignores domestic travel and recreation), however, could be informative of the desirability of a coastal location and that this must have some relation with the health of the system. We use a spatial comparison reference point that compares each region to the best performing regions. In order to compare different regions, we standardize by dividing the arrivals by the region’s population. <br  /><br  />Few non-economic indicators of tourism and recreation exist at the global scale, and thus the original approach in Global 2012 approximated this goal measuring the number of international tourists arriving by airline to coastal regions, accounting for their average length of stay, and adjusting by the region’s population size. This approach was sub-optimal because it did not account for domestic tourism, which is a large part of tourism in many regions. Also, since we only had information about total arrivals, not just those of people who were intending to spend time on the coast, we standardized by dividing by the total population, not just the coastal inhabitants, which tended to penalize especially large regions with large stretches of inhabited inland areas such as Canada, Australia and the USA.<br  /><br  />We log-transformed the status scores because of an extremely exponential distribution of scores driven by a few regions with much higher tourism rates relative to population size. Even after this transformation the distribution of scores remained strongly exponential and so we rescaled scores to the value of the 90th percentile region, which was 25% of the maximum score. The 17 regions above this score were all given status scores = 1.0. | A score of 100 in US West Coast would indicate that tourism in a specific place has not declined compared to its value in the reference year. In other assessments this would indicate that a value was not lower than the region with the highest score.
**Global 2013** | We calculated the proportion of direct employment in the tourism industry relative to total labor force. As in Global 2012, we used the tourism competitiveness index (TTCI) from the World Economic Forum to capture the socio-economic sustainability of the tourism industry.<br  /><br  />To determine the reference point, we identified the best scoring region across all years and rescaled all other regions across all years to that score (Bonaire; 2011, which was the most recent year of data). The high-scoring regions were outliers in the distribution of scores (the second best performing region scored 40 and the third scored 28); we therefore rescaled all scores to the 90th percentile score. All regions above this score received a status score of 100. | We created a new model different from Global 2012 by using employment in the tourism sector as a reasonable proxy measure for the total number of people engaged in coastal tourism and recreation activities. Employment within this sector should respond dynamically to the number of people participating in tourist activities, based on the assumption that the number of hotel employees, travel agents and employees of other affiliated professions will increase or decrease with changing tourism demand within different regions.<br  /><br  />Ideally there would be data available specifically for employment in coastal tourism industries, however the best data available at a global scale report total number of jobs, not just coastal jobs, within the travel and tourism industries. These data include jobs that are directly connected to the tourism and travel industry (i.e. for both leisure and business), including accommodation services, food and beverage services, retail trade, transportation services, and cultural, sports and recreational services, but exclude investment industries and suppliers. Unfortunately it was not possible to determine the proportion of jobs affiliated with strictly leisure travel. However, some (unknown) proportion of business travelers also enjoy the coast for leisure during their visit to coastal areas, such that we assumed all travel and tourism employment was related to tourism and recreation values. Additionally, it is true that not every tourist stays in a hotel and not everyone staying in a hotel is a tourist. Nevertheless, these data are of better quality and closer to what this goal is trying to capture than those used in Global 2012. |
**Brazil (2014)** | The model developed for Global 2012 was changed to use information on hotel employees for each coastal municipality in Brazil. Status was measured for each coastal state as the density of hotel jobs in coastal areas.<br  /><br  />We log-transformed coastal area under the assumption that density of hotel employees is not necessarily a measure of sustainable tourism, but that a balance likely exists between the density of tourists and the absolute number of tourists that a state receives (even if spread out over a larger area). Although the TTCI was included in the model as a measure of sustainability, this value is calculated at the national level, and was therefore applied equally to all states. Due to this, it has no effect on differences between regions within Brazil. The model could be improved if a state-specific index assessing sustainability of coastal tourism were available.<br  /><br  />The reference value used was the highest status value across all states over the time series, which was Rio de Janeiro in 2011. | The goal model for Brazil assumes that the majority of coastal hotels are located in proximity to the shoreline, and that the number of hotel employees is directly proportional to the volume of tourists an area receives. A report evaluating drivers of tourism in Brazil found a significant positive relationship between number of tourists and number of hotels; here we incorporate hotel employees which is likely a more sensitive metric, given that hotels can vary greatly in size and economic changes are likely to be reflected more quickly in number of jobs than number of hotel establishments. |
**U.S. West Coast (2014)** | At this scale we were able to make use of detailed studies documenting the changes in participation in 19 different marine and coastal specific recreational activities over time. These data come from the National Survey on Recreation and the Environment (NSRE), which has been conducted 8 times nationally since 1960, with the most recent data available for coastal and marine specific activities from 2000. These observations were used to produce a predictive model that was employed to estimate participation rates in recent years, because the survey data were no longer being collected.<br  /><br  />This model employs a temporal reference point, comparing current status to the status in the year 2000. | For the tourism and recreation goal we developed an approach that took advantage of time series data on participation in a range of coastal and marine tourism and recreational activities. Participation rates more closely matched the intent of this goal and were a more robust proxy than international tourist arrivals data, i.e., the proxy used in Global 2012. We also changed the tourism and recreation reference point from spatial (used in the global analysis, where having values from >170 assessed regions made this reasonable) to temporal (given availability of time-series and limited scope for spatial comparisons). |

***

### Practical Considerations for Fisheries Goals

*Ideal Approach*

These goals measure the amount of seafood sustainably harvested in a given region for primarily human consumption. It should include quantity of fish caught by any practice including wild-caught commercial fisheries, mariculture, artisanal-scale fisheries, and recreational fisheries.

*Practical Guidance for OHI+*

When data become available for artisanal or recreational catch, you could include them as part of the **Fisheries** sub-goal of **Food Provision** or as a separate sub-goal depending on the context. Importantly, seafood harvest using unsustainable fishing practices or catch levels is penalized, as the goal aims to maximize the amount of sustainably produced seafood from wild or cultured stocks.

The overall **Food Provision** model should not change. It should always measure whether the seafood from fisheries and mariculture is harvested at maximum carrying capacity and remaining sustainable. The contribution of each practice to the overall score is weighted by its relative contribution to the total seafood yield in your area.

The Global Assessments have studied commercial fisheries and mariculture. If another component were added, for example artisanal fisheries, you might want to consider different options for how to combine them into a weighted indicator. Does one tonne of fish caught through one component mean more than one tonne of fish caught in the others? If there is a rationale to use a different approach, that is entirely possible in the OHI+ framework.

#### Ready to start on **Wild-Caught Fisheries**?

*Ideal Approach*

>The **Wild-Caught Fisheries** sub-goal describes the amount of wild-caught seafood harvested and its sustainability for human consumption.

Ideally, you would find data for catch and effort of every commercial and recreationally-fished species in your area. You would also know the functional relationship between fish population size, or biomass, and fisheries effort, so that maximum sustainable yield (MSY) could be known or calculated. Then, fisheries catch and effort information would be used to calculate the present state and MSY would be used to set the reference point. Current status would be calculated using the present state of every individual species and combining each species together, as the weighted proportion of the total catch.

*Practical Guidance*

Use catch-per-unit effort data if available, and a functional relationship for the reference point. Fisheries modeling using data-poor sources was greatly improved in Global 2013 than the original approach in Global 2012. If your assessment relies solely on catch data, it is highly recommended to use Global 2013 and not Global 2012.

When collecting data on fish landings, it's important to consider how you will divide the data among regions. This was important in the case of a country using fisheries landings data reported at regional ports.  While it was known whether the fish were caught in inner or outer waters, it was also known that the fish reported at those ports were not necessarily caught in those matching particular regions. Boats, after all, go beyond our predefined OHI+ region designations in order to find their catch. So how does one apportion the percentage of catches correctly?

In this case, one option may be to use the information on where the boats are registered. Having the boats assigned to regions might then offer a way to disaggregate the data. So if possible, try to find as much spatial information for this goal as possible.

>If you are following the Global model, you don't want to split the catch among sub-regions; instead, you want to sum catch across all sub-regions, so you can calculate B/Bmsy for the whole population.

#### Ready to start on **Mariculture**?

>**Mariculture** measures the ability to reach the highest levels of seafood gained from far-raised facilities without damaging the ocean's ability to provide fish sustainably now and in the future.

*Ideal Approach*

Ideally, there would be information on the area available for mariculture - physically and/or based on social expectations and priorities - and the sustainability of the mariculture practices. This would mean that assessments had been made to identify the physical coastal and offshore habitat appropriate for each intended type of mariculture species (example: offshore habitats for finfish and shallower habitats for filter-feeding invertebrates) and the areas that have been identified as socially appropriate, since mariculture competes for space with many other ocean uses, including fishing and tourism activities. This approach would not penalize regions that have less geographic area available for mariculture, though places with fewer sheltered bays or lower primary production could be at a disadvantage. The type of reference point used will depend on the data available.

*Practical Guidance*

Setting the reference point for mariculture really depends on regional preferences. This can be very hard to do: in best cases you would incorporate the potential range for mariculture based on habitat suitability for each cultured species, distance from the coast as well as which habitat is suitable, and how much local preference wants to allot to mariculture (versus area apportioned to ports, hotels, beaches, tourism, etc). In Global 2012, without information about social limitations for how much coastal area could be allotted to mariculture, we included the entire area of the coastline, thus assuming that mariculture could be developed everywhere. At a regional scale, better data will allow for restrictions based on habitat, conflicting uses, and social preferences.

#### History of the Approaches

*Fisheries*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a Score |
---------------|------------------------------------------------|-----------------------------|-------------|
**Global 2012** | Status of the Fisheries sub-goal was calculated as a function of the absolute difference between a region’s total landed biomass from the reference multi-species maximum sustainable yield weighted by a correction factor that adjusts for taxonomic reporting quality of the data.<br  /><br  />The reference point is based on an estimate of the optimum amount of all marine species that may be caught sustainably, minimizing the likelihood of overfishing while maximizing harvest, i.e. the multispecies MSY (mMSY). This was calculated by summing all the single-species MSY estimates obtained for commercially landed species. The reference point for wild-caught fisheries was set at 25% below mMSY to take into account that mMSY may be overestimated because single-species estimates of MSY obtained under current conditions may change.<br  /><br  />Indeed, when all species are exploited simultaneously, the fishing pressure that each population can withstand might be lower (or higher) due to changes in interactions between species, e.g. if a prey population is reduced, a predator may not be as abundant as predicted by the single species model (or vice versa for the prey species, in the case of a predator species becoming less abundant). By picking a lower reference point, we adopt a precautionary estimate of the total amount of seafood that could be sustainably caught. In other words, the reference point is set so the total landed biomass of wild-caught species will not be more than 75% of the estimated mMSY. Regions are penalized for harvests above or below this reference level (more heavily if above). <br  /><br  /> | At a global scale, catch, effort, and MSY estimates are not available for either commercial, artisanal or recreational fishing: only landings data for commercial fisheries are available through the United Nations Food and Agriculture program (UN FAO). Thus, within the aims of the wild-caught fisheries goal, the ideal approach had to be modified to be appropriate for the data that were available. Working with fisheries scientists to adapt the ideal approach, data from all commercially fished species in a region were used to estimate the MSY for each species and were combined to obtain a reference point of multispecies MSY. | Higher scores reflect fishing practices with sustainably high yields that avoid excessively high exploitation (overfishing), and do not target threatened populations.<br  /><br />For Global 2012 and 2013, the formulae show that a stock receives a score of zero if either it is completely depleted, i.e. B/BMSY = 0, or strongly underfished, i.e. B/ BMSY = 3.35, with 3.35 representing the local currently observed maximum value. Any past or future B/ BMSY values greater than 3.35, as well as the species with this maximum value, would receive a zero score for food provision to denote that the species is severely underfished. However, given that underutilization of resources is generally easier to remediate than depletion, we apply an asymmetrical buffer around values of B/ BMSY close to 1 that get assigned a perfect score, (i.e., overfished stocks achieve a perfect score if B/BMSY is up to 0.2 points below 1 but underfished stocks achieve a perfect score if B/BMSY is within 0.5 points of 1). Thus, overfished species negatively influence the long-term sustainable delivery of the food provision goal more than underfished species do.
**Global 2013** | Status of the Fisheries sub-goal was calculated based on estimating population biomass relative to the biomass that can deliver maximum sustainable yield for each landed stock (B/BMSY). The estimates of B/BMSY were obtained by applying a model developed by Martell & Frœse, (2013), and referred to as the “catch-MSY” method. This ratio is conventionally used to inform fisheries management. <br  /><br  /> This approach adopts the population biomass at MSY (BMSY) as a single-species reference point, which by various assessment frameworks is considered conservative (e.g., Frœse et al. 2011). Single-species values of B/ BMSY are aggregated using a geometric mean ensuring that some multi-species effects may influence the scores. <br  /><br  /> This is a more direct measure of population health because it relates directly to population size, rather than the harvested biomass of those populations. More importantly, this reference point was calculated through a more robust model than the one used in Global 2012, published by Frœse & Martell in 2013. | Since Global 2012, several new data-poor approaches have been developed to assess fisheries that leverage globally-available information (Costello et al., 2012; Martell & Frœse, 2013; Thorson et al., 2013). The catch-MSY approach improves upon the method used in Global 2012 in that it leverages a mechanistic understanding of the connection between harvest dynamics and population dynamics and uses this to infer stock depletion levels as a function of both historical patterns in catch and of species-specific resilience traits (see also Thorson et al. 2013). In addition, this model is more informative in the case of developing fisheries, whereas the previous approach assumed a perfect score in cases where a peak with successive decline had yet to be observed. <br>The “catch-MSY” model, as designed by Martell & Frœse, calculates catch/MSY. For our analyses, we converted this to an estimate of B/BMSY, i.e. an indicator of stock abundance rather than catch, which is more directly informative of stock heath. This more complex (although still data poor) approach better takes into account species-specific fishery dynamics.  In addition, the scores for each population were combined using a geometric mean, which ensures that smaller, rarer populations have more weight and thus biodiversity of the catch is taken into account as well. As before, regions are penalized for underharvest and (more severely) for overharvest. |
**Brazil (2014)** | Status of the Fisheries sub-goal was calculated in the same manner as Global 2012, with a modified sustainability term. <br  /><br  /> As in Global 2012, the reference point is based on an estimate of the optimum amount of all marine species that may be caught sustainably: mMSY. | The fisheries sub-goal was calculated in the same manner as Global 2012; this study was conducted before improvements to the approach (Global 2013). However, local-scale data on exploitation category of species caught within Brazil’s EEZ was used as catch-based sustainability index, an improvement over the original Global 2012 approach. |
**U.S. West Coast (2014)** | Status of the Fisheries sub-goal was based on population biomass relative to the biomass that can deliver maximum sustainable yield (B/BMSY) and fishing mortality relative to fishing mortality that can deliver maximum sustainable yield (F/FMSY) for each landed stock, using formal stock assessments rather than relying solely on data-poor estimates from catch data. These ratios are conventionally used to inform fisheries management. <br  /><br  /> This approach adopts the population biomass at MSY, i.e. BMSY, as a single-species reference point, in combination with the fishing mortality at maximum sustainable yield, i.e. FMSY. | Stock assessments were only available for 41 different species across the whole study area. These 41 species accounted for ~59% of the total average catch across the catch time series data. We tested the use of a recently published data-poor approach (Costello et al. 2012) to obtain B/ BMSY values for the remaining stocks. To validate the results we compared estimates for which we had formal stock assessment values and found the latter to be outside the confidence bounds predicted by the model. Other estimates of overfishing are available for data poor stocks (Dick & MacCall 2010), however these only cover ~2% of overall catches. Therefore, our analyses were only based on values from assessed stocks.<br  /><br  />From each assessment we extracted the estimates for B/BMSY and F/FMSY that are assigned to the whole species throughout the west coast of the US. Fisheries scores were then assigned to each region based on the contribution of each species in each region to the overall catch in that region. These weights were assigned based on the average catch of each species across all years of recorded catches (1950-2011). This means that each species gets a single score in the overall study area, and what differentiates the scores from region to region is which species are in that area and how much they contribute to the area’s average historical catch. We used the average catch over time instead of current catch as a weighting factor as it reflects the mean potential contribution of each species to total food provision, smoothing over stochastic fluctuations and possible recent declines. Catch data were only available at the state level, so all regions within California received the same status score. |  For the U.S. West Coast, combining F/FMSY with the population size compared to the size that ensures MSY (B/BMSY) allows us to take into consideration how it is currently being exploited. A population that is dwindling, but is also not under heavy fishing pressure, has more chances of recovering and so it receives a higher score than one that has a similar B/BMSY but is also under strong fishing pressure, thus being most likely to continue in its decline in the near future. On the other hand, a population that is abundant, but has a low F/FMSY, is not being exploited to its full potential and thus its score gets partially penalized due to this underutilization. This approach produces lower scores for species where both underfishing and overfishing are occurring, but does not punish as severely for underfishing of stocks.

*Mariculture*

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a Score |
---------------|------------------------------------------------|-----------------------------|-------------|
**Global 2012** | Mariculture was calculated as the yield reported to the United Nations Food and Agriculture Organization (FAO) multiplied by the sustainability for each species harvested.<br  /><br  />The reference point is based on the goal for each region to produce as much farmed seafood as sustainably possible within its coastal area. The reference point for mariculture is a spatial comparison (and not a theoretical functional relationship for sustainable production yield as there is for wild-caught fisheries), set at the amount of seafood produced per square kilometer of eligible coastline in the most productive region, which, at the time of the global study, was China. Setting a spatial reference point in this way assumes that because China is able to produce such a high proportion of mariculture to its coastal area, all regions should be able to as well, given current ecological and technological conditions. This also assumes that it is socially desirable for all regions to produce farmed species at this level, which is likely not true for all regions.<br  /><br  />Global 2012 compared all areas to that with the highest observed production density after the sustainability coefficient was applied, based on the assumption that all coastal area in each region could be developed for mariculture at the same production density as the reference region (i.e., China) and that maximum potential productivity per unit of area is similar across ecosystems and regions. This caused regions with extensive proportions of coastline where mariculture is unsuitable for biological reasons (e.g., the water freezes for large part of the year) or logistical reasons (e.g., scarcely inhabited), such as Canada, to be unduly penalized. | At the global scale it was not possible to account for all physically appropriate habitats where mariculture could occur, and thus the entire area within 3nm from the coastline was considered potential habitat, although it is clear that that entire habitat is not physically suitable for mariculture, nor would it be socially desirable to do so. However, restricting the area based on biophysical constraints and social preferences at a global scale was not possible. Gauging mariculture sustainability was difficult and was ultimately based on information from a Mariculture Sustainability Index (MSI) by Trujillo (2008). The MSI incorporated information on wastewater treatment, origin of feed (i.e., fishmeal or other) and the origin of seed (i.e., hatchery or wild caught). The MSI, however, was not recalculated after 2005 and, when missing, values from other regions or from related species had to be used. | Higher scores reflect high food provisioning in a sustainable manner, while not compromising the water quality in the farmed area and not relying on wild populations to feed or replenish the cultivated species. A score of 100 means that a region is sustainably harvesting the greatest amount of farmed seafood possible based on its own potential (where its maximum potential is estimated in different ways depending on the assessment). A low score can indicate one of two things – that species are being farmed in an unsustainable manner or that regions are not maximizing the potential to farm in their marine territorial waters.
**Global 2013** | A similar model to the one developed previously in Global 2012 was used in Global 2013; however, since we modified the approach to setting the reference point, the calculation of the results has significantly changed.<br  /><br  />Global 2013 instead bases the reference point on harvested tonnes per coastal inhabitant (with coastal defined as within 25 km inland), under the assumption that production depends on the presence of coastal communities that can provide the labor force, infrastructures, and economic demand to support the development and economic viability of mariculture facilities. Thus, two regions with an equal number of coastal inhabitants harvesting an equal tonnage of cultured seafood should score the same, even if one is larger than the other, as the productivity is commensurate to each region’s socio-economic potential to develop mariculture. Stated another way, mariculture development is assumed to scale proportionally with coastal population as a proxy for local demand and potential logistic limitations to farm development, e.g., presence of infrastructures, coastal access, and locally available workforce. Given the very high skew in the status values per region, we set the reference point to the 95th percentile region (Thailand), with all regions above that value set to a status score = 1.0 | Global 2013 differs from Global 2012 due to the reference point; see below. |
**Brazil (2014)** | The status of the Mariculture sub-goal was calculated using harvest data reported by the Brazilian Institute of the Environment and Renewable Natural Resources (IBAMA). For each of up to four species cultured within the state, the score was determined by the yield, the reference sustainable production per unit area, and the total potential farming area. <br  /><br  />At the regional scale in Brazil, restricting the area available for Mariculture based on biophysical constraints and social preferences was possible. | Locally cultured species were used to calculate scores and appropriate reference points were set for each species state. |
**U.S. West Coast (2014)** | The status of the Mariculture sub-goal was calculated as the sustainable production density of shellfish biomass from mariculture relative to a target level of production density for each state within the region.<br  /><br  /> For the mariculture sub-goal, the reference point was modified to incorporate local information on suitable areas for cultivation and desirable production targets, proposed by the US government agency responsible for marine resources management (NOAA). This is a case where conceptually the US West Coast approach is similar to Assessments 1 and 2 but the reference point is based on better information. | Better information about physical and social limitations on mariculture allotments was available for the regional study in the US West Coast. The US government has identified areas that are appropriate for mariculture based on current water quality and coastal development, and thus mariculture production was assessed only within these predefined areas, and not for the entire coastline as was done in Global 2012. In addition, a target level of production increase was proposed by the ocean government agency that was used to set the reference point. |

***

#### Ready to start on **Artisanal Opportunities**?

*Ideal Approach*

Ideally, this goal would include some measure of how easy or hard it is for people to access ocean resources when they need them and a quantified evaluation of the sustainability of harvest of all nearshore stocks used by artisanal fishermen. The type of reference point used will depend on the data available.

*Practical Guidance*

You should include data that are distinct from the catch data used in other areas of **Food Provision**. So once you find catch data and access data, you should think about which goals to use it in. For instance, if you find tonnage of artisanally-caught fish, you should include that elsewhere. If you find access for **Tourism**, you can use it there too. In any case, you will likely modify the default Global Assessment model using different and better-resolved data.

>For example, in the Baltic Sea region, **Artisanal Opportunities** is very closely connected to **Tourism and Recreation** since there are a lot of locals and tourists using the shared sea for enjoyment. You will have to decide how to apportion the data.

Here, you will want to find proxy data for *access* in whatever way best suits your areas. This could be drawn from physical, economic, regulatory, or stock condition data as an indication of availability. A combination of all of these would be best to more accurately speak to the philosophy, but of course it is limited by data.

For example, in the U.S. West Coast Assessment (2014), three metrics were used to define **Artisanal Opportunity** that you can use to study:

| Type of Access | Data Used | Reference Point |
|-----|------|-------|
| Phyiscal | Number of coastal access points per mile | 1 coastal access point per mile |
| Economic | Change in gas price over time | No change in gas price |
| Resource | Condition of fish stocks through NOAA Fish Stock Index | Perfect sustainability score on FSI |

The **reference point for this goal** would likely be full access to the resource. Keep in mind that the access is for people, and therefore a marine protected area may not count towards full access.

#### History of the Approach

Assessment | Model Description and Reference Point | Evolution of Approach | Interpreting a score
---------------|------------------------------------------------|-----------------------------|-------------------|
**Global 2012** | Status for this goal is measured as the demand for opportunities to fish artisanally. Demand is estimated using poverty levels as proxy, measured by the gross domestic product (GDP) per capita, adjusted by the purchasing power parity. The supply was estimated using an indicator that ranked how well regions regulated and supported artisanal fishing, as part of a study by Mora et al. (2009). This assessment did not incorporate a measure of the health of the targeted species or of sustainability of the fishing practices as a standardized artisanal harvest database was not available at a global scale. <br> The reference point for artisanal fishing opportunities is that all demand for artisanal fishing is allowed and/or achieved and that the fishing is done in a way that doesn't compromise future fishing resources. Thus, the reference point is that ‘supply’ (i.e., fisheries regulations as measured by Mora et al. (2009)) is greater than demand so that unmet demand is 0, i.e., all demand for artisanal fishing is allowed and/or achieved. |  The need for artisanal fishing could potentially be driven by any number of socio-economic factors, but perhaps the most wide-spread reason is the need for food either directly or through undocumented local trade which correlates well with poverty level. Data on how many people live below the poverty level are not available for many regions. Therefore, we used an analogous proxy that is more complete globally: per capita gross domestic product (pcGDP) adjusted by the purchasing power parity (PPP). Because no time series data were available for the access to artisanal fishing measured in the study by Mora et al. (2009), the trend was actually solely driven by the change over time in the PPPpcGDP, i.e., how ‘demand’ is changing over time. The sustainability of artisanal fishing practices could be approximated by using the status of the species that are targeted by artisanal fishermen. Unfortunately data on harvest from artisanal fisheries are often unavailable so we were unable to include this term in the calculation of this goal; we include it here for conceptual completeness. | A score of 100 means that a region is addressing and meeting the needs that people and communities have to fish artisanally by implementing government policies that permit or encourage them to do so, providing appropriate access to near-shore areas, and maintaining the species targeted in good health. A low score indicates that regions are not achieving or allowing sustainable artisanal fishing opportunities to be realized.
**Global 2013** | Same as Global 2012. No data update available. | Same as Global 2012. No data update available. |
**Brazil (2014)** | Economic or physical access or demand to fishing were not deemed to reflect circumstances in Brazil, and therefore this simplified model reflects that the primary driver of artisanal fishing opportunity is the availability of fish to capture (i.e., the condition of the stocks).<br  />This model was based solely on the sustainability index calculated using the exploitation status of species. The reference point for artisanal fishing opportunities is an established target of 1.0, that is, all stocks are categorized as either Developing or Fully Exploited. Due to the widespread nature of artisanal fisheries throughout Brazil, and the major contribution of small-scale activities to total landings for the country, all species were considered possible targets of artisanal fishing activities. | In Global 2012 artisanal fishing opportunity was assessed as a function of the need and the accessibility with a place-holder for stock status (which could not be assessed at global scales for artisanal-scale fishing). For Brazil the primary driver of artisanal fishing opportunity is the availability of fish to capture (i.e. the condition of the stocks).<br  /><br  />Because the scale of analysis for which we had stock status information was national, we chose not to include a measure of artisanal need (levels of poverty), which has great variation within Brazil. In addition, we assume that access to fishing is largely open because permitting and regulations from the Ministry of Fisheries are not considered restrictive, and in most cases, neither is physical access. |
**U.S. West Coast (2014)** | We developed a model using physical and economic access to coastal areas and access to the biological resources through the effectiveness of fisheries management as key variables. This approach does not model demand, but simply assumes that as long as there are no obstacles to pursuing artisanal fishing, the goal is fully achieved. These data better capture the nature of small-scale fisheries in the study area (artisanal, subsistence, and small-scale commercial) whereas the global model focused essentially on subsistence fishing. <br> Members of the public in the region fish artisanally from shore-based coastal access points (like beaches and jetties) as well as from boats. The key variables affecting access to these two modes of artisanal fishing differ and so we treat them separately in our assessment. Shore-based fishing is primarily constrained by physical access to fishing locations and is thus measured as percent of coastline within a mile of coastal access points. The target here is to maximize the amount of public access along the coast, therefore a perfect score results when each part of a region’s coastline has a coastal access point within 1 mile. We calculate these scores using a raster allocation model with 1-mile resolution intersecting at the coastline. | There are no data available on the number of people actively participating in artisanal fishing activities, nor a good approximation of what a reasonable reference condition would be that would allow to model ‘demand’ for artisanal fishing opportunities were these data available. Instead, we only consider physical and economic access to fishing opportunities and to the biological resources by assessing the condition of targeted fish stocks in the region, focusing exclusively on whether artisanal fishing opportunities are being fully provided in the region. This approach differs from the Global 2012 and 2013 assessments, where artisanal fishing opportunities were assessed as a function of need (based on the level of poverty present in a region) and the effectiveness of small-scale fisheries management in satisfying this need, mainly focusing on artisanal opportunities for subsistence purposes. It is also important to note that we were able to incorporate the accessibility to the desired species (i.e. status of the targeted stocks) only in this assessment because of data availability, but ideally we would’ve included this also in Global 2012 and 2013. |

***

## Pressures and resilience

**Pressures** and **Resilience** are two of the four dimensions used to evaluate each goal or sub-goal, along with **Status** and **Trend**.

It is important to identify the pressures that affect the ocean and coastal systems in your study area, and to search for additional pressures not included the global assessments. Once you have identified pressures within your study area, you should identify what resilience measures could counteract or nullify those pressures. Alternatively, you can start with a list of known resiliences, such as the relevant environmental laws in your country, and them map them onto pressure layers.

> TIP: The same considerations and requirements about data presented in the "**Gathering Appropriate Data**" section also apply to pressures and resilience. Every measure you include for pressures and resilience requires data for each region in your assessment.

###*Ideal Approach*:

Ideally, every stressor with an identified strong impact should have a corresponding resilience measure. The rationale is that as resiliences in the study area increase (for instance, by improving environmental regulations), they would balance out and eventually neutralize the pressures. This would lead to an increase in the overall goal or sub-goal score. By including regulatory responses in your assessment, you ensure that the actions taken in your country are relevant to ocean health.

In practice, however, the pressures and resilience measures you include in your assessment will be highly determined by data availability. It is best to first consider what pressures are acting in your study area and then determine if data are available to measure them. You should also decide if the pressures data included in the global assessment are relevant for your assessment and determine if  local data better capture pressures for all the regions in your study area. When considering resilience measures, look for regulations or indicators that could be encompassed in one of the pressures categories.

#### Pressure and resilience categories

The Toolbox calculates pressures in five ecological pressure categories (pollution, habitat destruction, fishing pressure, species pollution, and climate change) and one social pressure category. The reason behind the ecological categories is to avoid hidden weighting (e.g., overrepresentation of pressures for which there is more data). For example, in the global assessment there were many pollution datasets available, but few distinct habitat destruction datasets. If we simply averaged the scores of each individual stressor, pollution scores would have a greater influence on the results (stronger weight) due to the relative higher availability of measurements of various pollutants. Instead, aggregating by pressure categories ensures that different stressor types influence the score based on ranks. Nonetheless, the scores are combined in a cumulative way within each category to account for the fact that multiple stressors within a category have a cumulative impact that is greater than if only one of the stressors were present. The resulting scores for the five ecological categories are averaged to produce a single ecological pressures score. This score is then averaged with the social pressures score to produce the final overall pressure score.

### Pressures and resilience matrices

After you identify the pressures and resilience measures for your study area are and gather available data for each region, you will use matrix tables to determine how each of the measures affects each goal and sub-goal (for some goals you will also need to do this for habitat type or natural product categories). The pressures matrix establishes the relationships between stressors and goals are determined, and uses a rank from 1-3 to weight how strongly a given pressure affects a goal or sub-goal relative to all the other pressures affecting it.

The rank weights used in the pressures matrix were determined by Halpern *et al*. 2012 (*Nature*) based on scientific literature and expert opinion (see Supplemental Table S28 of *Halpern et al. 2012*). In the pressures matrix ranks are categorized as follows:

* 3 = high pressure
* 2 = medium pressure
* 1 = low pressure

Stressors that have no impact are not included rather than being assigned a rank of zero, which would affect the average score. Pressures are ranked rather than being represented as a binary (yes/no) measure because the range of consequence of different pressures on each goal can be quite large, and to classify all those pressures as a simple 'yes' would give too much influence to the weakest stressors. For example, food provision is most heavily impacted by unsustainable, high-bycatch fishing, but pollution does have some impact on fish populations. Without a weighting system, these stressors would be treated equally in their impact on the food provision goal.

![Scores from 1-3 are given to rank the importance of each pressure. Only values of 2 or 3 require that a resilience layer be activated when calculating the goal scores.](./fig/ohiman_goals-pressures-2D.png)

While pressures and resilience are usually displayed as two-dimensional matrices, they are actually three-dimensional matrices: each stressor should have data for each region in the study area, which is the third dimension of the matrix, as shown in the figure. The Toolbox will combine the data with the rank weights to calculate the pressures scores. Therefore, pressure weights should not be applied to the regions, but only to the goals. The Toolbox will multiply the stressor score for each region by the weight (1, 2, 3) assigned to that pressure for a specific goal and subgoal, and then it will combined that score within its appropriate pressure category as previously discussed.

![The pressures matrix is three-dimensional: each pressure layer has data per region, which is multiplied by the ranking weights of the pressures matrix.](./fig/ohiman_goals-pressures-regions.png)

Each pressure with a rank weight of 2 or 3 should have a corresponding resilience measure, which is meant to 'balance' the pressures since these have the greatest effect on ocean health. The Ocean Health Index considers resilience in two categories: **ecological resilience** to address ecological pressures, and **social resilience**, which may not be strictly marine-related, but they can help estimate how a region may be able to respond to or prevent new environmental challenges. Additionally, **goal-specific regulations** are intended to address ecological pressures, and are measured as laws, regulations, and other institutional measures related to a specific goal. Ideally, for any resilience measure, you would have three tiers of information:

* **Existence of regulations**: Are regulations in place to appropriately address the ecological pressure?
* **Implementation and enforcement**: Have these regulations been appropriately implemented and are there enforcement mechanisms in place?
* **Effectiveness and compliance**: How effective have the regulations been at mitigating these pressures and is there compliance with these regulations?

Ideally, information would exist for these three tiers, and you would be able to weight the resilience measure based on the quality of the information as 1 (existence of regulation), 2 (implementation and enforcement), or 3 (effectiveness and compliance). This approach is different from the way ranks are assigned in pressures, which is based on impact. However, in most cases, information is not available for these three tiers: often, the existence of regulations is all that is available, and this does not always vary by region. In some cases, you may want to consider building your own set of indicators to determine **implementation and enforcement** and **effectiveness and compliance.**

### Incorporating local pressures in your assessment

The pressures you will include in your assessment will depend on what is important in your study area and what data are available. If local pressures data are not available, you may default to using data from the global assessment, but this means in most cases that you will not have different information for each region (See **Including pressures from global assessments**). You will determine the weight ranks required in the pressures matrix only after you have identified the data you will include.

The following steps outline the process of how to include pressures in your assessment. The steps are iterative; return to previous steps to ensure you capture all important pressures in your study area:

1. Begin by exploring pressures important to your study area. What are big stressors acting along your coastlines?
2. Are data available to measure these stressors? If not, are other indirect measures or proxies available to represent these stressors?
3. Evaluate the pressures included in the global assessment. For example, if there is no mariculture in your study area, you could remove pressures data layers that only affect this goal (i.e. genetic escapes).
4. Are all of them relevant? Are there local data that can be substituted in the place of global data?
5. Determine the pressure category for any additional stressors in your study area, and add it to the pressures matrix.
6. When all stressors are included in the pressures matrix, determine which goals it affects. Then, determine the weight rankings of all stressors for each goal. Use literature and expert judgement to determine this.
7. Prepare each pressure data layer as described in this manual only after steps 1-6 are completed. In addition to the proper formatting for the Toolbox, pressures data must be rescaled (normalized) on a unitless scale from 0 - 1, where 0 is no stressor at all and 1 is the highest possible value for the stressor, or the value at which the goal achievement is completely impaired. You will have to determine how to rescale the data, whether it is based on the highest value in the data range or other methods.

#### Including pressures from global assessments

If you are not able to find local data for stressors, you may use the data from the global assessments for your country. For most of the stressors, this means that there will not be differences between the regions within your study area. However, several stressors included in the global assessment are based on spatial data at high resolution from previous work by Halpern *et al.* (2008) in *Science:* [A global map of human impact on marine ecosystems](http://www.sciencemag.org/content/319/5865/948.abstract). These data are available at a resolution of 1 km^2 for the entire global ocean, and can be extracted for the regions in your study area. The stressors available at 1km^2 resolution are indicated below with ** \*\* **.

**Table of pressures layers and descriptions**

|layer            |name                                                                                              |
|:----------------|:-------------------------------------------------------------------------------------------------|
|cc_acid**        |Ocean acidification                                                                               |
|cc_slr**         |Sea level rise                                                                                    |
|cc_sst**         |Sea surface temperature (SST) anomalies                                                           |
|cc_uv**          |UV radiation                                                                                      |
|fp_art_hb        |High bycatch caused by artisanal fishing                                                          |
|fp_art_lb        |Low bycatch caused by artisanal fishing                                                           |
|fp_com_hb        |High bycatch caused by commercial fishing                                                         |
|fp_com_lb        |Low bycatch caused by commercial fishing                                                          |
|fp_targetharvest |Targeted harvest of cetaceans and sea turtles                                                     |
|hd_intertidal    |Coastal population density as a proxy for intertidal habitat destruction                          |
|hd_subtidal_hb   |High bycatch artisanal fishing practices as a proxy for subtidal hard bottom habitat destruction  |
|hd_subtidal_sb   |High bycatch commercial fishing practices as a proxy for subtidal soft bottom habitat destruction |
|po_chemicals**   |Ocean-based chemical pollution                                                                    |
|po_chemicals_3nm** |Land-based chemical pollution                                                                     |
|po_nutrients**   |Ocean nutrient pollution                                                                          |
|po_nutrients_3nm** |Coastal nutrient pollution                                                                        |
|po_pathogens     |Access to improved sanitation as a proxy for pathogen pollution                                   |
|po_trash         |Trash pollution                                                                                   |
|sp_alien         |Alien species                                                                                     |
|sp_genetic       |Introduced species as a proxy for genetic escapes                                                 |
|ss_wgi           |Weakness of governance indicated with the WGI                                                     |


Note that chemical and nutrient pollution have both land-based (within 3 nautical miles) and ocean-based (within the entire 200 nautical mile EEZ) elements. This is because how pollution affects different goals will depend on the spatial scale of the goal's activity. Some goals occur far from shore, and nutrient and chemical pollution should be included for all offshore waters: FIS, MAR, ECO, and SPP. However, some goals are really only relevant nearshore, so nutrient and chemical pollution should only be included close to the shoreline (3nm in the global study): AO, CS, CP, TR, ICO, LSP, HAB.

These distinctions won't always apply for smaller-scale assessments. For example, in the US West Coast study (Halpern *et al.* 2014), we did not distinguish between offshore and 3nm and therefore only used the `po_nutrients` data layer.


##Guide to searching for resilience metrics

###Ideal Approach

Ideally, assessments of social resilience would include national-level and as well as local rules and other relevant institutional mechanisms that are meant to safeguard ocean health. The global focus has been on international treaties and indices, so your region should have more localized information. There would also be information as to their effectiveness and enforcement. of more. Information on social norms and community (and other local-scale) institutions (such as tenure or use rights) that influence resource use and management would be useful too.

#### Practical Considerations

In practical terms, resilience is hard to define and finding data can be difficult. It is often difficult to find regulations and indicators that would directly 'balance' individual stressors, but it is worth the effort to explore what information is available in the local context and how it could be included as resilience measures. You may be able to construct your own set of indicators for resilience (particularly social resilience) using proxy data. Your team may have to get creative to develop appropriate assessment measures here. It can be metrically be defined as presence-versus-absence (value of zero or one), or on a scale (value between zero and one) if the measure is an assessment or score. For instance in the global study,  resilience measures that were counted in the socio-economic resilience class of data came from the World Governance Indicators (http://govindicators.org). In a regional context, however, a more appropriate data layer might be a local governance index of some kind, preferably developed by a reputable organization using credible methods.

When available, National-level data are preferable to global-level data for your assessment. These include national laws on the environment, or protection of the marine environment or rivers that lead to coastal waters. National laws include things like the Clean Water Act (CWA) and the Endangered Species Act (ESA) in the U.S., or the national implementations of the E.U. Water Framework Directive. National actions can also be broadened beyond just legislation to include administrative procedures such as those involving permits, licenses, court cases, administrative action, and compliance mechanisms. [Cultural items at the national scale, such as holidays, are also applied at this scale]

State or province-level laws provide more regionally-specific information and thus work well for assessments. This would involve looking at the same types of laws and policies that exist on the national level, but specifically incorporating those that have been tailored to fit the needs of a particular sub-national area. This includes things such as California's state-level California Environmental Quality Act (CEQA), or the California Ocean Protection Act (COPA), which have laws designed specifically to protect California's environment. This would tell you more relevant information than using data from a national or international law. Local level regulations will usually provide you with the most accurate information for your assessment in order to tailor it best to the local context.

#### Scoring: Turning Qualitative into Quantitative

There are several ways to turn the qualitative information of regulations and social actions into quantitative metrics for analysis. A  robust way is to give credit for different aspects of the resilience measures. In addition to a score for having the law, policy, or action, in place, it is possible to gauge the effectiveness of that activity.

The simplest way is to give credit for having a resilience measure in place. This means assigning a binary score of zero or one for "presence" versus "absence" of the resilience measure. For international conventions, this can be done by assigning a value of 1 for having signed a convention. A more rigorous score can be given for countries that have further *ratified* a convention in addition to signing it; this is one way to further differentiate scores. This can be done by seeing if a country has signed and ratified CITES, for example.

> For example, if you were trying to find out if there are regulations in place that guide fishing pressure, you could look see if regulations exist for trawl-fishing limitations, or see if there are regulations for fish size, length, or if there are any seasonal restrictions. Another option would be to see if formal stock assessments exist for commercially-fished species.

A further step is to assess how well those measures are being complied with. This will give you more robust way is to assess how well a resilience  mechanism is working to maintain the integrity of the regulation and thereby the ecosystem.

> For example, once you have found out whether regulations for fishing pressure exist, you would then try to find values for compliance with these regulations. These could be raw data or calculated statistics such as rate of compliance or proportion of compliance. It should answer the question, "Are there indicators of compliance with fishing pressure guidelines"?

A subsequent, and final, step to creating a robust resilience assessment is to determine whether there are enforcement mechanisms in place to deal with non-compliance of the regulations. This is because a regulation is only as good as its implementation, and having both enforcement and compliance actions in place would reinforce the regulation and make it more effective.

> For example, in the case of fishing pressures, a further look into available data could lead you learn whether there are reported values of inspector visits and enforcement coverage of permitted facilities. Or you could look at reported numbers of enforcement actions in response to non-compliance. Further, you could also see if there are fines that have been paid or exist in association with non-compliance.

#### Data sources

<!---Link to Courtney's Google Doc-->

Environmental laws and policies offer tangible information on resilience. The most common type of environmental regulations come from administrative law, such as pollution regulation of various kinds. Land-use law is also important to the integration of social and ecosystem issues, so finding zoning laws relevant for coastal areas could be useful, and so could finding whether or not a region requires environmental impact statements before allowing construction for either coastal land or for marine planning. Other kinds of law some countries include court cases settling disputes or requiring reparation of pollution damages, for example.

Resilience also goes beyond just the law, however. Insurance policies present another option, for instance.. Coastal areas are increasingly requiring climate-related insurance in some countries, and so the existence of such markets in a vulnerable area would be an example of a climate change resilience measure. Social initiatives also present another way to tackle resilience. There might be a beach clean-up day, a percentage of the refuse material that is recycled by the population, or some other social factor that reduces trash inputs into the ocean. A local law banning plastic bags is another way that local jurisdictions control plastic trash.

> In the Brazil study (2014), the marine trash resilience was calculated by counting up whether localities had one of four garbage management services, including access to beach clean-up services, household garbage collection, household recycling collection, and garbage collection in public streets. <!---Julie's MS--->

### Incorporating local resilience measures in your assessment

1. Begin by exploring how resilience could be measured in your study area. What laws and regulations are in place that could provide resilience to ocean health?
2. Are there locally-developed indices that capture social or ecological resilience? Is there information about how each region in your study area are implementing or enforcing the laws?
3. Evaluate the resilience measures are included in the global assessment. Are all of them relevant? Are there local data that can be substituted in the place of global data? Are there resilience measures that should be excluded entirely?
4. Assign the resilience measure to the appropriate goal. Since resilience measures are in response to pressures that have a weight rank of 2 or 3 effect on a certain goal, determining which goals ecological and social resilience measures effect follows the same pattern as the pressures matrix. For goal-specific resilience measures, assign the resilience measure to the appropriate goal.
5. Prepare each resilience data layer only after steps 1-6 are completed. In addition to the proper formatting for the Toolbox, resilience data must be rescaled (normalized) on a unitless scale from 0 - 1. You will have to determine how to rescale the data, whether it is based on the highest value in the data range or other methods.

#### Including resilience measures from global assessments

Remember that local measures are far more appropriate than those included in global assessments, which likely do not reflect local management targets. However, international data were used in the global assessments that are available to you if you cannot find better local data:

**Table of resilience layers and descriptions**

|layer                 |name                                                            |
|:---------------------|:---------------------------------------------------------------|
|alien_species         |Alien species                                                   |
|cites                 |Resilience from commitment to CITES                             |
|fishing_v1            |CBD survey: coastal fishing v1                                  |
|fishing_v1_eez        |CBD survey: ocean fishing v1                                    |
|fishing_v2_eez        |CBD survey: ocean fishing v2                                    |
|fishing_v3            |CBD survey: coastal fishing v3                                  |
|fishing_v3_eez        |CBD survey: ocean fishing v3                                    |
|habitat               |CBD survey: habitat                                             |
|habitat_combo         |CBD survey: coastal habitat                                     |
|habitat_combo_eez     |CBD survey: ocean habitat                                       |
|li_gci                |GCI: competitiveness in achieving sustained economic prosperity |
|li_sector_evenness    |Sector evenness as a measure of economic diversity              |
|mariculture           |CBD survey: mariculture                                         |
|msi_gov               |MSI sustainability and regulations                             |
|species_diversity     |Ocean ecological integrity                                      |
|species_diversity_3nm |Coastal ecological integrity                                    |
|tourism               |CBD survey: tourism                                             |
|water                 |CBD survey: water                                               |
|wgi_all               |Strength of governance indicated with the WGI                   |

\* *CBD = Convention on Biological Diversity; GCI = Global Competitiveness Index; MSI = Mariculture Sustainability Index; WGI = World Governance Indicators*.

# The Ocean Health Index Toolbox

>**Section Summary:**

>In this section, you will learn the basics of how to use OHI tools for conducting an assessment. You will be introduced to the files you will be working with, how to prepare them, and you will learn how concepts such as status, trend, pressures, and resilience are used together to create the final score. You will also learn what to do in cases of missing data.

> TIP: Knowing where your data gaps are will make gapfilling easier in this process.

**The OHI Toolbox** is an ecosystem of data, scripts, and structure required to calculate OHI scores at any scale. Toolbox scripts are open source, written in the software language R, and data inputted into the Toolbox are **comma-separated-value**, or *.csv* files, which can be created or edited using text editors or Microsoft Excel. Files are stored within two folders called **repositories**, or *(repos)*, such that

> OHI Toolbox = your assessment repo + `ohi core functions` repo.

We access and interact with the Toolbox ecosystem through an online collaborative platform called **GitHub**. GitHub stores the **R** scripts and *.csv* files in a folder called a repository, which is found online and can also be downloaded on your computer and synced with the online version. GitHub tracks changes by all collaborators working on the project through time, and saves all versions for comparison. The section, "**Installing the Toolbox**," provides instruction on how to download GitHub repositories to your computer, but everything is also available online.  

The Toolbox is used to calculate final scores. But, perhaps more importantly, it can also be used to organize an assessment, including data identification and management.  The Toolbox can additionally be used to compare how different management scenarios could affect overall ocean health, which can inform effective strategies for ocean resource management at a local scale.

## File System for Assessment Repositories

This section is an orientation to the files within your assessment repository. The file system structure is the same whether you view your assessment repository online or after downloading or cloning to your computer (see section, **"Installing the Toolbox"**).

Throughout this example, we will use Ecuador’s assessment repository as a guide. It's available at https://github.com/OHI-Science/ecu.

> TIP: Once you know the layout of the repository and the purpose of the files within it, you can plan an appropriate workflow with your team. See the **Using the Toolbox** introduction for more.

### Assessments and scenarios

Your *assessment repository* contains a *scenario folder*, which by default is named `subcountry2014`. This scenario folder contains all the files needed to calculate scores, and they are described in detail below.

The scenario folder is named `subcountry2014` because it contains data for your country used in the 2014 global assessment. These data in most cases were attributed equally to all regions within your study area (for example, data used for Ecuador in the global assessment was attributed to all coastal states in the files within `subcountry2014`).

You will be able to rename your scenario folder to better reflect the spatial and temporal scale of your scenario after you have set up your GitHub account. We recommend that the name defines the scale of the regions and the year. Eventually, you will likely have multiple scenario folders that contain data for subsequent years or modifications to explore policy alternatives.


![](https://docs.google.com/drawings/d/1eHViTehnAuxSDw1fYI54C3X5YgBktGtaVt71R3OXYeE/pub?w=960&h=720)

In the above figure, `ecu` is the **assessment repository** and `subcountry2014` is the **scenario folder**. Note that files with names preceded by a ‘.’ do not appear when not viewing from github.com; this is because these files are specific to GitHub.

![Navigating the assessment repository. The figure shows Mac folder navigation above and Windows navigation below. ](https://docs.google.com/drawings/d/13536h0d6hahYCBrxIItlG_q-r9FmezfN1lcpf-5BMHc/pub?w=692&h=820)

Within the `subcountry2014` folder area all the inputs required by the Toolbox. See **Modifying and Creating Data Layers** for more information on the  files you will commonly modify.


### *layers.csv*

> TIP: Keep `layers.csv` handy. It's a very useful reference throughout the assessment process.

`layers.csv` is the registry that manages all data required for the assessment. All relevant data are prepared as a ‘data layer’ and registered in this file. The Toolbox will rely on information from this file to use the data layers and display information on the WebApp. You will update some of the layers in `layers.csv`, and some of them will be auto-generated by the Toolbox code when it's running.

![](./fig/layers_csv_registry.png)

When you open `layers.csv`, you’ll see that each row of information represents a specific data layer that has been prepared for the Toolbox. The first columns (*targets, layer, name, description, fld_value, units, filename*) contain information that will be updated by your team as you incorporate your own data and edits; all other columns are generated later by the Toolbox as it confirms data formatting and content. The first columns have the following information:

* **targets** indicates which goal or dimension uses the data layer. Goals are indicated with two-letter codes and sub-goals are indicated with three-letter codes, with pressures, resilience, and spatial layers indicated separately.
 + Food Provision (FP): Fisheries (FIS) and Mariculture (MAR)
  + Artisanal Fishing Opportunity (AO)
  + Natural Products (NP)
  + Coastal Protection (CP)
  + Carbon Storage (CS)
  + Livelihoods and Economies (LE): Livelihoods (LIV) and Economies (ECO)
  + Tourism and Recreation (TR)
  + Sense of Place: Lasting Special Places (LSP) and Iconic Species (ICO)
  + Clean Waters (CW)
  + Biodiversity (BD): Habitats (HAB) and Species (SPP)  

* **layer** is the identifying name of the data layer, which will be used in R scripts like `functions.R` and *.csv* files like `pressures_matrix.csv` and `resilience_matrix.csv`. This is also displayed on the WebApp under the drop-down menu when the variable type is ‘input layer’.
* **name** is a longer title of the data layer; this is displayed on the WebApp under the drop-down menu when the variable type is ‘input layer’.
* **description** is further description of the data layer; this is also displayed on the WebApp under the drop-down menu when the variable type is ‘input layer’.
* **fld_value** indicates the units along with the units column.
* **units** unit of measure in which the data are reported.
* **filename** is the *.csv* filename that holds the data layer information, and is located in the folder `subcountry2014/layers`.


### *layers* folder
The `layers` folder contains every data layer as an individual *.csv* file. The names of the *.csv* files within the layers folder correspond to those listed in the *filename* column of the `layers.csv` file described above. All *.csv* files can be read with text editors or with Microsoft Excel or similar software.

![The `layers` folder contains every data layer as an individual *.csv* file. Mac navigation is shown on the left and Windows navigation is shown on the right.](https://docs.google.com/drawings/d/151Hw1Eb13T4KgndEKXM31BDjvdbB5JO7VGneqdUwGQU/pub?w=1702&h=476)

Note that each *.csv* file within the `layers` folder has a specific format that the Toolbox expects and requires. Comma separated value files (*.csv* files) can be opened with text editor software, or will open by default by Microsoft Excel or similar software.  

Now, open the `layers/alien_species.csv` file: note the unique region identifier (*rgn_id*) with a single associated *score* or *value*, and that the data are presented in ‘long format’ with minimal columns. See the section on *Formatting Data for the Toolbox* for further details and instructions. Scores can be viewed through the WebApp  using the ‘Input Layer’ pulldown menu on the App page.

> TIP: You can check your region identifiers (*rgn_id*) in the `rgn_labels.csv` file in the `layers` folder.

### *conf* folder
The `conf` (configuration) folder includes R functions (`config.R` and `functions.R`) and *.csv* files containing information that will be accessed by the R functions (`goals.csv`, `pressures_matrix.csv`, `resilience_matrix.csv`, and `resilience_weights.csv`).

![The `conf` folder contains important R functions and *.csv* files. Mac navigation is shown on the left and Windows is shown on the right.](./fig/layers_folder_location_conf.png)

#### *config.R*
`config.R` is an R script that configures labeling and constants appropriately.

#### *functions.R*
`functions.R` contains functions for each goal and sub-goal model, which calculate the status and trend using data layers identified as ‘layers’ in `layers.csv`. When you modify or develop new goal models, you will modify `functions.R`.

> TIP: It's useful to skip to different sections of `functions.R` to see how key calculations are being done. See section, **Update *Functions.R***.

#### *goals.csv*
`goals.csv` is a list of goals and sub-goals and their weights used to calculate the final score for each goal. Other information includes the goal description that is also presented in the WebApp. `goals.csv` also indicates the arguments passed to `functions.R`. These are indicated by two columns: *preindex_function* (functions for all goals that do not have sub-goals, and functions for all sub-goals) and *postindex_function* (functions for goals with sub-goals).

> TIP: It's important to check the weightings and preindex functions if you're planning to change the goal or sub-goal models.

#### *pressures_matrix.csv*
`pressures_matrix.csv` defines the different types of ocean pressures and the goals they affect.

Each column in the pressures matrix identifies a data layer that is also registered in `layers.csv`: and has a prefix (for example: `po_` for the pollution category).  The pressure data layers are also required to have a value for every region in the study area, with the region scores ranging from 0-1.

#### *resilience_matrix.csv*
`resilience_matrix.csv` defines the different types of resilience with the goals that they affect.

Like the pressures matrix, the resilience matrix also has weights depending on the level of protection. However, these weights are in a separate file: `resilience_weights.csv`.

Each column in the resilience matrix is a data layer that is also registered in `layers.csv`. Resilience layers, like the pressure layers, are also required to have a value for every region in the study area. Resilience layers each have a score between 0-1.

#### *resilience_weights.csv*
`resilience_weights.csv` describes the weight of various resilience layers, which in Halpern *et al*. 2012 (*Nature*) were determined based on scientific literature and expert opinion.

### *install_ohicore.R*
This script will install `ohicore`, the engine behind all Toolbox calculations. You will only need to run this script only one time.

### *launch_app_code.R*
The Toolbox can be launched on your computer so that you can visualize any edits you make while you are offline. To do this, you will run the code in `launch_app_code.R`. Make sure you are in the `subcountry2014` directory at that time: `setwd(~/github/ecu/subcountry2014)`

### *calculate_scores.R*
`calculate_scores.R` is a script that tells the Toolbox to calculate scores using the *.csv* files in the `layers` folder that are registered in `layers.csv` and the configurations identified in `config.R`. Scores will be saved in `scores.csv`.

> TIP: You can use the *layers* function in `calculate_scores.R` to error-check whether you have registered your files in `layers.csv` correctly or not. If you haven't, you will get an error message regarding 'missing files'.

![You can error-check your data layer registration if you see a 'missing files' warning when running `calculate_scores.R`.](https://docs.google.com/drawings/d/1c0xQtANDy-rd6y5MOkW7eBNZbN47vvaaMZjYiDDU_0M/pub?w=758&h=665)

### *scores.csv*
`scores.csv` contains the calculated scores for the assessment. Currently, these scores were calculated using data for your country from the global 2014 assessment. Scores are reported for each dimension (future, pressures, resilience, score, status, trend) for each region in the study area (with region identifier), and are presented in ‘long’ format. Scores can be viewed through the WebApp using the ‘Output Score’ pulldown menu on the 'App' page.

### *spatial* folder
The spatial folder contains a single file, `regions_gcs.js`. This is a spatial file in the JSON format; it spatially identifies the study area and regions for the assessment. If you plan to modify your study area or regions, you will need to upload a *.js* file with appropriate offshore boundaries. You will need a GIS analyst to do this: see http://ohi-science.org/pages/create_regions.html for some instruction.

### *layers-empty_swapping-global-mean.csv*
This file contains a list of data layers that were used in the global assessment while not for your country. Without these data for your country, global averages are included in your `subcountry2014` scenario folder so the Toolbox can calculate scores until you replace these data with appropriate data for your study area. This file is not used anywhere by the Toolbox but is a registry of data layers that should prioritized to be replaced with your own local data layers.

### Relaunching the Toolbox
After the initial Toolbox setup, further launches of the Toolbox can be done without the software program R. Instead, PC users can double-click the `launchApp.bat` file and Mac users can double-click the `launchApp.command` file.

## Formatting Data for the Toolbox

### Introduction

The OHI Toolbox is designed to work in the programming language **R** using input data stored in text-based *.csv* files (*csv* stands for 'comma-separated value'; these files can be opened as a spreadsheet using Microsoft Excel or similar programs). Each data layer (data input) has its own *.csv* file, which is combined with others within the Toolbox for the model calculations. These data layers are used for calculating goal scores, meaning that they are inputs for status, trend, pressures, and resilience. The global analysis included over 100 data layer files, and there will probably be as many in your own assessments. This section describes and provides examples of how to format the data layers for the Toolbox.

OHI goal scores are calculated at the scale of the reporting unit, which is called a ‘**region**’ and then combined using an area-weighted average to produce the score for the overall area assessed, called a ‘**study area**’. The OHI Toolbox expects each data file to be in a specific format, with data available for every region within the study area, with data layers organized in 'long' format (as few columns as possible), and with a unique region identifier (*rgn_id*) associated with a single *score* or *value*. In order to calculate trend, input data must be available as a time series for at least 5 recent years (and the longer the time series the better, as this can be used in setting temporal reference points).

The example below shows information for a study area with 4 regions. There are two different (and separate) data layer files: tourism count (`tr_total.csv`) and natural products harvested, in metric tonnes (`np_harvest_tonnes.csv`). Each file has data for four regions (1-4) in different years, and the second has an additional 'categories' column for the different types of natural products that were harvested. In this example, the two data layers are appropriate for status calculations with the Toolbox because:

1. At least five years of data are available,
2. There are no data gaps
3. Data are presented in 'long' or 'narrow' format (not 'wide' format -- see "**Long Formatting**"" section).

**Example of data in the appropriate format:**

![](./fig/formatting_data_example.png)

### Gapfilling

It is important that data prepared for the Toolbox have no missing values or 'gaps'. Data gaps can occur in two main ways: 1) **temporal gaps**: when several years in a time series in a single region have missing data, and 2) **spatial gaps**: when all years for a region have missing data (and therefore the whole region is 'missing' for that data layer).

How these gaps are filled will depend on the data and regions themselves, and requires thoughtful, logical  decisions to most reasonably fill gaps. Each data layer can be gapfilled using different approaches. Some data layers will require both temporal and spatial gapfilling. The examples below highlight some example of temporal and spatial gapfilling.  

All decisions of gapfilling should be documented to ensure transparency and reproducibility. The examples below are in Excel, but programming these changes in software like R is preferred because it promotes easy transparency and reproducibility.

#### Temporal gapfilling

Temporal gaps occur when a region is missing data for some years. The Toolbox requires data for each year for every region. It is important to make an informed decision about how to temporally gapfill data.

![](./fig/temporal_gaps.png)

Often, regression models are the best way to estimate data and fill temporal gaps. Here we give an example that assumes a linear relationship between the year and value variables within a region. If data do not fit a linear framework, other models may be fit to help with gapfilling. Here we give an example assuming linearity.

Using a linear model can be done in most programming languages using specific functions, but here we show this step-by-step using functions in Excel for Region 1.

**Temporal gapfilling example (assumes linearity: able to be represented by a straight line on a graph)):**

There are four steps to temporally gapfill with a linear model, illustrated in the figures with four columns.

**1. Calculate the slope for each region**

The first step is to calculate the slope of the line that is fitted through the available data points. This can be done in Excel using the **SLOPE(known_y's,known_x's)** function as highlighted in the figure below. In this case, the x-axis is *years* (2005, 2006, etc...), the y-axis is *count*, and the Excel function automatically plots and fits a line through the known values (177.14 in 2005, 212.99 in 2008, and 228.81 in 2009), and subsequently calculates the slope (12.69).

![](./fig/filling_temporal_gaps_slope.png)

**2. Calculate the y-intercept for each region**

The next step is to calculate the intercept of the line that is fitted through the available data points. This can be done in Excel similarly as for the slope calculation, using the the **INTERCEPT(known_y's,known_x's)** function that calculates the y-intercept (-25273.89) of the fitted line.

![](./fig/filling_temporal_gaps_intercept.png)

**3. Calculate y for all years**

The slope and y-intercept that were calculated in steps 1 and 2 can then be used along with the year (independent variable) to calculate the unknown 'y-values'. To do so, simply replace the known three values into the **y = mx + b** equation (m=slope, x=year, b=intercept), to calculate the unknown 'count' for a given year (189.39 in 2006, and 202.08 in 2007).

![](./fig/filling_temporal_gaps_value.png)

**4. Replace modeled values into original data where gaps had occurred**

Substitute these modeled values that were previously gaps in the timeseriew. *The data layer is now ready for the Toolbox, gapfilled and in the appropriate format.*


#### Spatial gapfilling

Spatial gaps are when no data are available for a particular region. The Toolbox requires data for each region. It is important to make an informed decision about how to spatially gapfilling data.

![](./fig/gapfilling_spatial.png)

To fill gaps spatially, you must assume that one region is like another, and data from another region is adequate to be substituted in place of the missing data. This will depend on the type of data and the properties of the regions requiring gapfilling. For example, if a region is missing data but has similar properties to a different region that does have data, the missing data could be 'borrowed' from the region with information. Each data layer can be gapfilled using a different approach when necessary.  

**Characteristics of regions requiring gapfilling that can help determine which type of spatial gapfilling to use:**

1. proximity: can it be assumed that nearby regions have similar properties?

2. study area: are data reported for the study area, and can those data be used for subcountry regions?

3. demographic information: can it be assumed a region with a similar population size has similar data?


**Spatial gapfilling example:**

For a certain data layer, suppose the second region (*rgn_id 2*) has no data reported, as illustrated in the figure above. How to spatially gapfill *rgn_id 2* requires thinking about the properties and characteristics of the region and the data, in this case, tourist count.

Here are properties that can be important for decision making:

*rgn_id 2*:

- is located between *rgn_id 1* and 3
- is larger than *rgn_id 1*
- has similar population size/demographics to *rgn_id 3*
- has not been growing as quickly as *rgn_id 4*

There is no absolute answer of how to best gapfill *rgn_id 2*. Here are a few reasonable possibilities:

Assign *rgn_id 2* values from:

- *rgn_id 1* because it is in close proximity to *rgn_id 2*
- *rgn_id 3* because it is in close proximity to *rgn_id 2* and has similar population size/demographics
- *rgn_id 1* and 3 averaged since they are in close proximity to *rgn_id 2*

Suppose the decision was made to gapfill *rgn_id 2* using the mean of *rgn_id 1* and *3* since this would use a combination of both of those regions. Again, other possibilities could be equally correct. But some form of spatial gapfilling is required so a decision must be made. The image below illustrates this in Excel.

![](./fig/gapfilling_spatial_example.png)

The data layer is now ready for the Toolbox, gapfilled and in the appropriate format.  

### Long formatting

The Toolbox expects data to be in 'long' or 'narrow' format. Below are examples of correct and incorrect formatting, and tips on how to transform data into the appropriate format.

**Example of data in an incorrect format:**

![](./fig/formatting_long_example.png)

With 'wide' format, data layers are more difficult to combine with others and more difficult to read and to analyze.

**Transforming data into 'narrow' format:**

Data are easily transformed in a programming language such as R.

In R, the `reshape` package has the `melt` command, which will melt the data from a wide format into a narrow format. It also can `cast` the data back into a wide format if desired. R documentation:

- http://cran.r-project.org/web/packages/reshape2/reshape2.pdf
- http://www.slideshare.net/jeffreybreen/reshaping-data-in-r
- http://tgmstat.wordpress.com/2013/10/31/reshape-and-aggregate-data-with-the-r-package-reshape2/

Example code using the *melt* command in the *reshape2* library. Assume the data above is in a variable called *data_wide*:

![](./fig/melt_code.png)

This will melt everything except any identified columns (*Region* and *DataLayer*), and put all other column headers into a new column named *Year*. Data values will then be found in a new column called *value*.

The final step is optional: ordering the data will make it easier for humans to read (R and the Toolbox can read these data without this final step):

**Example of data in the appropriate (long) format:**

![](./fig/formatting_long_example_2.png)

### Rescaling your data

<!---Notes from Github issue 389. Katie, develop--->

An important consideration is how to rescale your data when preparing it for use in the Toolbox. Rescaling involves turning a distribution of data into a value from zero to one. This is based on finding a highest observed or theoretical point in the distribution of the data, and from there, the relative value of the data can be calculated.

<!---Insert example: Data normalization; example with you rescaling to max, or to higher than max.--->

#### Example: Global Data Approach

You should base your decision on whether your consider it more appropriate to decide the reference point based on the data distribution of all data points, be they observed or interpolated, or whether we think we should only consider the observed data. If the interpolation covers large areas, and these get assigned values that aren't very frequent in the observed data, then the two distributions will be very different, and what value is in the 99.99th percentile is different too.

In theory, one would favor deciding the reference point based on as many observations as possible (i.e., interpolate first, then obtain the percentile). In practice, if we think that large interpolated areas are very unreliable, we might prefer to use real observations only (i.e., percentile first, then interpolate).

<!---Develop--->

# Installing the Toolbox

>**Section Summary:**

>In this section, you will learn how to successfully download, install, and use the software required to conduct an assessment. You will create a GitHub account and install R, RStudio, git, and the Github desktop  app. OHI assessments are conducted through open-source platforms that allow you to make real-time changes with collaborators, and to track progress so that errors can be corrected and new insights can be shared in the future.

## Overview

The **OHI Toolbox** is essentially several folders containing all the files required for an OHI assessment. These folders are stored online on www.github.com, and are called **GitHub repositories**. At this point, you should already be familiar with your assessment’s repository, and all of the files it contains (if not, read the section, "**File System for Assessment Repositories**").  

Conducting an OHI assessment using GitHub enables collaboration and transparency, and will provide access to the latest developments in the Toolbox software, allowing the OHI team to provide support remotely if necessary.  

This section explains the GitHub workflow and how to access and setup required software. Then, it explains how to after modifying files on your own computer, you can use GitHub to upload any modifications you make so that you can work collaboratively with your team.  

**Required software:**

1. **Github App**
2. ** *git* **
3. **R**
4. **RStudio**

> ![](./fig/overview_requirements_1.png)

## GitHub

**GitHub** is an open-source development platform that enables easy collaboration and versioning, which means that all saved versions are archived and attributed to each user. It is possible to revert back to any previous version, which is incredibly useful to not only to document what work has been done, but how it differs from work done in the past, and who is responsible for the changes.  

**GitHub Vocabulary:**

* **clone** ~ download to your computer from online version with synching capabilities enabled
* **commit** ~ message associated with your changes at a point in time
* **pull** ~ sync a repo on your computer with online version
* **push** ~ sync the online repo with your version, only possible after committing

**sync = pull + commit + push**

### Learning GitHub
The following section describes how to use GitHub to access and sync your assessment repository. There are also many great resources available online with more in-depth information:

* [**Git and GitHub**](http://r-pkgs.had.co.nz/git.html) by Hadley Wickham: http://r-pkgs.had.co.nz/git.html
* [**Collaboration and Time Travel: Version Control with Git, GitHub and RStudio**](http://www.rstudio.com/resources/webinars/) video tutorial by Hadley Wickham: www.rstudio.com/resources/webinars
* [**Good Resources for Learning Git and GitHub**](https://help.github.com/articles/good-resources-for-learning-git-and-github/) by GitHub: https://help.github.com/articles/good-resources-for-learning-git-and-github/

## Accessing GitHub Repositories

GitHub has an online interface and a desktop application for the version-control software called ** *git*. ** In addition to cloning your GitHub repository to your computer, you will need to download and install *git* software and the GitHub App (application), both of which are freely available.


### Create a GitHub account

Create a GitHub account at http://github.com. Choose a username and password. You will use this username and password when you install and set up *git* on your computer.


### Install *git* software

How you install *git* will depend on whether you are working on a Windows or Mac computer. It will also depend on your operating system version. If you have problems following these instructions, it is likely because your operating system requires a previous version of *git*. Previous versions are available from http://www.wandisco.com/git/download (you will need to provide your email address).

**For Windows:**

* Download *git* at http://git-scm.com/downloads and follow the install instructions.

* When running the Windows installer, use all default options except "Adjusting your PATH environment": instead, select "_**Run Git from the Windows Command Prompt**_". This will allow later compatibility with RStudio.  

  > ![](./fig/git_install_win_option.png)

**For Mac:**

* Download *git* at http://git-scm.com/downloads and follow the install instructions.
* Apple's [Xcode](https://developer.apple.com/xcode/) has a command line tools option during install which can override the preferred *git* command line tools. To ensure you are using the latest preferred version of *git*, you will need to launch  Terminal and type the following few lines of code:
* Access Terminal from the Applications folder: **Applications > Utilities > Terminal**. When you launch Terminal a window will appear with your computer’s name followed by a `$`. When you type, your commands will appear after the `$`.

Add access your 'bash profile' by typing:

```
pico ~/.bash_profile
```

You are now able to edit your ‘bash profile’. Type:

```
export PATH=/usr/local/git/bin:$PATH
```

Exit pico by typing:

> control-X  
y  
return/enter


Exit Terminal by typing:

```
exit
```

Finally, quit Terminal.

![](./fig/terminal_pico.png)


### Set up your Git Identity

After downloading and installing *git*, you will need to set up your **Git Identity**, which identifies you with your work. *Note*: if you have any problems with the following instructions, it is likely because of incompatibility between the version of your operating system and the version of git you downloaded in the previous section. In this case, find and download a compatible version at [www.wandisco.com/git/download](www.wandisco.com/git/download) and then follow the instructions below.

You will set up your GitHub identity using the command line specific to Windows or Mac:

* **Windows**: Start > Run > cmd
* **Mac**: Applications > Utilities > Terminal

In the window, you will see a cursor where you are able to type. Type the following and press return (or enter) at each step. Make sure all spaces and symbols are identical to the example below, including all spaces ( ) and dashes (-).

Substitute your GitHub username instead of jdoe:
```
git config --global user.name jdoe
```
and then: substitute the email address you used to create your GitHub account:
```
git config --global user.email johndoe@example.com
```

You can check settings with the following:

```
git config --list
```

Quit the Terminal after typing:
```
exit
```

### Install the GitHub application

There are several options to clone your repository to your local machine. When getting started, we recommend using the GitHub application. This is freely available for download. Follow the default instructions for downloading and installing from the following:

* **Windows**: https://windows.github.com/.

* **Mac**: https://mac.github.com/.

### Create a folder called *github* on your computer

Because you will use GitHub to collaborate with your team or request support from the OHI team, it is important you save files in places where the file path that is universal and not specific to your computer. When team members save files in different places, this will create a lot of problems when collaborating, particularly between Macs and Windows machines.

**Please create a folder called github in your root directory**. The file path for this folder will be:

* **Windows**: `Users\[User]\Documents\github\`
* **Mac**: `Users/[User]/github/`

This folder can be identified by any computer as `~/github/`.  

> TIP: You can check the location of your `github` folder by right-clicking the folder icon and selecting 'Get Info' on a Mac or 'Properties' on Windows.

### Clone your repository to your computer


Clone a repository by clicking the 'Clone in Desktop' button on your online repository's homepage (https://github.com/OHI-Science/[assessment]):

> ![](https://docs.google.com/drawings/d/1sGEwp5wX0q3BJCy_J51FjS3km7fh7sx3k3jD9CBguBg/pub?w=384&h=288)

You will be asked where to save this repository: save it into the `github` folder you created. The file path for your assessment will therefore be:

* Windows: C: `\Users\[User]\Documents\github\[assessment] (example: C:\Users\johndoe\Documents\github\ecu)`
* on a Mac: `/Users/[User]/github/[assessment] (example: /Users/johndoe/github/ecu)`

The assessment can be identified by any computer as `~/github/[assessment]`.  

The entire folder will now be saved on your computer.


### Update permissions

You need to **email your username to ohi-science@nceas.ucsb.edu** for permission to upload modifications to your GitHub repository (you only need to do this once). Only team members who will be modifying files will need to do this; all other members can view online and download the repository without these permissions.  

### Work locally

You will then work locally on your own computer, modifying the files in the repository to reflect the desired modifications your team has identified for your assessment. Multiple users can work on the same repository at the same time, so there are steps involved to 'check in' your modifications so they can merge with the work of others without problems. GitHub has specific words for each of these steps. You have already successfully **cloned** an online repository to your local machine. After making modifications, you will **commit** these changes with a description before being able to sync back to the online repository. **Synching** involves both **pulling** any updates from the online repository before **pushing** committed changes back to the server.

> TIP: While you can edit files in the online GitHub repository, we do not recommend this. It is good practice to track changes through commits and syncing.

The example below illustrates GitHub's collaborative workflow with the `ohi-israel` repo owned by `OHI-Science`:

> > > ![](./fig/clone_push_pull.png)

**All changes within your local repository will be tracked by GitHub regardless of the software you use to make the changes**. This means that you can delete or paste files in the Mac Finder or Windows Explorer and edit *.csv* files in Excel or a text editor, and still sync these changes with the online repository. We recommend doing as much data manipulation as possible in a programming language like R, to maximize transparency and reproducibility. When modifying R scripts such as `functions.R`, you will need to work in R.

We recommend syncing with either the GitHub App or with RStudio. Both methods require you to commit your changes, before pulling any updates and pushing your modifications. The GitHub App combines the pulling and pushing into one step, called syncing. The following sections show you how to synchronize the repository on your computer with the repository online.

### Syncing

When you work on your computer, any edits you make to any files in your repo, using any program, will be tracked by *git*. You can use any of the above to commit and sync your changes back to GitHub. There are many options you can use to sync your edits on a repo with the online version.

* **GitHub App** [for Mac](https://mac.github.com/) and [for Windows](https://windows.github.com/)
* [**RStudio**](www.rstudio.com)
* **Command line**

If you are just modifying data *.csv* files, you probably only need to use the GitHub App. RStudio is convenient if you are working with *.R* files. Also, the command line can be used by those interested, and there are resources available online.

> TIP: Once you sync your repository, the updated information will be automatically available to the WebApps.

### Using the GitHub App to synchronize your repository

The GitHub App will track your modifications and can be used to commit and sync any changes made locally to your repository.  Once you are done working on the pertinent files and wish to commit and sync the changes to the online server on the Github server, open the GitHub App. The following example is with the `ecu` repository:

1. Make sure you select the correct repository, located on the left column of the GitHub App window (Step 1 in the figure).
2. Select the different files to which changes have been made (2a), and preview those changes on the right column of the GitHub App window (2b).
3. Once all the changes have been reviewed, write a summary/description in the respective message bars in the GitHub App window (3), then click on 'Commit' (3a) and then 'Sync' (3b) located on the top-right corner of the GitHub App window (Note: If a `Commit` button appears instead of `Commit & Sync`, you can either click `Commit` and then click the `Sync` in this way, or you can alternatively select *Edit* > *Automatically Sync After Committing* which will then allow you to click on 'Commit and Sync')

> ![Figure showing the layout of the GitHub App when syncing. Click on 'Commit' and then 'Sync' to push changes to your repository.](https://docs.google.com/drawings/d/1-I-x8ML1QUR13AEAibn5OUX-bbHpdSIw1l6-fcMkO3o/pub?w=1033&h=665)

Go online and check that your changes are now visible on GitHub online.

### Working with R and RStudio

**RStudio** is a program that can be used to synchronize any modifications you make to files in your assessment’s repository, and if you are working in R, it is convenient since you do not need to open the GitHub App.
If you do not already have this installed, install the latest version of R and RStudio (and if you do have these installed, check for updates: there are frequent updates to the R software, and the current version is identified on the website). Both R and RStudio are freely available to download.  

**R**: Download the current version of R appropriate for your operating system at http://cran.r-project.org/ and follow the instructions to install it on your computer. If updating, compare the available version on their website with what you already have on your computer by typing sessionInfo() into your R console.  

**RStudio**: Download the current version of RStudio software at www.rstudio.com. RStudio is not updated as often as R, but it is good to check for updates regularly.  Note that in this case, you should follow the default install instructions.

If you are working on a Mac, you will need to tell RStudio to use the proper version of Git by doing the updating the preferences for 'Git executable':

**RStudio > Preferences... > Git/SVN > Git executable: /usr/local/git/bin/git**

### Using RStudio to synchronize your repository

RStudio can sync files with GitHub directly, and can be used instead of the GitHub App. Like the GitHub App, it will capture the changes made to any files within the repository, no matter which software was used to modify them. The advantage for using RStudio to sync instead of the GitHub App is if you are working with R scripts already. In RStudio, you sync by first pulling and then pushing (separately); in the GitHub App these two functions are done together.

Launch your project in RStudio by double-clicking the `.Rproj` file in the assessment folder on your local hard drive.

> ![](https://docs.google.com/drawings/d/11F2lbB1S56ccZK5CbCxga4SEiRoE6E0-3QtZO99p37A/pub?w=384&h=288)

When you modify or add a file, the file will appear in the 'Git' window once it has been saved. In the example below, the file `test.R` was created.

1. Clicking the 'Staged' box and the 'Commit' button opens a new window where you can review changes.
2. Type a commit message that is informative to the changes you've made.
  - Note 1: there will often be multiple files 'staged' at the same time, and so the same commit message will be associated with all of the updated files. It is best to commit changes often with informative commit messages.
  - Note 2: clicking on a staged file will identify additions and deletions within that file for your review
3. Click 'Commit' to commit the changes and the commit message
4. Pull any changes that have been made to the online repository. This is important to ensure there are no conflicts with updating the online repository.
5. Push your committed changes to the online repository. Your changes are now visible online.

> TIP: If you aren't seeing your changes in the 'Git' window, try saving the file again.

![Figure showing RStudio when sycing. After first staging your changes, click the 'commit' button to open a new window where you can enter a 'commit message' and then pull and push new changes. ](https://docs.google.com/drawings/d/1M9-87q0RZ_lPD8QEL3DIpoPgyh-w2rKPoF-5IFWFJfo/pub?w=1027&h=687)


> TIP: Another way to sync and open the project is to click on 'New Project' in the upper-right-hand corner of Rstudio,  then choose 'Version Control', and then you can paste the URL of the desired repository. This URL can be found on on your online repository's homepage.

### Install the latest version of R and RStudio

Make sure you have the most current version of R and RStudio. Download **R** at http://cran.r-project.org/ and install on your computer. If you already have R installed, check the website for updates. There are frequent updates to the R software, and the current version is identified on the website. Compare what is available from their website with what you already have on your computer by typing `sessionInfo()` into your R console. (This will also identify packages you have installed).  

While not required, we highly recommend working with **RStudio**, which is an interface that makes working with R much easier, and it also interfaces with GitHub so you are able to synchronize without using the GitHub App. RStudio does not get updated as often as R does, but it is good to check for updates regularly.

## GitHub repository architecture

GitHub stores all data files and scripts for your assessment in a repository (a folder). Different copies or complements to these folders, called *branches* can also exist, which aid with versioning and drafting. Your repository has four branches, two of which are displayed on your website (e.g., ohi-science.org/ecu):

1. **draft** branch is for editing. This is the default branch and the main working area where existing scenario data files can be edited and new scenarios added.

1. **published** branch is a vetted copy of the draft branch, not for direct editing. This branch is only updated by automatic calculation of scores if:

    1. no errors occur during the calculation of scores in the draft branch, and

    2. publishing is turned on. During the draft editing and testing phases of development, it is typically desirable to turn this off.

1. **gh-pages** branch is this website. The results sections of the site (regions, layers, goals, scores per branch/scenario) are overwritten into this repository after automatic calculation of scores. The rest of the site can be manually altered.

1. **app** branch is the interactive layer and map viewer application. The user interface and server-side processing use the [Shiny](http://shiny.rstudio.com/) R package and are deployed online via [ShinyApps.io](https://www.shinyapps.io/) to your website. Once deployed, the WebApp pulls updates from the data branches (draft and published) every time a new connection is initiated (i.e., browser refreshes).

> TIP: When looking at files on GitHub, note that the timestamps are associated with the 'commit' time rather than the 'push' time.

# Using the Toolbox

>**Section Summary:**

>In this section, you will learn about the most common modifications made to repositories. You will be given examples to follow to help with your own assessment. The most common modifications are changing the pressures and resilience matrices, changing or creating data layers, and changing or removing goals models.

> TIP: You should now have your assessment repository opened and be familiar with the files in the folder.

As your team finalizes which data should be included in the assessment and begins developing goal models, you can incorporate this information into your repository. Data layer files can be created and updated with any software that handles *.csv* files, but goal models must be updated in R. With any modifications you sync to the online repository, the Toolbox will automatically recalculate goal scores. Calculations can also be done locally and offline by running  `subcountry2014/calculate_scores.R`.

This section gives instruction and examples for the most common modifications you will make to your repository:

- **modifying pressures and resilience matrices**
- **modifying and creating data layers for status, trend, pressures and resilience**
- **modifying goal models**
- **removing goals**


The files you will modify are:

![Files you will commonly modify are shown in the figure (Mac navigation is shown above and Windows is shown below). These include the `conf` folder, `layers` folder, and `layers.csv`.](https://docs.google.com/drawings/d/10-cx0mlgT9tmy5KN_IKE0TxgojBX6J3U6ahZMMVmNqY/pub?w=964&h=878)

### File Preparation Workflow

It is generally recommended that you construct a useful workflow with your team when updating data layers for the Toolbox. This process is one that can be done by one person, or by several who are working through GitHub to sync the work. There are overall two main steps to preparing to input your layers into the Toolbox, starting with data layer preparation, and then going into data layer registration. The firs step involves placing files into `layers` folder, and the second is registering those files in `layers.csv`. This file preparation process can occur in tandem with the model modification process. However, it must occur in order for you to run modified goal code using your new input data.

![Diagram of OHI Toolbox data preparation workflow. You should start by prepping the files, loading them into the `layers` folder when they're ready for the Toolbox, and then registering them in `layers.csv`](https://docs.google.com/drawings/d/1-WB84qsupe4yeqKzeBnOSm9iIW-G7N3EYW0VqqGXORs/pub?w=960&h=720)

#### Overview of the Process

The following sections will describe the files included in the Toolbox. You will learn how to start preparing data layers for your assessment and how to start changing goal models. You will learn how the files interact to produce the calculated scores, starting from registering your layers to receiving the *scores* spreadsheed.

![Recommended steps in which to engage with files in the OHI Toolbox.](https://docs.google.com/drawings/d/155-wj8S-cDsbahZgmn5wJ1WHou0XS-2j_GOiX47QvkI/pub?w=969&h=161)

## Modifying and creating data layers

Data layers are *.csv* files and are located in the `[assessment]/subcountry2014/layers` folder. Remember that all data layers provided in your repository are extracted from the global 2014 assessment.

![This figure shows the location of your data layers. Mac navigation is shown above and Windows is shown below.](https://docs.google.com/drawings/d/1ztC3Warw_qWkxJsbPFcdrKRqPBmG-EqYzxHCK6RUQ8I/pub?w=1150&h=818)  

* Layers with the suffix `_gl2014.csv` (*gl* for *global*) have been exactly copied from the global assessment and applied equally to each region, and therefore the values will be the same across all subcountry regions.
* Layers with the suffix `_sc2014.csv` (*sc* for *subcountry*) have been spatially-extracted from global data or adjusted with spatially-extracted data so that each  region in your assessment has a unique value. For example, gross domestic product (GDP) used in the global assessment was reported at the national (most often country) level. Instead of being applied equally across all subcountry regions (which would incorrectly increase the nation's GDP several times), national GDP was down-weighted by the proportion of coastal population in each region compared with the total coastal population.

Both types of default data layers are of coarse-resolution and should be replaced with local, high-resolution data when possible. The priority should be to replace as much of the `_gl2014.csv` data as possible.

**There are several steps to follow when working with data layers:**

1. Modify or create data layer with proper formatting
2. Save the layer in the `layers` folder
3. Register the layer in `layers.csv`
4. Check (and update when appropriate) `pressures_matrix.csv` and `resilience_matrix.csv` (located in: `[assessment]/subcountry2014/conf`)

### Create data layers with proper formatting

The OHI Toolbox expects each data layer to be in its own *.csv* file and to be in a specific format, with data available for every region within the study area, with data organized in 'long' format (as few columns as possible), and with a unique region identifier (*rgn_id*) associated with a single score or value. See the **'Formatting data for the Toolbox'** section for more information.

### Save data layers in the *layers* folder

When you modify existing or create new data layers, we recommend saving this as a new *.csv* file with a suffix identifying your assessment (example: `_sc2014.csv`). Modifying the layer name provides an easy way to track which data layers have been updated regionally, and which rely on global data. Then, the original layers (`_gl2014.csv` and `_sc2014.csv`) can be deleted.  

\* Note: filenames should not have any spaces: use an underscore (‘_’) instead. This will reduce problems when R reads the files.

### Register data layers in `layers.csv`  

When there are new filenames associated with each layer, they will need to be registered in `[assessment]/subcountry2014/layers.csv`. If a layer simply has a new filename, only the *filename* column needs to be updated:

![Register new layers in `layers.csv`. Be sure to note if there is a change in the filename.](https://docs.google.com/drawings/d/1adaERJXxzBxCxqBtmvp8uf5g68mHFfakR-Edbh2wwWo/pub?w=1677&h=687)  

> TIP: This part is done manually. If you prefer not to manipulate your file by hand, you can generate a script that automates this.

However, if a new layer has been added (for example when a new goal model is developed), you will need to add a new row in the registry for the new data layer and fill in the first eight columns (columns A-H); other columns are generated later by the Toolbox as it confirms data formatting and content:

 + **targets:** Add the goal/dimension that the new data layer relates to. Goals are indicated with two-letter codes and sub-goals are indicated with three-letter codes, with pressures, resilience, and spatial layers indicated separately.
 + **layer:** Add an identifying name for the new data layer, which will be used in R scripts like `functions.R` and *.csv* files like `pressures_matrix.csv` and `resilience_matrix.csv`.
 + **name:** Add a longer title for the data layer--this will be displayed on your WebApp.
 + **description:** Add a longer description of the new data layer--this will be displayed on your WebApp.
 + **fld_value:** Add the appropriate units for the new data layer (which will be referenced in subsequent calculations).
 + **units:** Add a description about the *units* chosen in the *fld_value* column above.
 + **filename:** Add a filename for the new data layer that matches the name of the *.csv* file that was created previously in the `layers` folder.
 + **fld_id_num:** Area designation that applies to the newly created data layer, such as: *rgn_id* and *fao_id*.

 >TIP: Think about what units you would like to be displayed on the WebApp when filling out "units."

### Check pressures and resilience matrices

If the new or modified layer is a pressures layer, check that `pressures_matrix.csv` and `resilience_matrix.csv` have been properly modified to register the new data layers.

## Modifying pressures matrices

Your team will identify if any pressures layers should be added to the pressures matrices, and if so, which goals the pressure affects and what weight they should have. You can transfer this information in `pressures_matrix.csv` (located in the `[assessment]/subcountry2014/conf` folder). It is important to note that the matrix identifies the pressures relevant to each goal, and which weight will be applied in the calculation. Each pressure is a data layer, located in the `subcountry2014/layers` folder. This means that pressure layers need information for each region in the study area, and some layers will need to be updated with local data. In modifying pressures, you will need to consider whether data layers can be updated or added, and whether data layers map onto goals appropriately in the local context.

Adding a new pressure to the pressures matrix requires the following steps:

> 1. Create new pressure layer(s) and save in the `layers` folder
> 2. Register pressure layer(s) in `layers.csv`
> 3. Register pressure layer(s) in `pressures_matrix.csv`
  + a. Set the pressure category  
  + b. Identify the goals affected and set the weighting
  + c. Modify the resilience matrix (if necessary)

The following is an example of adding two new pressures layers.

### Create the new pressure layers and save in the `layers` folder

If you create a new data layer, give it a short but descriptive name that also includes a prefix that signifies the pressure category (for example: *po_* for the pollution category). There are five physical categories and one social category:

* *po_* = pollution
* *hd_* = habitat destruction
* *fp_* = fishing pressure
* *sp_* = species pollution
* *cc_* = climate change
* *ss_* = social pressure  

So for example, `po_trash` is a pollution layer with trash on beaches, and `sp_alien` is species pollution due to alien (invasive) species.

In the current example, the two new layers created to account for the input and output effects of desalination operations will be called *po_desal_in*, and *po_desal_out*.

These new layers will have scores from 0 to 1, with values for each region in your study area, and will be saved in the `layers` folder.

### Register the new pressure layers in `layers.csv`

Add two new rows in `layers.csv`, and register the new pressure layers by filling out the first eight columns for *po_desal_in*, and *po_desal_out*.

![](./fig/register_pressure.png)

### Register the new layers in `pressure_matrix.csv`  

`pressures_matrix.csv` identifies the different types of ocean pressures (columns) with the goals that they affect (rows). Adding a new pressures layer to `pressures_matrix.csv` requires adding a new column with the pressure layer name.

#### Set the pressure category

This step requires transferring previous decisions made by your team into `pressures_matrix.csv`. Each pressure category is calculated separately before being combined with the others, so it is important to register the new pressure with the appropriate category prefix decided by your regional assessment team.  

#### Identify the goals affected and set the weighting

This step also requires transferring prior decisions into `pressures_matrix.csv`. Mark which goals are affected by this new pressure, and then set the weighting. Pressures weighting by goal should be based on scientific literature and expert opinion (3 = highly influential pressure, 2 = moderately influential pressure, 1 = not very influential pressure). Remember that the rankings in the pressures matrix are separate from the actual data within the pressures data layers. The rankings ensure that within a particular goal (e.g. within a row of the pressures matrix), the stressors that more strongly influence the goal’s delivery have a larger contribution to that goal’s overall pressure score. Therefore, the rankings are assigned independently of the actual pressure scores, and only determine their importance within the calculations.

![](./fig/register_new_pressures.png)

### Modify the resilience matrix (if necessary)

Resilience is included in OHI as the sum of the ecological factors and social initiatives (policies, laws, etc.) that can positively affect goal scores by reducing or eliminating pressures. The addition of new pressure layers may therefore warrant the addition of new resilience layers that were not previously relevant. Similarly, the removal of pressure layers may warrant the removal of now irrelevant resilience layers.


## Modifying resilience matrices

Previous decisions made with your team will identify if any resilience layers should be added to the resilience matrices, and if so, which goals and/or pressures the resilience affects and what weight they should have. You can then transfer this information into `resilience_matrix.csv` (located in the `[assessment]/subcountry2014/conf` folder).

`resilience_matrix.csv` maps the different types of resilience (columns) with the goals that they affect (rows). New resilience layers may be added to `resilience_matrix.csv` based on finer-scale local information either in response to a new pressures layer, or as a new independent measure. Any added layer must be associated with a pressures layer that has a weight of 2 or 3 in the OHI framework so that resilience measures can mitigate pressures in each region.

Each goal must have a resilience measure associated with it. In the figure below, the Toolbox would give an error because there are no resilience layers indicated for the natural products (NP) goal.

![](./fig/resil_mtx_bad.png)  

### Updating resilience matrix with local habitat information

In this example we will borrow from the experience of `ohi-israel`, where they assessed habitats in the Habitats (HAB) sub-goal that were not included in global assessments `ohi-global`. Therefore, the resilience matrix needed some revision.  

The habitats assessed for `ohi-israel` are:

> `rocky_reef`, `sand_dunes`, `soft_bottom`

Updates are required for the following files:

* *layers.csv*
* *resilience_matrix.csv*
* *resilience_weights.csv* (only if adding new resilience layers)

#### Global resilience layers

The first step is to determine which resilience layers from the global assessment are relevant to your assessment, and whether others need to be added. The full list of layers included in the global resilience matrix are:

> `alien_species`,  `cites`,  `fishing_v1`,  `fishing_v1_eez`,	`fishing_v2_eez`,	`fishing_v3`,	`fishing_v3_eez`,	`habitat`,	`habitat_combo`,	`habitat_combo_eez`,	`li_gci`,	`li_sector_evenness`,	`mariculture`,	`msi_gov`,	`species_diversity`,	`species_diversity_3nm`,	`tourism`,	`water`,	`wgi_all`

Some of these layers capture general aspects of governance that apply to the protection of any habitat. These are:  

> `alien_species`, `cites`, `msi_gov`, `water`, `wgi_all`

Two layers only apply to the livelihoods and economies goal (LE), so they should be excluded from HAB resilience:

> `li_gci`, `li_sector_evenness`

The remaining layers apply to certain habitats, but not others. We focus on these to determine how to adapt the HAB resilience calculation for `ohi-israel`. They are:

> `fishing_v1`, `fishing_v1_eez`, `fishing_v2_eez`, `fishing_v3`, `fishing_v3_eez`, `habitat`, `habitat_combo`,	`habitat_combo_eez`, `mariculture`, `species_diversity`, `species_diversity_3nm`,	`tourism`

#### Determining how to modify these resilience layers

* To determine whether `species_diversity_3nm` or `species_diversity` should be used:
    + `sand_dunes` should use `species_diversity_3nm`,
    + `soft_bottom` should use `species_diversity`,
    + is `rocky_reef` mainly coastal? if so it should use `tourism` and `species_diversity_3nm`.
* If the habitats can be affected by mariculture plants (e.g. eutrophication and decreased water quality can occur if mariculture plants are close by and have poor wastewater treatment), then the `mariculture` resilience score should be added.
    + are there any mariculture plants in Israel? If yes, on which habitats do they occur?
* The remaining layers are the `fishing_v...` and `habitat..` layers, which are composite indicators obtained from different combinations of the following indicators:

> `Mora, Mora_s4, CBD_hab, MPA_coast, MPA_eez`,

where:

* `Mora` is a fisheries governance effectiveness indicator by Mora *et al* (2009)
* `Mora_s4` is another indicator from Figure S4 of the supplementary material of the same publication that focuses on regulations of artisanal and recreational fisheries
* `CBD_hab` is a score assigned based on answers to a questionnaire compiled by countries that committed to Rio's Convention on Biological Diversity (CBD) to establish their progress towards habitat biodiversity protection
* `MPA_coast` is an indicator obtained as the proportion of coastal (3nm) waters that are in a marine protected area (MPA), with the maximum being 30% of coastal waters
* `MPA_eez` is an indicator obtained as the proportion of the whole EEZ that is in a marine protected area, with the maximum being 30% of the whole EEZ.  

This table shows which indicators are used by each combo layer:

Layer | Mora | Mora_s4 | CBD_hab | MPA_coast | MPA_eez
------|------|---------|---------|-----------|--------
fishing_v1 | Mora | | CBD_hab | MPA_coast |
fishing_v1_eez | Mora | | CBD_hab | | MPA_eez
fishing_v2_eez | Mora | Mora_s4 | CBD_hab | | MPA_eez
fishing_v3 | | Mora_s4 | CBD_hab |  MPA_coast |
fishing_v3_eez | | Mora_s4 | CBD_hab | | MPA_eez
habitat | | | CBD_hab | |
habitat_combo | | | CBD_hab |  MPA_coast |
habitat_combo_eez | | | CBD_hab | | MPA_eez

**Questions to consider**:

The first objective is to determine whether the general `fishing_v..` or `habitat_...` categories are relevant to each of the habitats.  For example, fisheries regulations do not affect the conservation of sand dunes, so this habitat should not use any of the fisheries combos.
If the general resilience categories are relevant to the habitat, the next step is to select one resilience layer within the `fishing_v…` and `habitat...` categories that most adequately captures the suite of combined resilience variables that affect the habitat.  For example, the sand dune habitat is a strictly coastal habitat, so the most appropriate resilience layer would be the one that uses the MPA_coast (i.e., `habitat_combo`). The rocky reef and soft bottom, on the other hand, should definitely include fisheries and habitat regulations. So, you'll need to choose a fisheries and a habitat combo for these two habitats.  To do so, consider:

1) For which habitats should you use both a fishery and a habitat combo, or just use a habitat combo?
* fisheries regulations do not affect the conservation of sand-dunes, so this habitat should not use any of the fisheries combos. Also, this is a strictly coastal habitat, so choose the habitat layer that uses the `MPA_coast` instead of the `MPA_eez`, i.e. `habitat_combo` (and, as mentioned above, choose the coastal version of biodiversity, i.e. `species_diversity_3nm`).
* The rocky reef and soft bottom, on the other hand, should definitely include fisheries regulations. So you'll need to choose a fisheries and a habitat combo for these two habitats.
2) Which fisheries and habitat combos for `rocky_reef` and `soft_bottom`? The choice depends on two things:
* whether they are coastal habitats (within 3nm of the coast) or EEZ-wide habitats
      + if coastal, use the fisheries and habitat combos with `MPA_coast` (`fishing_v1`, `fishing_v3`, `habitat_combo`), and the `species_diversity_3nm` layer
      + if EEZ-wide, use the fisheries and habitat combos with `MPA_eez` (`fishing_v1_eez`, `fishing_v2_eez`, `fishing_v3_eez`, `habitat_combo_eez`), and the `species_diversity` layer
* whether the fisheries occurring on that habitat are mainly artisanal, mainly commercial, or both
    + if only commercial fisheries, use a layer that only uses the `Mora` data `fishing_v1..`)
    + if only artisanal/small-scale fisheries, use a layer that only uses the `Mora_s4` data (`fishing_v3..`)
    + if both, use a layer that uses both `Mora` and `Mora_s4` data (`fishing_v2..`)
3) It may also be that the existing global combo layers are not appropriate for your habitats.  For example, if rocky reef is mainly coastal, and it is fished by both commercial and artisanal methods, then we need a new combo that uses `Mora`, `Mora_s4`, `CBD_hab`, and `MPA_coast` (this is the same as `fishing_v2_eez`, but we use the `MPA_coast` layer instead of the `MPA_eez`). All other combinations are already present.
4) Another issue to consider is whether local data are available to improve the pressure layers (that are based on global data).  For example, if  there are local data on Marine Protected Areas (MPAs) and any areas with special regulations, this should be used to generate the `MPA_coast` and `MPA_eez` layers.You may know that only certain types of protected areas are closed to fisheries, and may want to only include those. Also, local datasets may be more accurate and regularly updated. **NOTE: in the global study, these are the same datasets used to calculate the status of Lasting Special Places (LSP).

5) How to update `resilience_matrix.csv`?
* write the complete list of layers you want to use for each habitat. Based on the above, for example, `soft bottom` in Israel matches the combination of layers called *soft bottom, with corals* in the default `resilience_matrix.csv`. But the `rocky_reef` and `sand_dunes` don't seem to match any existing combination, so you'll probably need to delete some of the rows, e.g. the *coral only*, and replace with new ad-hoc rows.

## Modifying goal models

When an existing layer is updated with new data, the Toolbox will automatically incorporate it into the goal calculations after the updated filenames are registered in `layers.csv`. However, if a new layer has been added to the layers folder and registered in `layers.csv`, the Toolbox will not use it unless it is called in a goal model. To integrate any new data layers registered in `layers.csv` you will need to modify the goal model to incorporate the data. Furthermore, in many cases, it will make sense to modify goal models based on data availability and/or local context. For example, the models for regional analyses can often be simplified because of improved data.

**There are two steps to follow when working with goal models:**

1. Update `functions.R`
2. Check and possibly update `goals.csv`

### Update *functions.R*

To incorporate a new data layer into a goal model, open `functions.R` in RStudio: this script contains all the models for each goal and sub-goal. A member of your team with the ability to write R code will need to translate the updated goal model into the Toolbox format. Follow the structure of existing goal models in order to incorporate the new data layers, noting the use of certain R packages for data manipulation.

The image below shows the navigation pane in RStudio that can be used to easily navigate between goal models.

![The navigation pane in RStudio can be used to easily navigate between goal models.](https://docs.google.com/drawings/d/1dMoQQMKV_gtl0v347FoLPsGimVzKY-J3O9zzQUR3VAY/pub?w=876&h=708)

### Check and possibly update *goals.csv*

`goals.csv` provides input information for `functions.R`, particularly about goal weighting and function calls. It also includes descriptions about goals and sub-goals, which is presented on the WebApp.

Changing goal weights will be done here by editing the value in the *weight* column. Weights do not need to be 0-1 or add up to 10; weights will be scaled as a proportion of the number of goals assessed. `goals.csv` also indicates the arguments passed to `functions.R`. These are indicated by two columns: *preindex_function* (functions for all goals that do not have sub-goals, and functions for all sub-goals) and *postindex_function* (functions for goals with sub-goals).

![Check the information in `goals.csv`. It provides input information for `functions.R`. ](https://docs.google.com/drawings/d/17BgYSw2sHbZvHNjUqBlTG-kCOAAn7o6a65O37s0S_es/pub?w=1052&h=719)


**When updating layers or goal models, it is important to ensure that information called from `goals.csv` is correct**:

- check the years
- etc...

### Example modification:

Suppose your team has decided to add an 'artisanal access' component to the Artisanal Fishing Opportunity goal because of locally available data. Once the data are obtained and properly formatted, the data layer is saved as `ao_access_art`. To include this new information in the goal model, you will need to do the following:

1. register the layer in `layers.csv`
2. update the goal model in `functions.R`
3. update the goal call in `goals.csv`


> 1. register in `layers.csv`

![](./fig/new_layer.png)


> 2. update goal model

![](./fig/functions_explained.png)

> 3. update goal call in `goals.csv`

[develop]

### What's the code trying to do?

#### **Natural Products**

You may have already looked at the **NP** section of `functions.R`. In simple terms, here is what the code is doing:

* It pulls out the appropriate data layers to find out the amount of each product per unit area. It does gap-filling as necessary for the Global data.

><!---Alt text--->It should be noted that in the Global Assessments, the harvested amounts are derived from the information from the Food and Agriculture Organization of the United Nations (FAO), and these are combined with habitat values used elsewhere in the assessment. You should be conscious of this as you go through the model and change it, because you may be able to simplify aspects of the code such as gap-filling.

* It calculates Exposure by finding how intensely each identified product is being harvested (amount of product per km^2), and then transforms this from a scale from 0 to 1.

> TIP: The data layer, `hab_extent` is used here and in other goal models in the default code for the Global Assessment.

* In parallel to this, it finds the Risk of each product based on a scoring system that becomes binary: 0, or 1.

* It then averages the two factors, Exposure and Risk, to reveal where risk and intensity are highest. This value is then inverted to become Sustainability and to reward lower intensity and lower risk.

* The amount of each kind of product, relative to the peak historical yield of that product across all regions assessed, and Sustainability are both used create sustainability-weighted scores for all regions and all years available.

* The latest year value is used in the status, and the past few years' values are used in the trend to produce the final score.

<!---I think this diagram is more confusing than explicative because it implies these data are spatial, but not all of them are--->

**Figure needed?** Diagram of sustainability calculation, NP; or perhaps a time-series of the available products in country X in order to show where the peak yield would be.]

#### Data Sources

If the case is that corals, sponges, and  then you might be able to use FAO data, which is the data source of the Global Assessments. Otherwise, you will have to find comparable data in your area or consult local statistical offices and local fisheries managers to get harvest values similar to landing values and any other kinds of stock assessments. The IUCN offers quantified assessments of risk to species, but that is more appropriate for biodiversity; CITES signatory data may be more appropriate for the trade products. Exposure can be calculated spatially, and for this you should be able to find or produce your own maps if possible. Your maps might have finer resolution than those in global resolution.

#### Gap-filling

> TIP: When checking your data, check cases where country-product pair has 0 for sustainability score, but relatively high harvest ratio (curr harvest/peak harvest) – it may be a flag that the sustainability score is off (eg because the habitat area is off)

> TIP: Explore simplifying gap-filling: use correlation model of dollar value vs. harvested tonnage, while discarding the part of script using dollar ratio (current dollar value)/(peak dollar value) as a gap-filler for harvest ratio.

> TIP: Switch the gap-filling order: using the dollar value correlation model first (in cases where the most recent year has no harvest reported but has dollar value reported, that’s a better estimate than using the harvest from the previous year), then gap-fill any remaining cases of missing harvest for the current year with harvest from the previous year

### Appendix - source materials
#### Global Data Approach (Technical Notes)

**Data Overview**

product | relative tonnes (1) | weighting (2) | Exposure (3) | Risk (4)
----------|---------------------|-------------|--------------|------
coral | FAO |  FAO | coral habitat | all 1
sponges | FAO | FAO | coral + rocky reef habitat | all 0
ornamentals | FAO | FAO | coral + rocky reef habitat | 1 if blast/cyanide fishing, otherwise 0
fish oil | FAO | FAO | fish score/100 | --
shells | FAO | FAO | coral + rocky reef habitat | all 0
seaweeds | FAO | FAO | rocky reef habitat | --

(1) relative tonnes: tonnes relative to max tonnes for region with 35% buffer.  The maximum corresponds to the year with the highest $ value - but it would probably be better to just base this off tonnes.  When we redo these data lets evaluate this approach.
(2) weighting: This weights the contribution of each product according to USD at max year for a region. It makes sense to use $, because comparing extraction weight of sponges vs. ornamentals doesn't make sense.
(3) Exposure: For fish oil this value is the FIS score (which is a bit different than what is described in the paper because FIS score can have penalties for underfishing).  The other values are determined by:
log (harvest/habitat area + 1) / log[max(harvest/habitat area) +1].

The habitat area used for seaweeds: rocky reef
The habitat area used for coral: coral
The habitat area used for shells, ornamentals, sponges: coral plus rocky reef

#### Notes: Preparing the Data

<!---Notes from Katie while updating the NP goal -- MOVED UP--->
-

#### Notes: Tech Specs

<!---Note on Updating the Script: I just pushed a new script, `data_prep_2015a.R`, and the resulting outputs to `ohiprep/globalprep/fao_commodities/v2015`.  The new script reworks the gap-filling, based on Mel's and Katie's suggestions.  I'll post later about the smoothing and calculations based on new input from Katie, but would love to get input on the gap-filling first.
* Before gap-filling, binds the USD and tonnes data for all natural products at the commodity level (rather than product level).
* By commodity & year: Identifies years with neither USD nor tonnes data, flags as `no_data`, and determines first reporting year based on first year with either data (and deletes years prior to this).
* By commodity & year: Gap-fills according to these rules:
    * If `no_data`, and not the last year of data set, assume that non-reporting means zero harvest; replace `NA` with `0` for both USD and tonnes
    * Create regression models for `(tonnes ~ USD)` and `(USD ~ tonnes)`
        * Exclude NAs (these will be in either USD or tonnes, but not both)
        * Remove all commodities with fewer than four non-zero observations (within a particular region)
            * not enough info for a decent regression or meaningful peak
            * counting these could also penalize experimental production that later stops
        * Use `lm()` to generate slope/intercept, and gap-fill all NAs with the appropriate regression model
        * Regression gap-filling takes care of the most current-year gaps, per Katie's comment
        * Regression gap-filling fails for certain data, where there are no paired observations for correlation (e.g. every reported value for USD shows NA for tonnes, and/or vice versa), still need to figure out how to deal with those without losing useful data.
    * If `no_data` appears in most recent year of data set, not applicable for regression gap-fill, so end-fill based upon the prior year.
    * Outputs a .csv with rgn_id, commodity, product, year, and gapfill method at the commodity level.  I made up text codes for now, pretty self-explanatory, but those are easy to change.  File is `data/np_gapfill_report.csv` if you want to take a peek.
* Collapses commodities into products at this point, in preparation for smoothing, finding peaks, and determining status and weighting.

Latest on NP:
in ohiprep/globalprep/FAO-commodities, new (well, a week or so ago) data_prep2015.R that fixes:
* the FAO data cleaning, so treats '0 0' as 0.1 instead of NA
* gap filling:
    * it runs at commodity level instead of product level
    * gapfills between USD and tonnes in sequence: local regression, then georegional regression, then global regression.
    * does all that before end-filling.
    * produces a gapfilling report for every commodity/region/year.
Currently this outputs a single file; needs to be updated to output individual files for tonnes, tonnes_rel, and prod_weight.  Needs to be renamed to data_prep.R.

In ohi-global/eez2013, LSP_update branch, I've updated /conf/functions.R - cleaned up (dplyr, etc), chunked into sub-functions.  Questions that need to be addressed:
* currently calcs trend using last five years of data (year_max >= year > year_max-5), which means only four intervals for the regression.  I think we want to include the (year_max - 5) data, for five intervals, so: (year_max >= year >= year_max-5).
* currently, for regions with exposure = NA, replaces NAs with zero.  Should these be replaced with one instead?
    * Exposure for these indicates harvest intensity (tonnes/km^2) relative to the region with the max harvest intensity.
    * NAs occur when a country hasn't reported area values for rocky (seaweeds), coral (corals), so tonnes/NA = NA.
    * Setting exposure to zero means intensity = none at all (boosting the status); leaving as NA removes from calculation (ignored in status); setting to one means intensity = worst case (penalizing the status).--->

    <!---Note Ecuador's approach to Natural Products:
    Very low data for species, so it has been hard to advance this goal, unknown for each global product. but they did look up FAO data and found 3 products by country
    but they need to be looking for data for things they actually produce, like madera, leña de manglares, sea horses, they do have data for ornamental species in Sta Elena (not sure if they have data (tonnes) of catch of these species) they have good resilience measures, should add these Maybe they should ignore this goal all together? → they can decide to, but first I think they should think about what natural products are actually important to the area: we’ve heard about mangrove wood before--->

    <!---SPP status takes into account the IUCN score and the area that the species occupies (although the results are not exactly equivalent to an area weighted average).  Specifically, the values are calculated at the spatial scale of the raster cells (which I believe is at 0.5 degree resolution).  For each raster cell, the IUCN scores of the species are averaged to get a score. To get status, the raster cell scores within an EEZ are then averaged (after weighting for the area of the raster cell).
    ICO status is calculated by taking the average of the IUCN ratings for all the iconic species in the EEZ. --->

    <!---SPECIES he original logic was to represent the species present relative to the proportion of their range within a given EEZ.  We may also have wanted to avoid penalizing a region too heavily if only a very small portion of the range came from a very threatened species.  I think we were also worried about bad aqua maps data that could misallocate species into a country and having a big effect.

    A disadvantage is that rare species (and those with contracting ranges) will have a relatively small influence on the score.  Common species will, in most cases, drive the results.

    An advantage is (actually a disadvantage of averaging species scores at the EEZ level): "The bigger an area, the more likely you are to find rare at risk species (the classic problem of species-area relationships or SARs) - so bigger countries would have lower diversity scores just as a function of their size but not actual poorer biodiversity. In regards to sampling effort, the number of rare species increases faster than the number of common species, so they would not even each other out."--->

    <!---SPECIES. For the global assessment, we started with a list of iconic species, and then found which ones had been assessed, in this case by IUCN. So from that original list of iconic species, we could only include the ones assessed by IUCN. IUCN scores are categorical ('extinct', 'least concern', etc), but Butchart et al. (attached) had done a study where they assigned numeric scores to each IUCN category. So we took the list of iconic species that had IUCN categories and assigned Butchart's numeric scores to each species based on these categories. We found how many species were in each IUCN category, (% or proportion of species in 'least concern' compared to all species with IUCN categories). For each region in the global assessment, we averaged the scores of the species that were there in that region together, giving that region's ICO score. (This averaging assumes that all species are of equal importance). So for an example, let's say there are 10 assessed iconic species: 5 are 'least concern', 4 'vulnerable', and 1 'threatened'. The math would be (5lc + 4v + 1t) / 10. Or, to think about this as percentages, it could be 0.5lc + 0.4v + 0.1t.
    Are you using IUCN categories? If so, you can use Butchart's method. You'll see in the Toolbox that they assign the scores such that we actually have to do (1-Butchart_score) but the logic of what we did is the same.--->


## Removing goals
If a goal is not relevant in your region, it is possible to remove the goal completely from the calculation. There are four places where you will need to remove the reference to this goal. Failing to delete all referenced layers after the goal is deleted will result in errors. To remove goals from your assessment, you will have to do the following:

1. Remove the goal model from `functions.R`
2. Remove the goal’s row from `goals.csv`
3. Remove the goal’s row from `pressures_matrix.csv`
4. Remove the goal’s row from `resilience_matrix.csv`

![](./fig/remove_goal.png)

**Example: Removing carbon storage (CS) goal**

To completely remove the carbon storage goal from Index calculations, you will do the following.

1) Remove the carbon storage (CS) goal model from `functions.R`. Delete the highlighted text in the figure below that references the CS layers and calculates CS goal status, trend, and scores.

![](./fig/functions_delete.png)

2) Remove the CS row from `goals.csv`. Delete the highlighted row in the figure below that contains the CS goal.

![](./fig/goals_delete.png)

3) Remove all CS rows from `pressures_matrix.csv`. Delete the highlighted rows in the figure below that contain CS pressures.

![](./fig/delete_pressures.png)

4) Remove all CS rows from `resilience_matrix.csv`. Delete the highlighted rows in the figure below that contain CS resilience.

![](./fig/delete_resilience.png)

## Modifying goals with categories

Several goals have categories that are assessed within them. In global assessments, these goals are:

Goal | Category
-----|---------
NP   | product types
CS   | habitat types
CP   | habitat types
HAB  | habitat types
LIV  | industry sectors
ECO  | industry sectors

These goal categories are identified in the file `config.r` located in the `conf` folder. The Toolbox uses `config.r` to identify the appropriate categories when pressures and resilience dimensions are calculated.

When you open `config.r`, you'll see that the `pressures_components` variable identifies which data layer indicates the category types. For global assessments, the following data layers are used:

Goal | Category         | Pressures Layer in `config.r`
-----|------------------|---------------
NP   | product types    | np_harvest_product_weight
CS   | habitat types    | cs_habitat_extent
CP   | habitat types    | cp_habitat_extent_rank
HAB  | habitat types    | le_sector_weight
LIV  | industry sectors | le_sector_weight
ECO  | industry sectors | hab_presence

If you have modified any of the categories for any goal, you will likely need to update the layer indicated in `config.r` in addition to updating the categories as unique rows in `pressures_matrix.csv`.

### Example 1: Pressures
For example, there are three product types for Natural Products in the China assessment (seasalt, sea chemicals, and sea medicine), differ from those assessed in the global assessments (corals, fish_oil, ornamentals, seaweeds, sponges). To modify this goal in the Toolbox, input layers were updated, saved in the `layers` folder, and registered in `layers.csv`;  the NP function in `functions.r` was updated, and new categories replaced the old in `pressures_matrix.csv`. The only remaining step to finalize the new NP goal is to update `config.r` to ensure it looks for the correct data layer and therefore categories. If you do not update `config.r` before running `calculate_scores.r`, you will get the following warning:


```
Calculating Pressures...
The following components for NP are not in the
aggregation layer np_harvest_product_weight categories
(corals, fish_oil, ornamentals, seaweeds, sponges):
seasalt, sea_chemicals, sea_medicine
```

This message indicates that the `np_harvest_product_weight` layer identifies five categories (corals, fish_oil, ornamentals, seaweeds,
sponges) but the `pressures_matrix.csv` indicates three (seasalt, sea_chemicals, sea_medicine).

To ensure that pressures are calculated correctly for the categories in your assessment, you will need to change the layer identified in `config.r`.

### Example 2: Pressures

More subtle examples of these mismatch between the categories identified in `pressures_matrix.csv` and `config.r` can also occur. For example, after updating the CS layers and goal in the China assessment, the following warning message appeared when running `calculate_scores.r`:

```
Calculating Pressures...
The following components for CS are not in the aggregation layer
cs_extent categories (saltmarshes, seagrasses, mangroves):
mangrove, saltmarsh, seagrass
```

The problem here is that the categories identified in `config.r` (saltmarshes, seagrasses, mangroves) are plural, whereas the categories identified in the pressures matrix (mangrove, saltmarsh, seagrass) are singular, and the Toolbox needs exact matches. To fix this warning, you need to update the pressures matrix with the plural names.


### Example 3: Resilience

For resilience, the proper categories also need to be identified both in `resilience_matrix.csv` and `config.r`. If neither are updated, you will see the following message:

```
Calculating Resilience...
Note: each goal in resilience_matrix.csv
must have at least one resilience field
Based on the following components for NP:
corals
fish_oil
ornamentals
seaweeds
shells
sponges
```

With resilience, if we update only the `resilience_matrix.csv` but not `config.r`, we get the following error message instead of the warning message we saw for pressures above.

```
Based on the following components for NP:
  seasalt
  sea_chemicals
  sea_medicine
Error in subset.default(SelectLayersData(layers, layers = lyrs),
id_num ==  : object 'id_num' not found
In addition: Warning messages:
1: Grouping rowwise data frame strips rowwise nature
2: In left_join_impl(x, y, by$x, by$y) :
  joining factors with different levels, coercing to character vector
  ```

This error can be fixed by updating `config.r` with a layer identifying the appropriate categories. NOTE: the file identified in `config.r` cannot contain any NA values.  

## Other example modifications

### Preparing the fisheries sub-goal 

Here is some background information about how to prepare fisheries data layers for the Toolbox.

**Data layers used by the Toolbox:**

* `fis_b_bmsy`
* `fis_meancatch`
* `fis_proparea_saup2rgn`
* `fp_wildcaught_weight`

#### Description of data layers

`fis_b_bmsy`

* *for species*: B/Bmsy estimate (either from formal stock assessment, or from a data-poor method such as CMSY)    
* *for genus/family/broader taxa*: the toolbox will use median B/Bmsy from species in that region + a penalty for not reporting at species level. In order for the code to assign the correct penalty, the taxa need to include a numerical code of 6 digits, where the first digit behaves like an ISSCAAP code (the standardized species codes used by FAO): 6 means species, 5 means genus, 4 to 1 are increasingly broad taxonomic groups    
* *data source (for CMSY)*: catch time-series (at least 10 years of catch >0), species resilience (if available)  

**Example data:**

|fao_id |taxon_name     |year |b_bmsy   |
|:------|:--------------|:----|:--------|
|51     |Ablennes hians |1985 |1.112412 |
|51     |Ablennes hians |1986 |1.222996 |
|51     |Ablennes hians |1987 |1.371058 |


NOTE: if a species that is caught in different sub-regions belongs to the same population, you don't want to split the catch among sub-regions, instead, you want to sum catch across all sub-regions, so you can calculate B/Bmsy for the whole population. For the global analysis we grouped all species catch by FAO major fishing area (www.fao.org/fishery/area/search/en), indicated in the column *fao_id*, assuming that all species caught within the same FAO area belonged to the same stock, while we assumed that the same species, if caught in a different fishing area, belonged to a separate stock.  
Use *fao_id* as an identifier that separates different fisheries 'stocks' belonging to the same species.   
If you don't have multiple stocks in your study area, set all *fao_id* = 1.  

`fis_meancatch`:

* average catch across all years, per species, per region  
* *data source*: catch time-series (at least 10 years of catch >0), with a unique identifier for each population that you want to assess separately   
 
**Example data:**

|fao_saup_id |taxon_name_key             |year |mean_catch  |
|:-----------|:--------------------------|:----|:-----------|
|37_8        |Aristeus antennatus_690051 |2014 |14.24398116 |
|37_8        |Atherinidae_400218         |2014 |27.30120156 |
|37_8        |Balistes capriscus_607327  |2014 |3.247883895 |

The *taxon_name_key* column indicates the name of the species (e.g. Aristeus antennatus) and its 'taxonkey'. The taxonkey is a 6 digit numeric code used by the Sea Around Us Project, modified from FAO codes. The important element of this code is the first digit, because it reflects the taxonomic level (6=species, 5=genus, 4=family, etc.) of the reported catch.The toolbox uses this first digit to assign a score to all catch that was not reported at species level, taking the median of the B/Bmsy of assessed species, and adding a penalty that is increasingly strong for coarser taxa.    

`fis_proparea_saup2rgn`:  

* a conversion file that, for each region for which catch is reported, tells us what proportion of that region falls within each of the final OHI reporting regions.   

**Example data:**

| saup_id| rgn_id| prop_area|
|-------:|------:|---------:|
|     166|      1|       1.0|
|     162|      2|       1.0|
|     574|      3|       0.7|
|      37|      4|       0.8|

**Specific instances:**

 *only if catch is reported for different regions than the ones used for the OHI assessment:* this should be calculated using spatial analyses of overlap of the spatial units at which catch is reported with the spatial units at which the OHI assessment will be reported. The global data was reported by subregions (*saup_id*) and in some cases multiple subregions were part of the same, larger EEZ. Since for OHI we wanted results by EEZ (*rgn_id*), in those cases we needed to combine results from the subregions to get the final score, based on their size relative to the total EEZ size (*prop_area*).   
 *If catch is reported for the same areas for which OHI is calculated:* then all the *prop_area* are = 1.   
 *If catch is reported for the whole area of the assessment, but you want to calculate a separate OHI score for different sub-regions:* for each OHI reporting region (*rgn_id*) you'll repeat the same region in the *saup_id* column, and *prop_area* will be =1. This effectively means all the reporting regions will get assigned 100% of the catch and will have the same final stastus and trend score for the fisheries goal (but may have different pressures and resilience scores, if those layers are different in each sub-region).  

`fp_wildcaught_weight`: 

*only needed if there is mariculture*: for each region, this represents the relative proportion of catch coming from wild caught fisheries versus mariculture. The layer is used to weight how much the fisheries score influences the final food provision score, the higher the fisheries catch, the more the food provision score will reflect the fisheries score, and vice-versa if mariculture has a higher catch.       
(NOTE that, before all mariculture harvest from all species gets summed, the mariculture harvest for each species is smoothed and then multiplied by the resilience score).     

#### Running CMSY model

**Sample data to run CMSY:**

|id |stock_id                    |res    |ct          |yr   |
|:--|:---------------------------|:------|:-----------|:----|
|6  |Acanthistius brasilianus_41 |Medium |100         |1950 |
|23 |Acanthurus dussumieri_61    |       |0.059250269 |1950 |
|24 |Acanthurus dussumieri_71    |       |0.190749971 |1950 |
|25 |Acanthurus lineatus_61      |Low    |12.74821966 |1950 |

The current CMSY script produces an output that looks something like this (split into 2 tables): 

|stock_id          |convergence |effective_sample_size |yr   |b_bmsy   |b_bmsyUpper |
|:-----------------|:-----------|:---------------------|:----|:--------|:-----------|
|Ablennes hians_51 |SC          |30974                 |1985 |1.112412 |1.8         |
|Ablennes hians_51 |SC          |30974                 |1986 |1.222996 |1.768895    |

|stock_id          |yr   |b_bmsyLower |b_bmsyiq25 |b_bmsyiq75 |b_bmsyGM |b_bmsyMed |
|:-----------------|:----|:-----------|:----------|:----------|:--------|:---------|
|Ablennes hians_51 |1985 |1           |1          |1          |1.093932 |1         |
|Ablennes hians_51 |1986 |1.014688    |1.075699   |1.298437   |1.209005 |1.160329  |

where *stock_id* is the unique identifier for each stock that was used in the input file, *convergence* indicates whether the model converged and how strongly ('SC' = strong convergence), *effective_sample_size* reports the number of iterations used, *yr* = year, b_bmsy = B/Bmsy for the corresponding year (based on the median of all the estimated values: reccomended),  b_bmsyUpper = B/Bmsy at the upper 95% bootstrapped confidence bound, b_bmsyLower = B/Bmsy at the lower 95% bootstrapped confidence bound, b_bmsyiq25 = B/Bmsy at the first quartile, b_bmsyiq75 = B/Bmsy at the third quartile, b_bmsyGM = B/Bmsy based on the geometric mean of estimates, b_bmsyMed = B/Bmsy based on the median of estimates.

**How to:** 

**1. Include resilience in the CMSY code:**

In the CMSY R script, in the PARAMETERS section, replace the following:

> ![](./fig/include_resilience.png)

**2. Make assumptions about fisheries regulations:**

If you assume that fisheries are depleted and there isn't very much fisheries regulation, and you are using the CMSY method to assess B/Bmsy, the original model may work well. If, however, the catch of a species declined because fisheries regulations have closed or limited the fishery, or if a fishery was abandoned for economic reasons (e.g., change in consumer prefereces, market price dynamics, etc.), the model may be too pessimistic and understimate B/Bmsy. In that case it may be best to use a version with a uniform prior on final biomass, instead of the constrained prior.  
The original constrained prior on final biomass is set by this line within the code:  
  
```
finalbio    <- if(ct[nyr]/max(ct) > 0.5) {c(0.3,0.7)} else {c(0.01,0.4)}    
```  

The model uses a uniform prior if that line is replaced with:

```
finalbio    <- c(0.01,0.7) 
```

**3. Use data at a different spatial resolution than the final assessment:**

See notes above for `fis_proparea_saup2rgn`

**4. Calculate B, or Bmsy:**

The CMSY model calculates B/Bmsy as a ratio, it does not estimate the two variables separately.      

**5. Use catch per unit of effort (CPUE):**

The CMSY model requires total biomass removed by fisheries, and uses catch as a proxy for that. It cannot use CPUE. Other more sophisticated stock assessment models use CPUE and may be employed. We do not provide documentation for the use of these other models.     

**6. Use other life-history characteristics, in addition to resilience:**

The CMSY model does not use more detailed information. Other more sophisticated stock assessment models use other life-history traits such as fecundity, larval dispersal, r, K, Lmax, etc., and may be employed. We do not provide documentation for the use of these other models.    

**7. Create a 'taxonkey' to assign to each species:**

When replacing the SAUP_FAO data with your own data, assign a key of 600000 to all species. For all catch that is reported at genus or coarser taxonomic level, you will have to choose an appropriate taxonkey. You can create your own key, from 100000 to 500000, based on your own judgment of how many species may be reported under that same denomination, and how different they may be (all that matters for the toolbox code is whether the number starts with a 1,2,3,4,5 or 6 with 1 being the coarsest, such as 'miscellaneous marine animals', or 'crustaceans nei'). 

#### Resources

Martell, S & Froese, R (2013) "A simple method for estimating MSY from catch and resilience". *Fish and Fisheries*, DOI: 10.1111/j.1467-2979.2012.00485.x. [Downloadable here](http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0CCkQFjAB&url=http%3A%2F%2Fwww.iotc.org%2Fsites%2Fdefault%2Ffiles%2Fdocuments%2F2013%2F06%2FIOTC-2013-WPNT03-INF01%2520-%2520Martell%2520%2526%2520Froese%25202012.pdf&ei=PXryU6TtGY3goATglYHoDA&usg=AFQjCNE-S0T1B7B_l7rUYaNNLxsUDguDaQ&bvm=bv.73231344,d.cGU)   
     
Rosenberg, A.A., Fogarty, M.J., Cooper, A.B., Dickey-Collas, M., Fulton, E.A., Gutiérrez, N.L., Hyde, K.J.W., Kleisner, K.M., Kristiansen, T., Longo, C., Minte-Vera, C., Minto, C., Mosqueira, I., Chato Osio, G., Ovando, D., Selig, E.R., Thorson, J.T. & Ye, Y. (2014) Developing new approaches to global stock status assessment and fishery production potential of the seas. *FAO Fisheries and Aquaculture Circular No. 1086*. Rome, FAO. 175 pp. [Downloadable here](http://www.fao.org/docrep/019/i3491e/i3491e.pdf)

## Notes about R

The Toolbox is written in R, and relies heavily on a few R packages created to faciliate data handling and manipulation. The primary R package used is called `dplyr` by Hadley Wickham. The `dplyr` package allows for 'chaining' between functions, which is represented with a `%>%`. See: https://github.com/hadley/dplyr#dplyr for documentation. 



# Frequently Asked Questions (FAQs)

This document provides answers to some frequently asked questions about conducting regional assessments using the Ocean Health Index. A few questions are related to general concepts in the Ocean Health Index, but mostly those topics are covered at http://www.oceanhealthindex.org/About/FAQ/. Here, the FAQ are primarily technical questions regarding regional assessments and using the OHI Toolbox. This document will be updated continually as we have more questions. Questions are arranged by theme, and have the format Q: (question) and A: (answer).

## Overall

## Conceptual

**Q: Are regional assessment scores comparable with global assessment scores?**

A: Regional Index scores cannot be directly compared to global Index scores, or to other regional Index scores calculated through separate efforts. This is because data and indicators (both what they measure and their quality), reference points (set using local knowledge and priorities), and specific goal models are often different for the areas being compared.

However, because scores for each goal are scaled to a reference point, qualitative comparisons can be made. For example, a score of 71 in the US West Coast compared to 66 in Brazil says that the US West coast is closer to fully meeting its sustainable goals (i.e., meeting regional reference points). Furthermore, use of the same Ocean Health Index framework across regional assessments permits fruitful discussion and general comparisons even if data inputs differ. Ocean Health Index assessments at any scale always work within a standardized definition of ocean health, using information to capture the philosophy of the ten goals that have been identified (and undergone scientific peer-review) prior to compiling relevant data. Use of the ten-goal framework is important both to ensure that all aspects of ocean health are captured and to allow better comparison across regional assessments than would be possible if the different regions used different methods.

**Q: How does the Index account for ecosystem benefits?**

A: The OHI is not an index of ecosystem services. The Index prefers to describe benefits from a healthy ocean and emphasize their relevance, but the ideas are closely related. The ten goals roughly fall into areas of ecosystem services such as food provisioning (**Food Provision**), regulatory services (**Carbon Storage**), cultural services (**Tourism and Recreation**,**Special Places**), supporting services (**Clean Waters**, **Biodiversity**), and other values (**Livelhoods and Economies**).

*(Source: OHI Baltic workshop)*


**Q: Where is climate change measured in the Index?**

A: Four different aspects of climate change -- increases in sea surface temperature (SST), sea level rise (SLR), ultraviolet radiation (UV), and ocean acidification (OA) -- are included as pressures to many goals in the Index, including Natural Products, Carbon Storage, Coastal Protection, Sense of Place, Livelihoods & Economies and Biodiversity.  Mitigation of climate change through carbon storage is one of the ten goals.


**Q: Why are food provision and artisanal fishing opportunities goals separated?**

A: These goals measure different aspects of how people relate to fishing. The catch of fish made by artisanal (=small-scale, subsistence type) fisheries is captured in the food provision goal. Jobs, wages and income from both the food provision and artisanal fishing goals are captured in the livelihoods & economies goal. The purpose of the artisanal fishing opportunity goal is to evaluate the opportunity for people to pursue this fishing in relation to their need to do so.  

## Timing and Resources

**Q: How much does it cost to produce a regional assessment?**

A: Regional assessments can be completed at(varying costs depending on the local context.(Funds are needed for a management and scientific team, workshops and meetings (including travel), communications, policy engagement, and operating costs. Therefore, securing funding is an important component to satisfactorily complete the assessment. We encourage the development of a local proposal or strategic action plan that details a timeline of activities and the resources needed to accomplish them.


**Q: How many people are required in a team?**

A: rather than a specific number of individuals, what is required are specific skillsets. For example, if the scientific analysts were capable of effectively conducting the R analysis, then a dedicated R analyst would not be required. In current assessments, teams range between 2 and 8 people.


**Q: How long does it take to calculate OHI at a regional scale?**

A: The duration of an OHI assessment depends on a number of factors, such as the budget and number of people involved, the scale of the study area and whether new regions will need to be created, how easily data can be acquired, how much local data can be incorporated, how many goal models need to be changed. Additionally, decisions about setting reference points require input from experts. For independent assessments (OHI+), we have found that the average time has ranged from 1.5 to 3 years (See **Task Timeline** in the **Conceptual Guide**).


**Q: How much time will modifications by an R analyst take?**

A: This will depend on if you are changing any models, and potentially data layers--but a lot of changing data layers just requires registering them properly in `layers.csv` (and maybe `pressures_matrix.csv` and resilience_matrix.csv if they are pressures or resilience files) and having the `functions.R` file call those layers. That is more 'bookkeeping' than actual R programming.


**Q: How much time will modifications by a GIS analyst take?**

A: this will depend on how many layers you are processing: you are clipping spatial data? That will take some time because there are quite a few files, but maybe not too long since it is pretty small scale and once there is a clipping mask created I think you apply it to other files.


**Q: Which goals require a GIS analyst?**

A: All goals using spatial data could potentially require a GIS analyst. These goals are commonly: habitat-based goals and sub-goals: (Coastal Protection, Carbon Storage, Habitats—a sub-goal of Biodiversity), Food Provision, Sense of Place, Species—a sub-goal  of Biodiversity, Clean Waters

## Structure

**Q: Can we remove or add goals to the OHI?**

A: A lot of deliberation went into defining the ten goals, and they seem to do a pretty good job of covering many if not most ocean uses, so additional goals may not be necessary. But it could be that they eclipse or replace an existing goal.

## Reference points

**Q: Can planning targets can be used as the reference points?**

A: Yes, planning targets can be used as reference points. This won't be appropriate for every goal, but there are cases where this seemed best (example: iconic species sub-goal in the global assessment, mariculture sub-goal in the US West Coast assessment).


**Q: What is sector evenness?**

A: Sector evenness (also called a diversity index) is an economic concept that is included in OHI to enable comparison across many different sectors included in the Livelihoods & Economies goal. This goal evaluates jobs, wages and revenues for nine marine employment sectors. The distribution of employment across these nine sectors is an effective indicator of resilience. If total employment within a community is primarily based in one or two sectors, the overall economic system will be excessively vulnerable to downturns in those sectors.  Conversely, if employment is spread relatively evenly throughout all nine sectors, the overall system will be more robust and resistant to such disturbances. Overall revenue within the community will remain more stable during such downturns, and workers displaced by a downturn in their sector may be able to find employment in another sector without leaving the community.

## Appropriate data layers

**Q: Shipping and port activity are hardly affected by the health of the ecosystem. Why are these included in the Index?**

A: Shipping and port activity are included as pressures only


**Q: Can oil spills be included in OHI?**

A: Yes, oil spills could be included as a pressure and in the Clean Waters goal.


**Q: Is seasonal (non-permanent) sea ice included in OHI habitats?**

A: No, sea ice only includes permanent sea ice.


**Q: Can seaweeds be included in the Carbon Storage goal?**

A: Because they store carbon for less than 100 years, seaweeds and corals are not included in the carbon storage goal. While the pelagic oceanic carbon sink (phytoplankton) plays a large role in the sequestration of anthropogenic carbon, the pelagic ocean mechanisms are not amenable to local or regional management intervention. Phytoplankton and contribute to carbon fixation when they die and sink to the sea bottom at sufficient depth, because it is effectively out of circulation. However, if those phytoplankton are eaten, the carbon is cycled back into the system and not sequestered. Something that could potentially be included in the carbon storage goal is mollusc shells, if they are added to a landfill and not recycled in the sea. So if information on mariculture production and waste disposal are available, this could be an interesting addition to carbon storage at a regional scale.


**Q: Is coastal engineering included in Coastal Protection? What if it reduces erosion?**

A: We did not include an assessment of the protection afforded by  man-made structures, such as jetties and seawalls, because these structures cannot be preserved without maintenance, may have other negative side effects (e.g. alter sedimentation rates causing erosion in new locations), thus they do not constitute long-term sustainable services.
Coastal engineering (jetties, harbours, marina and breakwater) is not natural, and is mostly seen as a pressure. It will also be evident in the status of due to decreased natural habitat. It gets tricky when structures are built to help reduce coastal erosion--they are still manmade and therefore not a natural benefit that the ocean provides. But if available data allow, it might be possible to include tradeoff effects: maybe in areas where natural habitats are degraded and man-made structures have been built to reduce erosion, we could reduce the pressure that would otherwise be applied.


**Q: How is seawater used for cooling on-shore power plants incorporated into OHI?**

A: The use of cooling water for on-shore power plants would be a pressure on the ocean, since it causes entrapment of fishes, larvae, etc, and usually is circulated back into the ocean at higher temperatures (and maybe other chemicals, minerals, etc). Since the energy is coming from land-based activities, there isn't a service that the ocean is providing that 'benefits' people, it is only a pressure from the OHI perspective.


**Q: How is freshwater production through desalination incorporated into OHI?**

A: Desal would be incorporated into OHI in several places. The benefit is that there is freshwater produced, which could be incorporated into the Natural Products goal (or potentially into its own goal). Data required would be the volume of freshwater created based on the volume of seawater involved and spatial extent. Setting the reference point would not be based on how much can be produced, but some other targets perhaps set by government (percentage of the population served).
Similar to the mariculture sub-goal and tourism goals, any negative effects caused by desal that affect other goals (example: species) do not influence the ability to obtain desalination targets now and in the future. Therefore, the sustainability coefficient only measures the ability to sustain that goal, but not the impacts on other goals: instead, they are taken into account as pressures when calculating the other goals. Desal should be included as a pressure similar to cooling on-shore power plants since the discharge brine is dense, doesn't plume very well and there are chemicals involved.

**Q: Where do energy activities fit in to OHI?**

It depends. Energy could be part of a **Natural Products** goal, for instance, such as wave energy -- but then the question is, what is the reference point? It is partially accounted for in **Livelihoods & Economies** through sectoral jobs data. The infrastructure is also something to consider. It could also be a pressure or resilience factor if there is a measurable footprint of the activity. You may want to consider for resilience, do you have governance measures that promote more sustainable practices in the energy industry?

<!---From Baltic Discussion 2015--->

## Food Provision

**Q: Could the culture of marine fish in closed pools on-shore be included in the Mariculture sub-goal?**

A: This should not be included because onshore aquaculture does not require a marine environment.


**Q: Can aquaculture farms that receive seawater supply and return seawater back to the sea be included in the food provision goal?**

A: This would be more appropriately included in the Mariculture sub-goal, and with finer-scale data additional pressures due to the intake pipes and the processed brine back into the marine system could be incorporated as well.
Natural Products


**Q: If natural products are all produced through on-land aquaculture, should this goal be removed?**

A: In this case you would probably have good reason to exclude the natural product goal due if this was defendable through discussions with experts and any reports/papers on the topic. This would also depend on the origin of these natural products--are they from the region’s waters?
Habitat-based goals


**Q: I have fish that are used as feed for other fish (e.g., sprat) in my country. Can I include them in this goal?

 A: It would be more appropriate to include them in Natural Products rather than Food Provision. This is because they are not being consumed directly. Fish such as sprat, for example, may be used to feed pigs in addition to other fish, and therefore you would need to know how much (tonnage) is being produced, and where it is going to be able to accurately distinguish these categories to avoid double-counting.

 *(Source: OHI Baltic Workshop, February 2015)*

**Q: How is coral health calculated?**

A: Coral health was estimated by compiling point data from multiple studies of percent live coral cover. In other words, estimates of coral cover within transects of certain sites were repeated in time and we used that rate of change in time as an indication of health of the reefs in the whole region. The difficulty lies in 1) having enough different locations sampled that you can say something about the whole region and 2) finding studies that did repeated measures in time, in the same location, over at least 20 years. In the Global 2013 assessment, there were so few datasets that satisfied this condition that we had to pool observations from different locations.


**Q: Is it possible to calculate habitat goals when there is only one year of habitat data?**

A: With only one year of habitat data, it is not possible to calculate the trend (which requires 5 years of data). Instead, it might be best to use the available habitat data to calculate the current status and then to overlay pressures for the last 5 years to calculate trend.

## Livelihoods & Economies

**Q: Benefits gained from Wild-caught fisheries, Mariculture, Tourism & Recreation are included in specific goals. Why are these counted again in Livelihoods & Economies?**

A: The quantity of fish, mariculature, and participation in T&R are considered separately in goals whereas the monetary component is captured in L&E.


**Q: Why are revenue data from shipping, boat building, ports and harbors included as revenue? Do these activities rely on a healthy ocean?**

A: These sectors are included in the Ocean Health Index because the demand for some of those boats (fishing boats, sailboats, yachts) is dependent on a healthy ocean.


**Q: Why isn’t oil and gas industries included in revenue?**

A: The Natural Products goal does not include non-living items such as oil, gas, and mining products, because these practices are not considered to be sustainable. They are also done at such large scales that including them would essentially make OHI an index for oil and mining--and they are not truly an ocean product. Because these products are not included in terms of quantity extracted, it did not seem appropriate to include information regarding jobs, wages or revenue.

## Tourism & Recreation

**Q: How do I calculate the sustainability term for TR?**

A: The best way is to use a local indicator or measure of tourism sustainability or competitiveness, otherwise use the TTCI value from the Global 2013 assessment for the study area (applied evenly across all regions.

## Natural Products

**Q: Where do Natural Products come from?**

A: In the global assessments, Natural Products data come from the UN’s Food and Agriculture Administration (www.fao.org/fishery/statistics/software/fishstatj/en). These data are compiled and reported by product for each country, and available by downloading the FishStatJ software.

## Species

**Q: Can species and iconic species model scores be penalized if there are local flagship species that have not been evaluated?**

Global data are based on IUCN assessments. For these evaluations, IUCN chooses a taxon (e.g. sharks) and a group of world experts assess it comprehensively. Locally identified species identified in a regional assessment may not be in the IUCN database because they do not belong to one of the taxa that have been selected for assessment, or because the experts that did the assessment did not know that information existed. In either case, there is no connection between what IUCN reports and what assessments are done locally. Therefore, it might not be fair to penalize a study area for missing species. For biodiversity, it is unrealistic to expect that all species are assessed, so it seems unfair to penalize for unassessed species. In the fisheries goal, there are penalties for species that are exploited but not assessed, because if there are landings data, it means they are somewhat measurable, and so it is reasonable to expect they should be at least monitored.

It might be reasonable to penalize unassessed iconic species. It is a smaller list of species that are specifically identified as being of interest, for one reason or other. This would work for species that have some form of assessment - unless that information already exists, it might be unrealistic to try to produce the data layer required to develop a new model.

## Sense of Place

**Q: Data are only available for marine protected areas, not terrestrial protected areas. Can we still calculate the Lasting Special Places sub-goal?**

A: Yes, it is possible to calculate only the marine component of this sub-goal: this is not ideal but OHI is flexible to work with the data available.

**Q: Should we calculate each category used in our assessment (e.g., antiquities, MPAs, beaches of special interest) independently, and then give the same weight (e.g., a third of the goal score) to the three categories, or should we instead pool the actual areas of the 3 categories?**

A: Whether you group them together or calculate each category separately depends on reference points. Maybe you want 10% of offshore water to be in MPAs, but only 5% of coastlines to be beaches and 3% Antiquities, for example; in this case, you would calculate them separately and then add them together. But if you want 10% of your country's coast to have any combination of these things, you would keep them together.

*(Source: OHI Israel assessment discussions, 2014-2015)*

## Pressures

**Q: How are single ecological pressures (si in Equation S8) calculated?**

A: Data included in pressures calculations are accessed in the same manner as any other data layer, and rescaled from 0-1 with an appropriate reference point. For further information, see HowTo_GatherAppropriateData and HowTo_CalculatePressures from ohi-science.org.


**Q: Does the pressures matrix need to be changed?**

A: It is likely that the pressures matrix will not need to be changed. The weights assigned in the matrix were set using information from the literature and by experts; the matrix was created by Halpern et al. 2012.


**Q: How is commercial high and low bycatch calculated?**

A: Commercial high and low bycatch are categorical values that were set based on fishing gear type. This began as a list of gear types used, producing a range of potential bycatch frequencies (from local reports when possible), which can be rescaled.

# Toolbox Troubleshooting

The Toolbox prints messages during its processing to help guide error checking and debugging. Here are a few troubleshooting tips. This section will be updated frequently; please share any problems that you encounter.  

## Error: RStudio won't push to GitHub

When pushing committed changes within RStudio, would return the error
* `error: unable to read askpass response from 'rpostback-askpass'`
* `fatal: could not read Username for 'https://github.com': Device not configured`
![Error screen window: 'error: unable to read askpass response'.](https://docs.google.com/drawings/d/1_yPk-eiJz-9P1VO0Z50bGQSTERM2aKcq6U_un3MlUO4/pub?w=819&h=107)

Here's how we fixed it: we updated `git.exe` to the latest version, 2.2.1, edited the search path to point to the new version, made sure the *git* credential.helper was configured to be able to access the OS X keychain, and pushed a test commit from terminal to store the username and password in the keychain, where it can be accessed from other apps like RStudio. Easy peasy!

1. To check your current version of `git.exe`, type this at the terminal command line:
    * `$ git --version` should return something like:
    * `git version 2.2.1` (check online to see if this is the latest version)
2. To update, go to http://git-scm.com/download/mac, download the latest *git* for OS X, install it.  
3. In terminal, type  `git --version` and verify that it reports the new version.  If it shows the new version, great!  Skip to Step 5.
    * Don't be sad if it doesn't!  If you still see the old version, the installer put the new version into a different directory, which has a lower priority in the search path, so now to update the search path.  The default Apple *git* seems to install the `git.exe` into `/usr/bin/` directory, this particular updater seems to install into `/usr/local/git/bin/` directory.  The search path needs to be updated to look for `git.exe` in the new directory first.
4. To change the search path, open up the paths file in `nano` editor using `sudo`:
    * `$ sudo nano /etc/paths`
    * At the top line of the paths file, add the directory for the updated *git*: `’/usr/local/git/bin’`(without the quotes) so it looks like the top line here:
![Terminal window showing where to set *git* filepaths.](https://docs.google.com/drawings/d/11KDJp52kCa-_n4jP97nGZqXc-cKNEvtV-R6M9_neMBg/pub?w=564&h=335)
    * Then hit `control-X` to exit, then `Y` in response to the save prompt.
5. Make sure your `git config` is up to date, including `credential.helper`:
    * `$ git config --global -l` should return something like:
    * `user.name="Casey O'Hara"`
    * `user.email=ohara@nceas.ucsb.edu`
        * see https://github.com/OHI-Science/ohiprep/wiki/Setup#git_identity for help on updating user.name and user.email
    * `credential.helper=osxkeychain`
        * (if you need to configure the credential helper: https://help.github.com/articles/caching-your-github-password-in-git/)
6. Now while you are in Terminal, it is important to sync with a repository to establish your security credentials. You must clone a repository and push a 'test' commit, and then once you are prompted for your username and password your information will get stored in the keychain. Here are the steps:
    * Change your working directory to your local github directory: `$ cd github`
       * (Tip: you can check if you're in the right folder by entering `pwd`, short for "print working directory"; or you could look at the line of code preceding the "$".)
    * Clone into a repository with a URL *for which you have permissions*. As an example, the following steps use a repository called 'ZAF' but you should use your own URL with a three-letter country code in place of 'ZAF':
       * `$ git clone  https://github.com/omalik/zaf.git`
    * Change your working directory to the folder you just created (here, 'ZAF'): `$ cd zaf`
    * Push a test commit to repository 'ZAF':
       * `$ touch test.md`
       * `$ git add test.md`
       * `$ git commit -m "testing"`
       * `$ git status`
       * `$ git push`
       * Check your status again: `$ git status`
         * (TIP: You can check your status with `$ git status` and you can use 'ls' to see if your new changes have registered in this repository.)
7. Now that *git* is updated and your username and password are set, make sure RStudio knows the location of the new `git.exe`.  In RStudio, select **Tools > Global Options…**, select the `Git/SVN`, and browse to the new `Git executable` (it should appear as `/usr/local/git/bin/git` if you updated your *git* version as above).
![Checking the options in RStudio for the git executable path.](https://docs.google.com/drawings/d/1Y3NrM8mvhRqsMrF2wkTjA0b_Rgfl_2nwU2J6C4p-VUw/pub?w=581&h=542)

Next time you push a commit from RStudio, it should remember the username and password from your test commit in Step 6, and you should be good to go.



## Loading RWorkspace on Restart

When you restart your R Session (**Session > Restart R** on a Mac), if you see that it is trying to load `ohicore`, it may give you an error:

  > ![](./fig/ohicore_load.png)

You do not want it to load `ohicore` or to save anything in your workspace. You will need to change the default setting from you **.Rproj** file. Steps to do this:

1. Go to Project Options, either in the pull-down menu or by double-clicking the .Rproj file:


  > ![](./fig/proj_op.png)

  > ![](./fig/proj_op2.png)

2. Change all options to **No:**

  > ![](./fig/proj_op3.png)

## Calculating Pressures...

### 'The following components for [goal] are not in the aggregation layer [layer]...'

Example:

> ![](./fig/troubleshoot_aggregation_layer.png)

  > ![](./fig/tblshoot_pressures.png)  

This error means you should update your pressures matrix because it expects there to be components that your region does not have.

### 'Error in matrix...'

Example:
  > ![](./fig/tblshoot_pressures.png)  

This error means there is an empty column in `pressures_matrix.csv`, and the Toolbox cannot handle empty columns.

## Calculating Resilience ...

### 'Error in match(x, table, nomatch = OL) : object id_num not found'

  > ![](./fig/error_resil_mtx.png)  

This error means you should check that there is at least one entry for each goal (for each row) in `resilience_matrix.csv`.

